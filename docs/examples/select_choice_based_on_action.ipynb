{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enforcing Guardrails on Choice Selection\n",
    "\n",
    "!!! note\n",
    "    To download this tutorial as a Jupyter notebook, click [here](https://github.com/ShreyaR/guardrails/blob/main/docs/examples/select_choice_based_on_action.ipynb).\n",
    "\n",
    "In this example, we want the LLM to pick an action (e.g. `fight` or `flight`), and based on that action we want to return different JSON objects. For example, if the action is `fight`, we want to return a JSON object that contains the `weapon` field. If the action is `flight`, we want to return a JSON object that contains the `direction` and `distance` fields.\n",
    "\n",
    "We make the assumption that:\n",
    "\n",
    "1. We don't need any external libraries that are not already installed in the environment.\n",
    "2. We are able to execute the code in the environment.\n",
    "\n",
    "## Objective\n",
    "\n",
    "We want the LLM to play an RP game where it can choose to either `fight` or `flight`. If it chooses to `fight`, the LLM should choose a `weapon` and an `enemy`. If the player chooses `flight`, the LLM shoudl choose a `direction` and a `distance`.\n",
    "\n",
    "\n",
    "## Step 1: Generating `RAIL` Spec\n",
    "\n",
    "Ordinarily, we could create a separate `RAIL` spec in a file. However, for the sake of this example, we will generate the `RAIL` spec in the notebook as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rail_str = \"\"\"\n",
    "<rail version=\"0.1\">\n",
    "\n",
    "<output>\n",
    "    <choice name=\"action\" on-fail-choice=\"reask\">\n",
    "        <case name=\"fight\">\n",
    "            <string name=\"weapon\" format=\"valid-choices: {['crossbow', 'machine gun']}\" on-fail-valid-choices=\"reask\" />\n",
    "        </case>\n",
    "        <case name=\"flight\">\n",
    "            <object name=\"flight\">\n",
    "                <string name=\"flight_direction\" format=\"valid-choices: {['north','south','east','west']}\" on-fail-valid-choices=\"exception\" />\n",
    "                <integer name=\"distance\" format=\"valid-choices: {[1,2,3,4]}\" on-fail-valid-choices=\"exception\" />\n",
    "            </object>\n",
    "        </case>\n",
    "    </choice>\n",
    "</output>\n",
    "\n",
    "<prompt>\n",
    "You are a human in an enchanted forest. You come across opponents of different types, and you should fight smaller opponents and run away from bigger ones.\n",
    "\n",
    "You run into a ${opp_type}. What do you do?\n",
    "\n",
    "${gr.complete_json_suffix_v2}</prompt>\n",
    "\n",
    "</rail>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create a `Guard` object with the RAIL Spec\n",
    "\n",
    "We create a `gd.Guard` object that will check, validate and correct the generated code. This object:\n",
    "\n",
    "1. Enforces the quality criteria specified in the RAIL spec (i.e. bug free code).\n",
    "2. Takes corrective action when the quality criteria are not met (i.e. reasking the LLM).\n",
    "3. Compiles the schema and type info from the RAIL spec and adds it to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import guardrails as gd\n",
    "\n",
    "from rich import print\n",
    "\n",
    "guard = gd.Guard.from_rail_string(rail_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Guard` object compiles the output schema and adds it to the prompt. We can see the final prompt below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(guard.base_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Wrap the LLM API call with `Guard`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now wrap the LsLM API call with the `Guard` object. This will ensure that the LLM generates an output that is compliant with the RAIL spec.\n",
    "\n",
    "To start, we test with a 'giant' as an opponent, and look at the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "raw_llm_response, validated_response = guard(\n",
    "    openai.Completion.create,\n",
    "    prompt_params={'opp_type': 'giant'},\n",
    "    engine=\"text-davinci-003\",\n",
    "    max_tokens=256,\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the cell above returns:\n",
    "1. The raw LLM text output as a single string.\n",
    "2. A dictionary where the key is `python_code` and the value is the generated code.\n",
    "\n",
    "We can see that if the LLM chooses `flight`, the output is a dictionary with `flight_direction` and `distance` fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validated_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the logs of the guard object to see the quality criteria that were checked and the corrective actions that were taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(guard.state.most_recent_call.tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test with a `goblin` as an opponent.\n",
    "\n",
    "We can see that the LLM chose to `fight` and the output is a choice of `weapon`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_llm_response, validated_response = guard(\n",
    "    openai.Completion.create,\n",
    "    prompt_params={'opp_type': 'goblin'},\n",
    "    engine=\"text-davinci-003\",\n",
    "    max_tokens=256,\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validated_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the state of the guard after each call to see what happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(guard.state.most_recent_call.tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiff-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
