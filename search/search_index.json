{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Guardrails.ai Note: Guardrails is an alpha release, so expect sharp edges and bugs. \ud83d\udee4\ufe0f What is Guardrails? Guardrails is a Python package that lets a user add structure, type and quality guarantees to the outputs of large language models (LLMs). Guardrails: does pydantic-style validation of LLM outputs. This includes semantic validation such as checking for bias in generated text, checking for bugs in generated code, etc. takes corrective actions (e.g. reasking LLM) when validation fails, enforces structure and type guarantees (e.g. JSON). \ud83d\ude92 Under the hood Guardrails provides a format ( .rail ) for enforcing a specification on an LLM output, and a lightweight wrapper around LLM API calls to implement this spec. rail ( R eliable AI markup L anguage) files for specifying structure and type information, validators and corrective actions over LLM outputs. gd.Guard wraps around LLM API calls to structure, validate and correct the outputs. graph LR A[Create `RAIL` spec] --> B[\"Initialize `guard` from spec\"]; B --> C[\"Wrap LLM API call with `guard`\"]; Check out the Getting Started guide to learn how to use Guardrails. \ud83d\udcdc RAIL spec At the heart of Guardrails is the rail spec. rail is intended to be a language-agnostic, human-readable format for specifying structure and type information, validators and corrective actions over LLM outputs. rail is a flavor of XML that lets users specify: The expected structure and types of the LLM output (e.g. JSON), The quality criteria for the output to be considered valid (e.g. generated text should be bias-free, generated code should be bug-free), Corrective actions to be taken if the output is invalid (e.g. reask the LLM, filter out the invalid output, etc.) To learn more about the rail spec and the design decisions behind it, check out the Rail Specification . To learn how to write your own rail spec, check out specifying output elements in RAIL . \ud83d\udccd Roadmap Adding more examples, new use cases and domains Adding integrations with langchain, gpt-index, minichain, manifest Expanding validators offering More compilers from .rail -> LLM prompt (e.g. .rail -> TypeScript) Informative logging Improving reasking logic A guardrails.js implementation VSCode extension for .rail files Next version of .rail format Add more LLM providers","title":"Home"},{"location":"#guardrailsai","text":"Note: Guardrails is an alpha release, so expect sharp edges and bugs.","title":"Guardrails.ai"},{"location":"#what-is-guardrails","text":"Guardrails is a Python package that lets a user add structure, type and quality guarantees to the outputs of large language models (LLMs). Guardrails: does pydantic-style validation of LLM outputs. This includes semantic validation such as checking for bias in generated text, checking for bugs in generated code, etc. takes corrective actions (e.g. reasking LLM) when validation fails, enforces structure and type guarantees (e.g. JSON).","title":"\ud83d\udee4\ufe0f What is Guardrails?"},{"location":"#under-the-hood","text":"Guardrails provides a format ( .rail ) for enforcing a specification on an LLM output, and a lightweight wrapper around LLM API calls to implement this spec. rail ( R eliable AI markup L anguage) files for specifying structure and type information, validators and corrective actions over LLM outputs. gd.Guard wraps around LLM API calls to structure, validate and correct the outputs. graph LR A[Create `RAIL` spec] --> B[\"Initialize `guard` from spec\"]; B --> C[\"Wrap LLM API call with `guard`\"]; Check out the Getting Started guide to learn how to use Guardrails.","title":"\ud83d\ude92 Under the hood"},{"location":"#rail-spec","text":"At the heart of Guardrails is the rail spec. rail is intended to be a language-agnostic, human-readable format for specifying structure and type information, validators and corrective actions over LLM outputs. rail is a flavor of XML that lets users specify: The expected structure and types of the LLM output (e.g. JSON), The quality criteria for the output to be considered valid (e.g. generated text should be bias-free, generated code should be bug-free), Corrective actions to be taken if the output is invalid (e.g. reask the LLM, filter out the invalid output, etc.) To learn more about the rail spec and the design decisions behind it, check out the Rail Specification . To learn how to write your own rail spec, check out specifying output elements in RAIL .","title":"\ud83d\udcdc RAIL spec"},{"location":"#roadmap","text":"Adding more examples, new use cases and domains Adding integrations with langchain, gpt-index, minichain, manifest Expanding validators offering More compilers from .rail -> LLM prompt (e.g. .rail -> TypeScript) Informative logging Improving reasking logic A guardrails.js implementation VSCode extension for .rail files Next version of .rail format Add more LLM providers","title":"\ud83d\udccd Roadmap"},{"location":"data_types/","text":"Boolean Bases: ScalarType Element tag: <bool> Date Bases: ScalarType Element tag: <date> Email Bases: ScalarType Element tag: <email> Field Bases: ScalarType Element tag: <field> Float Bases: ScalarType Element tag: <float> Integer Bases: ScalarType Element tag: <integer> List Bases: NonScalarType Element tag: <list> Object Bases: NonScalarType Element tag: <object> Percentage Bases: ScalarType Element tag: <percentage> Pydantic ( model , children , format_attr , element ) Bases: NonScalarType Element tag: <pydantic> model = model instance-attribute validators : List property from_xml ( element , strict = False ) classmethod to_object_element () Convert the Pydantic data type to an element. PythonCode Bases: ScalarType Element tag: <pythoncode> SQLCode Bases: ScalarType Element tag: <sql> String Bases: ScalarType Element tag: <string> Time Bases: ScalarType Element tag: <time> URL Bases: ScalarType Element tag: <url>","title":"Data Types"},{"location":"data_types/#guardrails.datatypes.Boolean","text":"Bases: ScalarType Element tag: <bool>","title":"Boolean"},{"location":"data_types/#guardrails.datatypes.Date","text":"Bases: ScalarType Element tag: <date>","title":"Date"},{"location":"data_types/#guardrails.datatypes.Email","text":"Bases: ScalarType Element tag: <email>","title":"Email"},{"location":"data_types/#guardrails.datatypes.Field","text":"Bases: ScalarType Element tag: <field>","title":"Field"},{"location":"data_types/#guardrails.datatypes.Float","text":"Bases: ScalarType Element tag: <float>","title":"Float"},{"location":"data_types/#guardrails.datatypes.Integer","text":"Bases: ScalarType Element tag: <integer>","title":"Integer"},{"location":"data_types/#guardrails.datatypes.List","text":"Bases: NonScalarType Element tag: <list>","title":"List"},{"location":"data_types/#guardrails.datatypes.Object","text":"Bases: NonScalarType Element tag: <object>","title":"Object"},{"location":"data_types/#guardrails.datatypes.Percentage","text":"Bases: ScalarType Element tag: <percentage>","title":"Percentage"},{"location":"data_types/#guardrails.datatypes.Pydantic","text":"Bases: NonScalarType Element tag: <pydantic>","title":"Pydantic"},{"location":"data_types/#guardrails.datatypes.Pydantic.model","text":"","title":"model"},{"location":"data_types/#guardrails.datatypes.Pydantic.validators","text":"","title":"validators"},{"location":"data_types/#guardrails.datatypes.Pydantic.from_xml","text":"","title":"from_xml()"},{"location":"data_types/#guardrails.datatypes.Pydantic.to_object_element","text":"Convert the Pydantic data type to an element.","title":"to_object_element()"},{"location":"data_types/#guardrails.datatypes.PythonCode","text":"Bases: ScalarType Element tag: <pythoncode>","title":"PythonCode"},{"location":"data_types/#guardrails.datatypes.SQLCode","text":"Bases: ScalarType Element tag: <sql>","title":"SQLCode"},{"location":"data_types/#guardrails.datatypes.String","text":"Bases: ScalarType Element tag: <string>","title":"String"},{"location":"data_types/#guardrails.datatypes.Time","text":"Bases: ScalarType Element tag: <time>","title":"Time"},{"location":"data_types/#guardrails.datatypes.URL","text":"Bases: ScalarType Element tag: <url>","title":"URL"},{"location":"getting_started/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Getting Started In this notebook, we will go through the basics of creating a RAIL spec and using Guardrails to enforce it. Objective Our goal is to understand what a bank run is, and generate URL links to relevant news articles. We will first generate a RAIL spec for this and then use Guardrails to enforce it. Installation To get started, install the guardrails package with pip . ! pip install guardrails - ai Creating an RAIL spec At the heart of Guardrails is the RAIL spec. RAIL a flavor of XML (standing for R eliable AI markup L anguage) that describes the expected structure and type of the output of the LLM, the quality criteria for the output to be valid and corrective actions to be taken if the output is invalid. For this task, we create a RAIL spec that requests the LLM to generate an object with 2 fields: explanation and follow_up_url . For the explanation field to be valid, the max length of the generated string should be between 200 to 280 characters in length . In case the generated string doesn't meet this criteria, for now we just want to log the validation error and continue (i.e. the noop action). For the follow_up_url field to be valid, the URL should be reachable . In case this quality criteria is not met, the generated output should be filtered out (i.e. the filter action). We specify our quality criteria (generated length, URL reachability) in the format fields of the RAIL spec below. For now, we want to do nothing if the quality criteria for explanation is not met, and filter the follow_up_url if it is not valid. Note Ordinarily, the RAIL spec would be created in a file directly. However, for the purposes of this demo, we write the spec in a string and then create a file from it. rail_spec = \"\"\" <rail version=\"0.1\"> <output> <object name=\"bank_run\" format=\"length: 2\"> <string name=\"explanation\" description=\"A paragraph about what a bank run is.\" format=\"length: 200 240\" on-fail-length=\"noop\" /> <url name=\"follow_up_url\" description=\"A web URL where I can read more about bank runs.\" required=\"true\" format=\"valid-url\" on-fail-valid-url=\"filter\" /> </object> </output> <prompt> Explain what a bank run is in a tweet. @xml_prefix_prompt {output_schema} @json_suffix_prompt_v2_wo_none </prompt> </rail> \"\"\" Using Guardrails to enforce the RAIL spec We use the RAIL spec to create a Guard object. The Guard object is used to wrap the LLM API call and enforce the RAIL spec on the output of the LLM call. from rich import print import guardrails as gd guard = gd . Guard . from_rail_string ( rail_spec ) We can see that the Guard object compiles the RAIL output specification and adds it to the provided prompt. print ( guard . base_prompt ) Explain what a bank run is in a tweet. Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <object name = \"bank_run\" format = \"length: 2\" > <string name = \"explanation\" description = \"A paragraph about what a bank run is.\" format = \"length: 200 240\" / > <url name = \"follow_up_url\" description = \"A web URL where I can read more about bank runs.\" required = \"true\" format = \"valid-url\" / > < / object > < / output > ONLY return a valid JSON object ( no other text is necessary ) . The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. JSON Output: Next, we call the Guard object with the LLM API call as the first argument and add any additional arguments to the LLM API call as the remaining arguments. import openai import os # Set your OpenAI API key os . environ [ \"OPENAI_API_KEY\" ] = \"YOUR_OPENAI_API_KEY\" # Wrap the OpenAI API call with the `guard` object raw_llm_output , validated_output = guard ( openai . Completion . create , engine = \"text-davinci-003\" , max_tokens = 1024 , temperature = 0.3 , ) # Print the validated output from the LLM print ( validated_output ) { 'bank_run' : { 'explanation' : \"A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about the bank's solvency.\" , 'follow_up_url' : 'https://www.investopedia.com/terms/b/bankrun.asp' } } print ( f 'Len of explanation: { len ( validated_output [ \"bank_run\" ][ \"explanation\" ]) } ' ) Len of explanation: 125 As we can see, the explanation field didn't meet the quality criteria (length between 200 and 280 characters). However, because of the the noop action specified in the RAIL spec, the Guard object returned the output of the LLM API call as is. Next, we change the RAIL spec to reask the LLM for a correct explanation if its length is incorrect. We do this by creating a new RAIL spec and creating a new Guard object. import tempfile rail_spec = \"\"\" <rail version=\"0.1\"> <output> <object name=\"bank_run\" format=\"length: 2\"> <string name=\"explanation\" description=\"A paragraph about what a bank run is.\" format=\"length: 200 240\" on-fail-length=\"reask\" /> <url name=\"follow_up_url\" description=\"A web URL where I can read more about bank runs.\" required=\"true\" format=\"valid-url\" on-fail-valid-url=\"filter\" /> </object> </output> <prompt> Explain what a bank run is in a tweet. @xml_prefix_prompt {output_schema} @json_suffix_prompt_v2_wo_none </prompt> </rail> \"\"\" with tempfile . NamedTemporaryFile ( mode = \"w\" , suffix = \".rail\" ) as f : f . write ( rail_spec ) f . flush () guard_with_reask = gd . Guard . from_rail ( f . name ) raw_llm_output , validated_output = guard_with_reask ( openai . Completion . create , engine = \"text-davinci-003\" , max_tokens = 1024 , temperature = 0.3 , ) # Print the validated output from the LLM print ( validated_output ) { 'bank_run' : { 'explanation' : 'A bank run is when a large number of people withdraw their deposits from a bank due to concerns about its solvency. This can cause a financial crisis if the bank is unable to meet the demand for withdrawals.' , 'follow_up_url' : 'https://www.investopedia.com/terms/b/bankrun.asp' } } print ( f 'Len of explanation: { len ( validated_output [ \"bank_run\" ][ \"explanation\" ]) } ' ) Len of explanation: 207","title":"Getting Started"},{"location":"getting_started/#getting-started","text":"In this notebook, we will go through the basics of creating a RAIL spec and using Guardrails to enforce it.","title":"Getting Started"},{"location":"getting_started/#objective","text":"Our goal is to understand what a bank run is, and generate URL links to relevant news articles. We will first generate a RAIL spec for this and then use Guardrails to enforce it.","title":"Objective"},{"location":"getting_started/#installation","text":"To get started, install the guardrails package with pip . ! pip install guardrails - ai","title":"Installation"},{"location":"getting_started/#creating-an-rail-spec","text":"At the heart of Guardrails is the RAIL spec. RAIL a flavor of XML (standing for R eliable AI markup L anguage) that describes the expected structure and type of the output of the LLM, the quality criteria for the output to be valid and corrective actions to be taken if the output is invalid. For this task, we create a RAIL spec that requests the LLM to generate an object with 2 fields: explanation and follow_up_url . For the explanation field to be valid, the max length of the generated string should be between 200 to 280 characters in length . In case the generated string doesn't meet this criteria, for now we just want to log the validation error and continue (i.e. the noop action). For the follow_up_url field to be valid, the URL should be reachable . In case this quality criteria is not met, the generated output should be filtered out (i.e. the filter action). We specify our quality criteria (generated length, URL reachability) in the format fields of the RAIL spec below. For now, we want to do nothing if the quality criteria for explanation is not met, and filter the follow_up_url if it is not valid. Note Ordinarily, the RAIL spec would be created in a file directly. However, for the purposes of this demo, we write the spec in a string and then create a file from it. rail_spec = \"\"\" <rail version=\"0.1\"> <output> <object name=\"bank_run\" format=\"length: 2\"> <string name=\"explanation\" description=\"A paragraph about what a bank run is.\" format=\"length: 200 240\" on-fail-length=\"noop\" /> <url name=\"follow_up_url\" description=\"A web URL where I can read more about bank runs.\" required=\"true\" format=\"valid-url\" on-fail-valid-url=\"filter\" /> </object> </output> <prompt> Explain what a bank run is in a tweet. @xml_prefix_prompt {output_schema} @json_suffix_prompt_v2_wo_none </prompt> </rail> \"\"\"","title":"Creating an RAIL spec"},{"location":"getting_started/#using-guardrails-to-enforce-the-rail-spec","text":"We use the RAIL spec to create a Guard object. The Guard object is used to wrap the LLM API call and enforce the RAIL spec on the output of the LLM call. from rich import print import guardrails as gd guard = gd . Guard . from_rail_string ( rail_spec ) We can see that the Guard object compiles the RAIL output specification and adds it to the provided prompt. print ( guard . base_prompt ) Explain what a bank run is in a tweet. Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <object name = \"bank_run\" format = \"length: 2\" > <string name = \"explanation\" description = \"A paragraph about what a bank run is.\" format = \"length: 200 240\" / > <url name = \"follow_up_url\" description = \"A web URL where I can read more about bank runs.\" required = \"true\" format = \"valid-url\" / > < / object > < / output > ONLY return a valid JSON object ( no other text is necessary ) . The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. JSON Output: Next, we call the Guard object with the LLM API call as the first argument and add any additional arguments to the LLM API call as the remaining arguments. import openai import os # Set your OpenAI API key os . environ [ \"OPENAI_API_KEY\" ] = \"YOUR_OPENAI_API_KEY\" # Wrap the OpenAI API call with the `guard` object raw_llm_output , validated_output = guard ( openai . Completion . create , engine = \"text-davinci-003\" , max_tokens = 1024 , temperature = 0.3 , ) # Print the validated output from the LLM print ( validated_output ) { 'bank_run' : { 'explanation' : \"A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about the bank's solvency.\" , 'follow_up_url' : 'https://www.investopedia.com/terms/b/bankrun.asp' } } print ( f 'Len of explanation: { len ( validated_output [ \"bank_run\" ][ \"explanation\" ]) } ' ) Len of explanation: 125 As we can see, the explanation field didn't meet the quality criteria (length between 200 and 280 characters). However, because of the the noop action specified in the RAIL spec, the Guard object returned the output of the LLM API call as is. Next, we change the RAIL spec to reask the LLM for a correct explanation if its length is incorrect. We do this by creating a new RAIL spec and creating a new Guard object. import tempfile rail_spec = \"\"\" <rail version=\"0.1\"> <output> <object name=\"bank_run\" format=\"length: 2\"> <string name=\"explanation\" description=\"A paragraph about what a bank run is.\" format=\"length: 200 240\" on-fail-length=\"reask\" /> <url name=\"follow_up_url\" description=\"A web URL where I can read more about bank runs.\" required=\"true\" format=\"valid-url\" on-fail-valid-url=\"filter\" /> </object> </output> <prompt> Explain what a bank run is in a tweet. @xml_prefix_prompt {output_schema} @json_suffix_prompt_v2_wo_none </prompt> </rail> \"\"\" with tempfile . NamedTemporaryFile ( mode = \"w\" , suffix = \".rail\" ) as f : f . write ( rail_spec ) f . flush () guard_with_reask = gd . Guard . from_rail ( f . name ) raw_llm_output , validated_output = guard_with_reask ( openai . Completion . create , engine = \"text-davinci-003\" , max_tokens = 1024 , temperature = 0.3 , ) # Print the validated output from the LLM print ( validated_output ) { 'bank_run' : { 'explanation' : 'A bank run is when a large number of people withdraw their deposits from a bank due to concerns about its solvency. This can cause a financial crisis if the bank is unable to meet the demand for withdrawals.' , 'follow_up_url' : 'https://www.investopedia.com/terms/b/bankrun.asp' } } print ( f 'Len of explanation: { len ( validated_output [ \"bank_run\" ][ \"explanation\" ]) } ' ) Len of explanation: 207","title":"Using Guardrails to enforce the RAIL spec"},{"location":"guard/","text":"The Guard class. This class is the main entry point for using Guardrails. It is initialized from either from_rail or from_rail_string methods, which take in a .rail file or string, respectively. The __call__ method functions as a wrapper around LLM APIs. It takes in an LLM API, and optional prompt parameters, and returns the raw output from the LLM and the validated output. Initialize the Guard. from_rail ( rail_file , num_reasks = 1 ) classmethod Create a Schema from a .rail file. Parameters: Name Type Description Default rail_file str The path to the .rail file. required num_reasks int The max times to re-ask the LLM for invalid output. 1 Returns: Type Description Guard An instance of the Guard class. from_rail_string ( rail_string , num_reasks = 1 ) classmethod Create a Schema from a .rail string. Parameters: Name Type Description Default rail_string str The .rail string. required num_reasks int The max times to re-ask the LLM for invalid output. 1 Returns: Type Description Guard An instance of the Guard class. __call__ ( llm_api , prompt_params = None , num_reasks = 1 , * args , ** kwargs ) Call the LLM and validate the output. Parameters: Name Type Description Default llm_api Callable The LLM API to call (e.g. openai.Completion.create) required prompt_params Dict The parameters to pass to the prompt.format() method. None num_reasks int The max times to re-ask the LLM for invalid output. 1 *args Additional arguments to pass to the LLM API. () **kwargs Additional keyword arguments to pass to the LLM API. {} Returns: Type Description Tuple [ str , Dict ] The raw text output from the LLM and the validated output. parse ( llm_output , llm_api = None , num_reasks = 1 , * args , ** kwargs ) Alternate flow to using Guard where the llm_output is known. Parameters: Name Type Description Default llm_output str The output from the LLM. required llm_api PromptCallable The LLM API to use to re-ask the LLM. None num_reasks int The max times to re-ask the LLM for invalid output. 1 Returns: Type Description Dict The validated response.","title":"Guard"},{"location":"guard/#guardrails.guard.Guard.from_rail","text":"Create a Schema from a .rail file. Parameters: Name Type Description Default rail_file str The path to the .rail file. required num_reasks int The max times to re-ask the LLM for invalid output. 1 Returns: Type Description Guard An instance of the Guard class.","title":"from_rail()"},{"location":"guard/#guardrails.guard.Guard.from_rail_string","text":"Create a Schema from a .rail string. Parameters: Name Type Description Default rail_string str The .rail string. required num_reasks int The max times to re-ask the LLM for invalid output. 1 Returns: Type Description Guard An instance of the Guard class.","title":"from_rail_string()"},{"location":"guard/#guardrails.guard.Guard.__call__","text":"Call the LLM and validate the output. Parameters: Name Type Description Default llm_api Callable The LLM API to call (e.g. openai.Completion.create) required prompt_params Dict The parameters to pass to the prompt.format() method. None num_reasks int The max times to re-ask the LLM for invalid output. 1 *args Additional arguments to pass to the LLM API. () **kwargs Additional keyword arguments to pass to the LLM API. {} Returns: Type Description Tuple [ str , Dict ] The raw text output from the LLM and the validated output.","title":"__call__()"},{"location":"guard/#guardrails.guard.Guard.parse","text":"Alternate flow to using Guard where the llm_output is known. Parameters: Name Type Description Default llm_output str The output from the LLM. required llm_api PromptCallable The LLM API to use to re-ask the LLM. None num_reasks int The max times to re-ask the LLM for invalid output. 1 Returns: Type Description Dict The validated response.","title":"parse()"},{"location":"logs/","text":"Inspecting logs All gd.Guard calls are logged internally, and can be accessed via two methods, gd.Guard.guard_state or guardrails.log . \ud83e\udeb5 Accessing logs via guardrails.log This is the simplest way to access logs. It returns a list of all gd.Guard calls, in the order they were made. In order to access logs, run: eliot-tree --output-format = ascii guardrails.log \ud83c\uddfb\ud83c\udde6 Accessing logs via gd.Guard.guard_state guard_state is an attribute of the gd.Guard class. It contains: A list of all gd.Guard calls, in the order they were made. For each call, reasks needed and their results. \u23f2\ufe0f Coming soon On the roadmap: first class support for reading logs.","title":"Inspecting logs"},{"location":"logs/#inspecting-logs","text":"All gd.Guard calls are logged internally, and can be accessed via two methods, gd.Guard.guard_state or guardrails.log .","title":"Inspecting logs"},{"location":"logs/#accessing-logs-via-guardrailslog","text":"This is the simplest way to access logs. It returns a list of all gd.Guard calls, in the order they were made. In order to access logs, run: eliot-tree --output-format = ascii guardrails.log","title":"\ud83e\udeb5 Accessing logs via guardrails.log"},{"location":"logs/#accessing-logs-via-gdguardguard_state","text":"guard_state is an attribute of the gd.Guard class. It contains: A list of all gd.Guard calls, in the order they were made. For each call, reasks needed and their results.","title":"\ud83c\uddfb\ud83c\udde6 Accessing logs via gd.Guard.guard_state"},{"location":"logs/#coming-soon","text":"On the roadmap: first class support for reading logs.","title":"\u23f2\ufe0f Coming soon"},{"location":"validation/","text":"This module contains the validators for the Guardrails framework. The name with which a validator is registered is the name that is used in the RAIL spec to specify formatters. BugFreePython Validate that there are no Python syntactic bugs in the generated code. This validator checks for syntax errors by running ast.parse(code) , and will raise an exception if there are any. Only the packages in the python environment are available to the code snippet. Name for format attribute: bug-free-python Supported data types: pythoncode Programmatic fix: None BugFreeSQL Validate that there are no SQL syntactic bugs in the generated code. This is a very minimal implementation that uses the Pypi sqlvalidator package to check if the SQL query is valid. You can implement a custom SQL validator that uses a database connection to check if the query is valid. Name for format attribute: bug-free-sql Supported data types: sql Programmatic fix: None EndsWith ( end , on_fail = 'fix' ) Validate that a list ends with a given value. Name for format attribute: ends-with Supported data types: list Programmatic fix: Append the given value to the list. Filter IsHighQualityTranslation ( * args , ** kwargs ) Using inpiredco.critique to check if a translation is high quality. Name for format attribute: is-high-quality-translation Supported data types: string Programmatic fix: \"\" critique = Critique ( api_key = os . environ [ 'INSPIREDCO_API_KEY' ]) instance-attribute IsProfanityFree Validate that a translated text does not contain profanity language. This validator uses the alt-profanity-check package to check if a string contains profanity language. Name for format attribute: is-profanity-free Supported data types: string Programmatic fix: \"\" LowerCase Validate that a value is lower case. Name for format attribute: lower-case Supported data types: string Programmatic fix: Manually convert to lower case. OneLine Validate that a value is a single line or sentence. Name for format attribute: one-line Supported data types: string Programmatic fix: Pick the first line. Pydantic ( model , on_fail = None ) Validate an object using Pydantic. model = model instance-attribute PydanticReAsk Refrain SimilarToDocument ( document , threshold = 0.7 , model = 'text-embedding-ada-002' , on_fail = None ) Validate that a value is similar to the document. This validator checks if the value is similar to the document by checking the cosine similarity between the value and the document, using an embedding. Name for format attribute: similar-to-document Supported data types: string Programmatic fix: None TwoWords Validate that a value is upper case. Name for format attribute: two-words Supported data types: string Programmatic fix: Pick the first two words. UpperCase Validate that a value is upper case. Name for format attribute: upper-case Supported data types: string Programmatic fix: Manually convert to upper case. ValidChoices ( choices , on_fail = None ) Validate that a value is within the acceptable choices. Name for format attribute: valid-choices Supported data types: all Programmatic fix: None. ValidLength ( min = None , max = None , on_fail = None ) Validate that the length of value is within the expected range. Name for format attribute: length Supported data types: string , list , object Programmatic fix: If shorter than the minimum, pad with empty last elements. If longer than the maximum, truncate. ValidRange ( min = None , max = None , on_fail = None ) Validate that a value is within a range. Name for format attribute: valid-range Supported data types: integer , float , percentage Programmatic fix: Closest value within the range. ValidUrl Validate that a value is a valid URL. Name for format attribute: valid-url Supported data types: string , url Programmatic fix: None","title":"Validators"},{"location":"validation/#guardrails.validators.BugFreePython","text":"Validate that there are no Python syntactic bugs in the generated code. This validator checks for syntax errors by running ast.parse(code) , and will raise an exception if there are any. Only the packages in the python environment are available to the code snippet. Name for format attribute: bug-free-python Supported data types: pythoncode Programmatic fix: None","title":"BugFreePython"},{"location":"validation/#guardrails.validators.BugFreeSQL","text":"Validate that there are no SQL syntactic bugs in the generated code. This is a very minimal implementation that uses the Pypi sqlvalidator package to check if the SQL query is valid. You can implement a custom SQL validator that uses a database connection to check if the query is valid. Name for format attribute: bug-free-sql Supported data types: sql Programmatic fix: None","title":"BugFreeSQL"},{"location":"validation/#guardrails.validators.EndsWith","text":"Validate that a list ends with a given value. Name for format attribute: ends-with Supported data types: list Programmatic fix: Append the given value to the list.","title":"EndsWith"},{"location":"validation/#guardrails.validators.Filter","text":"","title":"Filter"},{"location":"validation/#guardrails.validators.IsHighQualityTranslation","text":"Using inpiredco.critique to check if a translation is high quality. Name for format attribute: is-high-quality-translation Supported data types: string Programmatic fix: \"\"","title":"IsHighQualityTranslation"},{"location":"validation/#guardrails.validators.IsHighQualityTranslation.critique","text":"","title":"critique"},{"location":"validation/#guardrails.validators.IsProfanityFree","text":"Validate that a translated text does not contain profanity language. This validator uses the alt-profanity-check package to check if a string contains profanity language. Name for format attribute: is-profanity-free Supported data types: string Programmatic fix: \"\"","title":"IsProfanityFree"},{"location":"validation/#guardrails.validators.LowerCase","text":"Validate that a value is lower case. Name for format attribute: lower-case Supported data types: string Programmatic fix: Manually convert to lower case.","title":"LowerCase"},{"location":"validation/#guardrails.validators.OneLine","text":"Validate that a value is a single line or sentence. Name for format attribute: one-line Supported data types: string Programmatic fix: Pick the first line.","title":"OneLine"},{"location":"validation/#guardrails.validators.Pydantic","text":"Validate an object using Pydantic.","title":"Pydantic"},{"location":"validation/#guardrails.validators.Pydantic.model","text":"","title":"model"},{"location":"validation/#guardrails.validators.PydanticReAsk","text":"","title":"PydanticReAsk"},{"location":"validation/#guardrails.validators.Refrain","text":"","title":"Refrain"},{"location":"validation/#guardrails.validators.SimilarToDocument","text":"Validate that a value is similar to the document. This validator checks if the value is similar to the document by checking the cosine similarity between the value and the document, using an embedding. Name for format attribute: similar-to-document Supported data types: string Programmatic fix: None","title":"SimilarToDocument"},{"location":"validation/#guardrails.validators.TwoWords","text":"Validate that a value is upper case. Name for format attribute: two-words Supported data types: string Programmatic fix: Pick the first two words.","title":"TwoWords"},{"location":"validation/#guardrails.validators.UpperCase","text":"Validate that a value is upper case. Name for format attribute: upper-case Supported data types: string Programmatic fix: Manually convert to upper case.","title":"UpperCase"},{"location":"validation/#guardrails.validators.ValidChoices","text":"Validate that a value is within the acceptable choices. Name for format attribute: valid-choices Supported data types: all Programmatic fix: None.","title":"ValidChoices"},{"location":"validation/#guardrails.validators.ValidLength","text":"Validate that the length of value is within the expected range. Name for format attribute: length Supported data types: string , list , object Programmatic fix: If shorter than the minimum, pad with empty last elements. If longer than the maximum, truncate.","title":"ValidLength"},{"location":"validation/#guardrails.validators.ValidRange","text":"Validate that a value is within a range. Name for format attribute: valid-range Supported data types: integer , float , percentage Programmatic fix: Closest value within the range.","title":"ValidRange"},{"location":"validation/#guardrails.validators.ValidUrl","text":"Validate that a value is a valid URL. Name for format attribute: valid-url Supported data types: string , url Programmatic fix: None","title":"ValidUrl"},{"location":"examples/bug_free_python_code/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Generating Bug Free Leetcode Solutions Note To download this tutorial as a Jupyter notebook, click here . In this example, we want to solve String Maniuplation leetcode problems such that the code is bug free. We make the assumption that: We don't need any external libraries that are not already installed in the environment. We are able to execute the code in the environment. Objective We want to generate bug-free code for solving leetcode problems. In this example, we don't account for semantic bugs, only for syntactic bugs. In short, we want to make sure that the code can be executed without any errors. Step 1: Generating RAIL Spec Ordinarily, we could create a separate RAIL spec in a file. However, for the sake of this example, we will generate the RAIL spec in the notebook as a string. rail_str = \"\"\" <rail version=\"0.1\"> <output> <pythoncode name=\"python_code\" format=\"bug-free-python\" on-fail-bug-free-python=\"reask\" /> </output> <prompt> Given the following high level leetcode problem description, write a short Python code snippet that solves the problem. Problem Description: {{leetcode_problem}} @complete_json_suffix</prompt> </rail> \"\"\" Step 2: Create a Guard object with the RAIL Spec We create a gd.Guard object that will check, validate and correct the generated code. This object: Enforces the quality criteria specified in the RAIL spec (i.e. bug free code). Takes corrective action when the quality criteria are not met (i.e. reasking the LLM). Compiles the schema and type info from the RAIL spec and adds it to the prompt. import guardrails as gd from rich import print guard = gd . Guard . from_rail_string ( rail_str ) The Guard object compiles the output schema and adds it to the prompt. We can see the final prompt below: print ( guard . base_prompt ) Given the following high level leetcode problem description, write a short Python code snippet that solves the problem. Problem Description: { leetcode_problem } Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <pythoncode name = \"python_code\" format = \"bug-free\" / > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter ` None `. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object: Step 3: Wrap the LLM API call with Guard import openai leetcode_problem = \"\"\" Given a string s, find the longest palindromic substring in s. You may assume that the maximum length of s is 1000. \"\"\" raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { \"leetcode_problem\" : leetcode_problem }, engine = \"text-davinci-003\" , max_tokens = 2048 , temperature = 0 , ) Running the cell above returns: 1. The raw LLM text output as a single string. 2. A dictionary where the key is python_code and the value is the generated code. print ( validated_response ) { 'python_code' : \"def longestPalindrome(s):\\n longest_palindrome = ''\\n for i in range(len(s)):\\n for j in range(i, len(s)):\\n substring = s[i:j+1]\\n if substring == substring[::-1] and len(substring) > len(longest_palindrome):\\n longest_palindrome = substring\\n return longest_palindrome\" } Here's the generated code: print ( validated_response [ \"python_code\" ]) def longestPalindrome ( s ) : longest_palindrome = '' for i in range ( len ( s )) : for j in range ( i, len ( s )) : substring = s if substring == substring [ :: -1 ] and len ( substring ) > len ( longest_palindrome ) : longest_palindrome = substring return longest_palindrome We can confirm that the code is bug free by executing the code in the environment. try : exec ( validated_response [ \"python_code\" ]) print ( \"Success!\" ) except Exception as e : print ( \"Failed!\" ) Success!","title":"Generating bug-free Python code"},{"location":"examples/bug_free_python_code/#generating-bug-free-leetcode-solutions","text":"Note To download this tutorial as a Jupyter notebook, click here . In this example, we want to solve String Maniuplation leetcode problems such that the code is bug free. We make the assumption that: We don't need any external libraries that are not already installed in the environment. We are able to execute the code in the environment.","title":"Generating Bug Free Leetcode Solutions"},{"location":"examples/bug_free_python_code/#objective","text":"We want to generate bug-free code for solving leetcode problems. In this example, we don't account for semantic bugs, only for syntactic bugs. In short, we want to make sure that the code can be executed without any errors.","title":"Objective"},{"location":"examples/bug_free_python_code/#step-1-generating-rail-spec","text":"Ordinarily, we could create a separate RAIL spec in a file. However, for the sake of this example, we will generate the RAIL spec in the notebook as a string. rail_str = \"\"\" <rail version=\"0.1\"> <output> <pythoncode name=\"python_code\" format=\"bug-free-python\" on-fail-bug-free-python=\"reask\" /> </output> <prompt> Given the following high level leetcode problem description, write a short Python code snippet that solves the problem. Problem Description: {{leetcode_problem}} @complete_json_suffix</prompt> </rail> \"\"\"","title":"Step 1: Generating RAIL Spec"},{"location":"examples/bug_free_python_code/#step-2-create-a-guard-object-with-the-rail-spec","text":"We create a gd.Guard object that will check, validate and correct the generated code. This object: Enforces the quality criteria specified in the RAIL spec (i.e. bug free code). Takes corrective action when the quality criteria are not met (i.e. reasking the LLM). Compiles the schema and type info from the RAIL spec and adds it to the prompt. import guardrails as gd from rich import print guard = gd . Guard . from_rail_string ( rail_str ) The Guard object compiles the output schema and adds it to the prompt. We can see the final prompt below: print ( guard . base_prompt ) Given the following high level leetcode problem description, write a short Python code snippet that solves the problem. Problem Description: { leetcode_problem } Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <pythoncode name = \"python_code\" format = \"bug-free\" / > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter ` None `. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object:","title":"Step 2: Create a Guard object with the RAIL Spec"},{"location":"examples/bug_free_python_code/#step-3-wrap-the-llm-api-call-with-guard","text":"import openai leetcode_problem = \"\"\" Given a string s, find the longest palindromic substring in s. You may assume that the maximum length of s is 1000. \"\"\" raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { \"leetcode_problem\" : leetcode_problem }, engine = \"text-davinci-003\" , max_tokens = 2048 , temperature = 0 , ) Running the cell above returns: 1. The raw LLM text output as a single string. 2. A dictionary where the key is python_code and the value is the generated code. print ( validated_response ) { 'python_code' : \"def longestPalindrome(s):\\n longest_palindrome = ''\\n for i in range(len(s)):\\n for j in range(i, len(s)):\\n substring = s[i:j+1]\\n if substring == substring[::-1] and len(substring) > len(longest_palindrome):\\n longest_palindrome = substring\\n return longest_palindrome\" } Here's the generated code: print ( validated_response [ \"python_code\" ]) def longestPalindrome ( s ) : longest_palindrome = '' for i in range ( len ( s )) : for j in range ( i, len ( s )) : substring = s if substring == substring [ :: -1 ] and len ( substring ) > len ( longest_palindrome ) : longest_palindrome = substring return longest_palindrome We can confirm that the code is bug free by executing the code in the environment. try : exec ( validated_response [ \"python_code\" ]) print ( \"Success!\" ) except Exception as e : print ( \"Failed!\" ) Success!","title":"Step 3: Wrap the LLM API call with Guard"},{"location":"examples/debug/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); rail_spec = \"\"\" <rail version=\"0.1\"> <script language=\"python\"> from guardrails.validators import Validator, EventDetail, register_validator from typing import Dict, List, Callable, Any, Optional, Union @register_validator(name=\"string-length\", data_type=[\"string\"]) class ValidLengthString(Validator): def __init__( self, min: int = None, max: int = None, on_fail: Optional[Callable] = None ): super().__init__(on_fail=on_fail) self._min = int(min) if min is not None else None self._max = int(max) if max is not None else None def validate(self, key: str, value: Any, schema: Union[Dict, List]) -> Dict: '''Validate that a value is within a range.''' print( f\"Validating {value} is in length range {self._min} - {self._max} ...\" ) if self._min is not None and len(value) &lt; self._min: print(f\"Value is less than {self._min} .\") # Repeat the last character to make the value the correct length. corrected_value = value + value[-1] * (self._min - len(value)) raise EventDetail( key, value, schema, f\"String ' {value} ' is too short. Create with a more verbose string shorter than 240 characters.\", corrected_value, ) if self._max is not None and len(value) &gt; self._max: print(f\"Value {value} is greater than {self._max} .\") raise EventDetail( key, value, schema, f\"String ' {value} ' is too long. Create a shorter string.\", value[: self._max], ) return schema </script> <output> <object name=\"bank_run\" format=\"length: 2\"> <string name=\"explanation\" description=\"A paragraph about what a bank run is.\" format=\"string-length: 200 240\" on-fail-string-length=\"reask\" /> <url name=\"follow_up_url\" description=\"A web URL where I can read more about bank runs.\" required=\"true\" format=\"valid-url\" on-fail-valid-url=\"filter\" /> </object> </output> <prompt> Explain what a bank run is in a tweet. @xml_prefix_prompt {output_schema} @json_suffix_prompt_v2_wo_none </prompt> </rail> \"\"\" import logging logging . basicConfig ( level = logging . DEBUG ) import guardrails as gd guard = gd . Guard . from_rail_string ( rail_spec , num_reasks = 1 ) Initializing ValidLength... Initializing ValidLengthString... Initializing ValidUrl... import openai import os os . environ [ 'OPENAI_API_KEY' ] = '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' raw_llm_output , validated_output = guard ( openai . Completion . create , engine = \"text-davinci-003\" , max_tokens = 1024 , temperature = 0.3 , ) /Users/shreyarajpal/anaconda3/envs/tiff-env/lib/python3.9/site-packages/eliot/json.py:22: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar. (This may have returned Python scalars in past versions. if isinstance(o, (numpy.bool, numpy.bool_)): DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/engines/text-davinci-003/completions DEBUG:openai:api_version=None data='{\"prompt\": \"\\\\nExplain what a bank run is in a tweet.\\\\n\\\\n\\\\nGiven below is XML that describes the information to extract from this document and the tags to extract it into.\\\\n\\\\n\\\\n<output>\\\\n <object name=\\\\\"bank_run\\\\\" format=\\\\\"length: \\\\\">\\\\n <string name=\\\\\"explanation\\\\\" description=\\\\\"A paragraph about what a bank run is.\\\\\" format=\\\\\"string-length: 200 240\\\\\"/>\\\\n <url name=\\\\\"follow_up_url\\\\\" description=\\\\\"A web URL where I can read more about bank runs.\\\\\" required=\\\\\"true\\\\\" format=\\\\\"valid-url\\\\\"/>\\\\n </object>\\\\n</output>\\\\n\\\\n\\\\nONLY return a valid JSON object (no other text is necessary). The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise.\\\\n\\\\nJSON Output:\\\\n\\\\n\", \"max_tokens\": 1024, \"temperature\": 0.3}' message='Post details' DEBUG:urllib3.connectionpool:Resetting dropped connection: api.openai.com DEBUG:urllib3.connectionpool:https://api.openai.com:443 \"POST /v1/engines/text-davinci-003/completions HTTP/1.1\" 200 581 DEBUG:openai:message='OpenAI API response' path=https://api.openai.com/v1/engines/text-davinci-003/completions processing_ms=3375 request_id=77c1220319671fea308e91ad3d235c58 response_code=200 DEBUG:guardrails.validators:Validating {'explanation': 'A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail.', 'follow_up_url': 'https://www.investopedia.com/terms/b/bankrun.asp'} is in length range 2 - None... DEBUG:guardrails.validators:Validator ValidLengthString failed for explanation with error ('explanation', 'A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail.', {'explanation': 'A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail.', 'follow_up_url': 'https://www.investopedia.com/terms/b/bankrun.asp'}, \"String 'A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail.' is too short. Create with a more verbose string.\", 'A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail...............'). DEBUG:guardrails.validators:Validating https://www.investopedia.com/terms/b/bankrun.asp is a valid URL... DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): www.investopedia.com:443 Validating bank_run with ValidLength... Validating explanation with ValidLengthString... Validating A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail. is in length range 200 - 240... Value is less than 200. Validator ValidLengthString failed for explanation with error ('explanation', 'A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail.', {'explanation': 'A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail.', 'follow_up_url': 'https://www.investopedia.com/terms/b/bankrun.asp'}, \"String 'A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail.' is too short. Create with a more verbose string.\", 'A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail...............'). Validating follow_up_url with ValidUrl... DEBUG:urllib3.connectionpool:https://www.investopedia.com:443 \"GET /terms/b/bankrun.asp HTTP/1.1\" 200 None DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/engines/text-davinci-003/completions DEBUG:openai:api_version=None data='{\"prompt\": \"\\\\nI was given the following JSON response, which had problems due to incorrect values.\\\\n\\\\n{\\\\n \\\\\"bank_run\\\\\": {\\\\n \\\\\"explanation\\\\\": {\\\\n \\\\\"incorrect_value\\\\\": \\\\\"A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail.\\\\\",\\\\n \\\\\"error_message\\\\\": \\\\\"String \\'A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail.\\' is too short. Create with a more verbose string.\\\\\"\\\\n }\\\\n }\\\\n}\\\\n\\\\nHelp me correct the incorrect values based on the given error messages.\\\\n\\\\nGiven below is XML that describes the information to extract from this document and the tags to extract it into.\\\\n\\\\n<output>\\\\n <object name=\\\\\"bank_run\\\\\">\\\\n <string name=\\\\\"explanation\\\\\" description=\\\\\"A paragraph about what a bank run is.\\\\\" format=\\\\\"string-length: 200 240\\\\\"/>\\\\n </object>\\\\n</output>\\\\n\\\\nONLY return a valid JSON object (no other text is necessary), where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML\\'s tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter `None`.\\\\n\\\\nHere are examples of simple (XML, JSON) pairs that show the expected behavior:\\\\n- `<string name=\\'foo\\' format=\\'two-words lower-case\\' />` => `{{\\'foo\\': \\'example one\\'}}`\\\\n- `<list name=\\'bar\\'><string format=\\'upper-case\\' /></list>` => `{{\\\\\"bar\\\\\": [\\'STRING ONE\\', \\'STRING TWO\\', etc.]}}`\\\\n- `<object name=\\'baz\\'><string name=\\\\\"foo\\\\\" format=\\\\\"capitalize two-words\\\\\" /><integer name=\\\\\"index\\\\\" format=\\\\\"1-indexed\\\\\" /></object>` => `{{\\'baz\\': {{\\'foo\\': \\'Some String\\', \\'index\\': 1}}}}`\\\\n\\\\nJSON Object:\", \"max_tokens\": 1024, \"temperature\": 0.3}' message='Post details' Initializing ValidLengthString... Initializing ValidLengthString... DEBUG:urllib3.connectionpool:https://api.openai.com:443 \"POST /v1/engines/text-davinci-003/completions HTTP/1.1\" 200 582 DEBUG:openai:message='OpenAI API response' path=https://api.openai.com/v1/engines/text-davinci-003/completions processing_ms=2467 request_id=243e91e74abd0cb81d40c3e62d74cf1a response_code=200 DEBUG:guardrails.validators:Validator ValidLengthString failed for explanation with error ('explanation', \"A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail, resulting in significant losses for the bank's customers and shareholders.\", {'explanation': \"A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail, resulting in significant losses for the bank's customers and shareholders.\"}, \"String 'A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail, resulting in significant losses for the bank's customers and shareholders.' is too long. Create a shorter string.\", \"A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail, resulting in significant losses for the bank's custom\"). Validating explanation with ValidLengthString... Validating A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail, resulting in significant losses for the bank's customers and shareholders. is in length range 200 - 240... Value A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail, resulting in significant losses for the bank's customers and shareholders. is greater than 240. Validator ValidLengthString failed for explanation with error ('explanation', \"A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail, resulting in significant losses for the bank's customers and shareholders.\", {'explanation': \"A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail, resulting in significant losses for the bank's customers and shareholders.\"}, \"String 'A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail, resulting in significant losses for the bank's customers and shareholders.' is too long. Create a shorter string.\", \"A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail, resulting in significant losses for the bank's custom\"). len ( validated_output [ 'bank_run' ][ 'explanation' ]) 240 validated_output [ 'bank_run' ][ 'explanation' ] \"A bank run is when a large number of customers withdraw their deposits from a bank due to concerns about its solvency. This can lead to a liquidity crisis and can cause the bank to fail, resulting in significant losses for the bank's custom\" len ( guard . state . most_recent_call . history ) 2 guard . state . most_recent_call . history [ 1 ] . validated_output {'bank_run': {'explanation': \"A bank run occurs when a large number of customers withdraw their deposits from a bank due to concerns about the bank's solvency........................................................................\", 'follow_up_url': 'https://www.investopedia.com/terms/b/bankrun.asp'}} print ( guard . state . most_recent_call . history [ 1 ] . validated_output ) {'bank_run': {'explanation': \"A bank run occurs when a large number of customers withdraw their deposits from a bank due to concerns about the bank's solvency........................................................................\", 'follow_up_url': 'https://www.investopedia.com/terms/b/bankrun.asp'}} print ( guard . state . most_recent_call . history [ - 1 ] . output_as_dict [ 'bank_run' ][ 'explanation' ]) A bank run occurs when a large number of customers withdraw their deposits from a bank due to concerns about the bank's solvency. print ( len ( guard . state . most_recent_call . history )) 2","title":"Debug"},{"location":"examples/extracting_entities/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Extracting entities from a Terms of Service document Note To download this example as a Jupyter notebook, click here . In this example, we will use Guardrails to extract key information from a Terms-of-Service document. Objective We want to extract structured information about all fees and interest rates associated with the Chase credit card. Step 0: Download PDF and load it as string To get started, download the document from here and save it in data/chase_card_agreement.pdf . Guardrails has some built-in functions to help with common tasks. Here, we will use the read_pdf function to load the PDF as a string. import guardrails as gd from rich import print content = gd . docs_utils . read_pdf ( \"data/chase_card_agreement.pdf\" ) print ( f \"Chase Credit Card Document: \\n\\n { content [: 275 ] } \\n ...\" ) Chase Credit Card Document: 2 / 25 / 23 , 7:59 PM about:blank about:blank 1 / 4 PRICING INFORMATION INTEREST RATES AND INTEREST CHARGES Purchase Annual Percentage Rate ( APR ) 0 % Intro APR for the first 18 months that your Account is open. After that, 19.49 %. This APR will vary with the market based on th ... Step 1: Create the RAIL Spec Ordinarily, we would create an RAIL spec in a separate file. For the purposes of this example, we will create the spec in this notebook as a string following the RAIL syntax. For more information on RAIL, see the RAIL documentation . Here, we request: A list of the fees associated with the card. We ask for sub-information, each with its own quality criteria and corrective action. A object (i.e. key-value pairs) for the interest. rail_str = \"\"\" <rail version=\"0.1\"> <output> <list name=\"fees\" description=\"What fees and charges are associated with my account?\"> <object> <integer name=\"index\" format=\"1-indexed\" /> <string name=\"name\" format=\"lower-case; two-words\" on-fail-lower-case=\"noop\" on-fail-two-words=\"reask\"/> <string name=\"explanation\" format=\"one-line\" on-fail-one-line=\"noop\" /> <float name=\"value\" format=\"percentage\"/> </object> </list> <object name=\"interest_rates\" description=\"What are the interest rates offered by the bank on savings and checking accounts, loans, and credit products?\" /> </output> <prompt> Given the following document, answer the following questions. If the answer doesn't exist in the document, enter 'None'. {{document}} @xml_prefix_prompt {output_schema} @json_suffix_prompt_v2_wo_none</prompt> </rail> \"\"\" Step 2: Create a Guard object with the RAIL Spec We create a gd.Guard object that will check, validate and correct the output of the LLM. This object: Enforces the quality criteria specified in the RAIL spec. Takes corrective action when the quality criteria are not met. Compiles the schema and type info from the RAIL spec and adds it to the prompt. guard = gd . Guard . from_rail_string ( rail_str ) /Users/shreyarajpal/guardrails/guardrails/datatypes.py:53: UserWarning: Formatter 1-indexed is not valid for element integer. warnings.warn( /Users/shreyarajpal/guardrails/guardrails/datatypes.py:53: UserWarning: Formatter percentage is not valid for element float. warnings.warn( As we can see, a few formatters weren't supported. These formatters won't be enforced in the output, but this information can still be used to generate a prompt. We see the prompt that will be sent to the LLM. The {document} is substituted with the user provided value at runtime. print ( guard . base_prompt ) Given the following document, answer the following questions. If the answer doesn't exist in the document, enter 'None' . { document } Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <list name = \"fees\" description = \"What fees and charges are associated with my account?\" > <object> <integer name = \"index\" format = \"1-indexed\" / > <string name = \"name\" format = \"lower-case; two-words\" / > <string name = \"explanation\" format = \"one-line\" / > <float name = \"value\" format = \"percentage\" / > < / object > < / list > <object name = \"interest_rates\" description = \"What are the interest rates offered by the bank on savings and checking accounts, loans, and credit products?\" / > < / output > ONLY return a valid JSON object ( no other text is necessary ) . The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. JSON Output: Step 3: Wrap the LLM API call with Guard import openai raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { \"document\" : content [: 6000 ]}, engine = \"text-davinci-003\" , max_tokens = 2048 , temperature = 0 , ) The guard wrapper returns the raw_llm_respose (which is a simple string), and the validated and corrected output (which is a dictionary). We can see that the output is a dictionary with the correct schema and types. print ( validated_response ) { 'fees' : [ { 'index' : 1 , 'name' : 'annual membership' , 'explanation' : 'none' , 'value' : 0 } , { 'index' : 2 , 'name' : 'fee one' , 'explanation' : 'monthly fee of 0% of the amount of each eligible purchase transaction or amount selected to create a My Chase Plan while in the 0% Intro Purchase APR period. After that, monthly fee of 1.72% of the amount of each eligible purchase transaction or amount selected to create a My Chase Plan.' , 'value' : 1.72 } , { 'index' : 3 , 'name' : 'balance transfers' , 'explanation' : 'intro fee of either $5 or 3% of the amount of each transfer, whichever is greater, on transfers made within 60 days of account opening. After that: Either $5 or 5% of the amount of each transfer, whichever is greater.' , 'value' : 5 } , { 'index' : 4 , 'name' : 'cash advances' , 'explanation' : 'either $10 or 5% of the amount of each transaction, whichever is greater.' , 'value' : 5 } , { 'index' : 5 , 'name' : 'foreign transactions' , 'explanation' : '3% of the amount of each transaction in U.S. dollars.' , 'value' : 3 } , { 'index' : 6 , 'name' : 'late payment' , 'explanation' : 'up to $40.' , 'value' : 0 } , { 'index' : 7 , 'name' : 'fee two' , 'explanation' : 'none' , 'value' : 0 } , { 'index' : 8 , 'name' : 'return payment' , 'explanation' : 'up to $40.' , 'value' : 0 } , { 'index' : 9 , 'name' : 'return check' , 'explanation' : 'none' , 'value' : 0 } ] , 'interest_rates' : { 'purchase' : { 'apr' : 0 , 'explanation' : '0% Intro APR for the first 18 months that your Account is open. After that, 19.49%. This APR will vary with the market based on the Prime Rate.' } , 'my_chase_loan' : { 'apr' : 19.49 , 'explanation' : '19.49%. This APR will vary with the market based on the Prime Rate.' } , 'balance_transfer' : { 'apr' : 0 , 'explanation' : '0% Intro APR for the first 18 months that your Account is open. After that, 19.49%. This APR will vary with the market based on the Prime Rate.' } , 'cash_advance' : { 'apr' : 29.49 , 'explanation' : '29.49%. This APR will vary with the market based on the Prime Rate.' } , 'penalty' : { 'apr' : 29.99 , 'explanation' : 'Up to 29.99%. This APR will vary with the market based on the Prime Rate.' } , 'prime_rate' : 7.75 } }","title":"Extracting entities from ToS"},{"location":"examples/extracting_entities/#extracting-entities-from-a-terms-of-service-document","text":"Note To download this example as a Jupyter notebook, click here . In this example, we will use Guardrails to extract key information from a Terms-of-Service document.","title":"Extracting entities from a Terms of Service document"},{"location":"examples/extracting_entities/#objective","text":"We want to extract structured information about all fees and interest rates associated with the Chase credit card.","title":"Objective"},{"location":"examples/extracting_entities/#step-0-download-pdf-and-load-it-as-string","text":"To get started, download the document from here and save it in data/chase_card_agreement.pdf . Guardrails has some built-in functions to help with common tasks. Here, we will use the read_pdf function to load the PDF as a string. import guardrails as gd from rich import print content = gd . docs_utils . read_pdf ( \"data/chase_card_agreement.pdf\" ) print ( f \"Chase Credit Card Document: \\n\\n { content [: 275 ] } \\n ...\" ) Chase Credit Card Document: 2 / 25 / 23 , 7:59 PM about:blank about:blank 1 / 4 PRICING INFORMATION INTEREST RATES AND INTEREST CHARGES Purchase Annual Percentage Rate ( APR ) 0 % Intro APR for the first 18 months that your Account is open. After that, 19.49 %. This APR will vary with the market based on th ...","title":"Step 0: Download PDF and load it as string"},{"location":"examples/extracting_entities/#step-1-create-the-rail-spec","text":"Ordinarily, we would create an RAIL spec in a separate file. For the purposes of this example, we will create the spec in this notebook as a string following the RAIL syntax. For more information on RAIL, see the RAIL documentation . Here, we request: A list of the fees associated with the card. We ask for sub-information, each with its own quality criteria and corrective action. A object (i.e. key-value pairs) for the interest. rail_str = \"\"\" <rail version=\"0.1\"> <output> <list name=\"fees\" description=\"What fees and charges are associated with my account?\"> <object> <integer name=\"index\" format=\"1-indexed\" /> <string name=\"name\" format=\"lower-case; two-words\" on-fail-lower-case=\"noop\" on-fail-two-words=\"reask\"/> <string name=\"explanation\" format=\"one-line\" on-fail-one-line=\"noop\" /> <float name=\"value\" format=\"percentage\"/> </object> </list> <object name=\"interest_rates\" description=\"What are the interest rates offered by the bank on savings and checking accounts, loans, and credit products?\" /> </output> <prompt> Given the following document, answer the following questions. If the answer doesn't exist in the document, enter 'None'. {{document}} @xml_prefix_prompt {output_schema} @json_suffix_prompt_v2_wo_none</prompt> </rail> \"\"\"","title":"Step 1: Create the RAIL Spec"},{"location":"examples/extracting_entities/#step-2-create-a-guard-object-with-the-rail-spec","text":"We create a gd.Guard object that will check, validate and correct the output of the LLM. This object: Enforces the quality criteria specified in the RAIL spec. Takes corrective action when the quality criteria are not met. Compiles the schema and type info from the RAIL spec and adds it to the prompt. guard = gd . Guard . from_rail_string ( rail_str ) /Users/shreyarajpal/guardrails/guardrails/datatypes.py:53: UserWarning: Formatter 1-indexed is not valid for element integer. warnings.warn( /Users/shreyarajpal/guardrails/guardrails/datatypes.py:53: UserWarning: Formatter percentage is not valid for element float. warnings.warn( As we can see, a few formatters weren't supported. These formatters won't be enforced in the output, but this information can still be used to generate a prompt. We see the prompt that will be sent to the LLM. The {document} is substituted with the user provided value at runtime. print ( guard . base_prompt ) Given the following document, answer the following questions. If the answer doesn't exist in the document, enter 'None' . { document } Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <list name = \"fees\" description = \"What fees and charges are associated with my account?\" > <object> <integer name = \"index\" format = \"1-indexed\" / > <string name = \"name\" format = \"lower-case; two-words\" / > <string name = \"explanation\" format = \"one-line\" / > <float name = \"value\" format = \"percentage\" / > < / object > < / list > <object name = \"interest_rates\" description = \"What are the interest rates offered by the bank on savings and checking accounts, loans, and credit products?\" / > < / output > ONLY return a valid JSON object ( no other text is necessary ) . The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. JSON Output:","title":"Step 2: Create a Guard object with the RAIL Spec"},{"location":"examples/extracting_entities/#step-3-wrap-the-llm-api-call-with-guard","text":"import openai raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { \"document\" : content [: 6000 ]}, engine = \"text-davinci-003\" , max_tokens = 2048 , temperature = 0 , ) The guard wrapper returns the raw_llm_respose (which is a simple string), and the validated and corrected output (which is a dictionary). We can see that the output is a dictionary with the correct schema and types. print ( validated_response ) { 'fees' : [ { 'index' : 1 , 'name' : 'annual membership' , 'explanation' : 'none' , 'value' : 0 } , { 'index' : 2 , 'name' : 'fee one' , 'explanation' : 'monthly fee of 0% of the amount of each eligible purchase transaction or amount selected to create a My Chase Plan while in the 0% Intro Purchase APR period. After that, monthly fee of 1.72% of the amount of each eligible purchase transaction or amount selected to create a My Chase Plan.' , 'value' : 1.72 } , { 'index' : 3 , 'name' : 'balance transfers' , 'explanation' : 'intro fee of either $5 or 3% of the amount of each transfer, whichever is greater, on transfers made within 60 days of account opening. After that: Either $5 or 5% of the amount of each transfer, whichever is greater.' , 'value' : 5 } , { 'index' : 4 , 'name' : 'cash advances' , 'explanation' : 'either $10 or 5% of the amount of each transaction, whichever is greater.' , 'value' : 5 } , { 'index' : 5 , 'name' : 'foreign transactions' , 'explanation' : '3% of the amount of each transaction in U.S. dollars.' , 'value' : 3 } , { 'index' : 6 , 'name' : 'late payment' , 'explanation' : 'up to $40.' , 'value' : 0 } , { 'index' : 7 , 'name' : 'fee two' , 'explanation' : 'none' , 'value' : 0 } , { 'index' : 8 , 'name' : 'return payment' , 'explanation' : 'up to $40.' , 'value' : 0 } , { 'index' : 9 , 'name' : 'return check' , 'explanation' : 'none' , 'value' : 0 } ] , 'interest_rates' : { 'purchase' : { 'apr' : 0 , 'explanation' : '0% Intro APR for the first 18 months that your Account is open. After that, 19.49%. This APR will vary with the market based on the Prime Rate.' } , 'my_chase_loan' : { 'apr' : 19.49 , 'explanation' : '19.49%. This APR will vary with the market based on the Prime Rate.' } , 'balance_transfer' : { 'apr' : 0 , 'explanation' : '0% Intro APR for the first 18 months that your Account is open. After that, 19.49%. This APR will vary with the market based on the Prime Rate.' } , 'cash_advance' : { 'apr' : 29.49 , 'explanation' : '29.49%. This APR will vary with the market based on the Prime Rate.' } , 'penalty' : { 'apr' : 29.99 , 'explanation' : 'Up to 29.99%. This APR will vary with the market based on the Prime Rate.' } , 'prime_rate' : 7.75 } }","title":"Step 3: Wrap the LLM API call with Guard"},{"location":"examples/generate_structured_data/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Generating Structured Synthetic Data Note To download this tutorial as a Jupyter notebook, click here . In this example, we'll generate structured dummy data for a pandas dataframe. We make the assumption that: We don't need any external libraries that are not already installed in the environment. We are able to execute the code in the environment. Objective We want to generate structured synthetic data, where each column has a specific data type. All rows in the dataset must respect the column data types. Additionally, we have some more constraints we want the data to respect: There should be exactly 10 rows in the dataset. Each user should have a first name and a last name. The number of orders associated with each user should be between 0 and 50. Each user should have a most recent order date. Step 1: Generating RAIL Spec Ordinarily, we could create a separate RAIL spec in a file. However, for the sake of this example, we will generate the RAIL spec in the notebook as a string. rail_str = \"\"\" <rail version=\"0.1\"> <output> <list name=\"user_orders\" description=\"Generate a list of user, and how many orders they have placed in the past.\" format=\"length: 10 10\" on-fail-length=\"noop\"> <object> <string name=\"user_id\" description=\"The user's id.\" format=\"1-indexed\" /> <string name=\"user_name\" description=\"The user's first name and last name\" format=\"two-words\" /> <integer name=\"num_orders\" description=\"The number of orders the user has placed\" format=\"valid-range: 0 50\" /> <date name=\"last_order_date\" description=\"Date of last order\" /> </object> </list> </output> <prompt> Generate a dataset of fake user orders. Each row of the dataset should be valid. @complete_json_suffix</prompt> </rail> \"\"\" Step 2: Create a Guard object with the RAIL Spec We create a gd.Guard object that will check, validate and correct the generated code. This object: Enforces the quality criteria specified in the RAIL spec (i.e. bug free code). Takes corrective action when the quality criteria are not met (i.e. reasking the LLM). Compiles the schema and type info from the RAIL spec and adds it to the prompt. import guardrails as gd from rich import print guard = gd . Guard . from_rail_string ( rail_str ) The Guard object compiles the output schema and adds it to the prompt. We can see the final prompt below: print ( guard . base_prompt ) Generate a dataset of fake user orders. Each row of the dataset should be valid. Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <list name = \"user_orders\" description = \"Generate a list of user, and how many orders they have placed in the past.\" format = \"length: 10 10\" > <object> <string name = \"user_id\" description = \"The user's id.\" format = \"1-indexed\" / > <string name = \"user_name\" description = \"The user's first name and last name\" format = \"two-words\" / > <integer name = \"num_orders\" description = \"The number of orders the user has placed\" format = \"valid-range: 0 50\" / > <date name = \"last_order_date\" description = \"Date of last order\" / > < / object > < / list > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter ` None `. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object: Step 3: Wrap the LLM API call with Guard import openai raw_llm_response , validated_response = guard ( openai . Completion . create , engine = \"text-davinci-003\" , max_tokens = 2048 , temperature = 0 ) Running the cell above returns: 1. The raw LLM text output as a single string. 2. A dictionary where the key user_orders key contains a list of dictionaries, where each dictionary represents a row in the dataframe. print ( validated_response ) { 'user_orders' : [ { 'user_id' : 1 , 'user_name' : 'John Smith' , 'num_orders' : 10 , 'last_order_date' : '2020-05-01' } , { 'user_id' : 2 , 'user_name' : 'Jane Doe' , 'num_orders' : 15 , 'last_order_date' : '2020-04-15' } , { 'user_id' : 3 , 'user_name' : 'James Johnson' , 'num_orders' : 20 , 'last_order_date' : '2020-03-30' } , { 'user_id' : 4 , 'user_name' : 'Mary Williams' , 'num_orders' : 25 , 'last_order_date' : '2020-03-15' } , { 'user_id' : 5 , 'user_name' : 'Robert Brown' , 'num_orders' : 30 , 'last_order_date' : '2020-02-28' } , { 'user_id' : 6 , 'user_name' : 'Michael Miller' , 'num_orders' : 35 , 'last_order_date' : '2020-02-15' } , { 'user_id' : 7 , 'user_name' : 'Linda Davis' , 'num_orders' : 40 , 'last_order_date' : '2020-01-31' } , { 'user_id' : 8 , 'user_name' : 'William Anderson' , 'num_orders' : 45 , 'last_order_date' : '2020-01-15' } , { 'user_id' : 9 , 'user_name' : 'David Taylor' , 'num_orders' : 48 , 'last_order_date' : '2019-12-31' } , { 'user_id' : 10 , 'user_name' : 'Joseph Thomas' , 'num_orders' : 50 , 'last_order_date' : '2019-12-15' } ] }","title":"Generate structured synthetic data"},{"location":"examples/generate_structured_data/#generating-structured-synthetic-data","text":"Note To download this tutorial as a Jupyter notebook, click here . In this example, we'll generate structured dummy data for a pandas dataframe. We make the assumption that: We don't need any external libraries that are not already installed in the environment. We are able to execute the code in the environment.","title":"Generating Structured Synthetic Data"},{"location":"examples/generate_structured_data/#objective","text":"We want to generate structured synthetic data, where each column has a specific data type. All rows in the dataset must respect the column data types. Additionally, we have some more constraints we want the data to respect: There should be exactly 10 rows in the dataset. Each user should have a first name and a last name. The number of orders associated with each user should be between 0 and 50. Each user should have a most recent order date.","title":"Objective"},{"location":"examples/generate_structured_data/#step-1-generating-rail-spec","text":"Ordinarily, we could create a separate RAIL spec in a file. However, for the sake of this example, we will generate the RAIL spec in the notebook as a string. rail_str = \"\"\" <rail version=\"0.1\"> <output> <list name=\"user_orders\" description=\"Generate a list of user, and how many orders they have placed in the past.\" format=\"length: 10 10\" on-fail-length=\"noop\"> <object> <string name=\"user_id\" description=\"The user's id.\" format=\"1-indexed\" /> <string name=\"user_name\" description=\"The user's first name and last name\" format=\"two-words\" /> <integer name=\"num_orders\" description=\"The number of orders the user has placed\" format=\"valid-range: 0 50\" /> <date name=\"last_order_date\" description=\"Date of last order\" /> </object> </list> </output> <prompt> Generate a dataset of fake user orders. Each row of the dataset should be valid. @complete_json_suffix</prompt> </rail> \"\"\"","title":"Step 1: Generating RAIL Spec"},{"location":"examples/generate_structured_data/#step-2-create-a-guard-object-with-the-rail-spec","text":"We create a gd.Guard object that will check, validate and correct the generated code. This object: Enforces the quality criteria specified in the RAIL spec (i.e. bug free code). Takes corrective action when the quality criteria are not met (i.e. reasking the LLM). Compiles the schema and type info from the RAIL spec and adds it to the prompt. import guardrails as gd from rich import print guard = gd . Guard . from_rail_string ( rail_str ) The Guard object compiles the output schema and adds it to the prompt. We can see the final prompt below: print ( guard . base_prompt ) Generate a dataset of fake user orders. Each row of the dataset should be valid. Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <list name = \"user_orders\" description = \"Generate a list of user, and how many orders they have placed in the past.\" format = \"length: 10 10\" > <object> <string name = \"user_id\" description = \"The user's id.\" format = \"1-indexed\" / > <string name = \"user_name\" description = \"The user's first name and last name\" format = \"two-words\" / > <integer name = \"num_orders\" description = \"The number of orders the user has placed\" format = \"valid-range: 0 50\" / > <date name = \"last_order_date\" description = \"Date of last order\" / > < / object > < / list > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter ` None `. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object:","title":"Step 2: Create a Guard object with the RAIL Spec"},{"location":"examples/generate_structured_data/#step-3-wrap-the-llm-api-call-with-guard","text":"import openai raw_llm_response , validated_response = guard ( openai . Completion . create , engine = \"text-davinci-003\" , max_tokens = 2048 , temperature = 0 ) Running the cell above returns: 1. The raw LLM text output as a single string. 2. A dictionary where the key user_orders key contains a list of dictionaries, where each dictionary represents a row in the dataframe. print ( validated_response ) { 'user_orders' : [ { 'user_id' : 1 , 'user_name' : 'John Smith' , 'num_orders' : 10 , 'last_order_date' : '2020-05-01' } , { 'user_id' : 2 , 'user_name' : 'Jane Doe' , 'num_orders' : 15 , 'last_order_date' : '2020-04-15' } , { 'user_id' : 3 , 'user_name' : 'James Johnson' , 'num_orders' : 20 , 'last_order_date' : '2020-03-30' } , { 'user_id' : 4 , 'user_name' : 'Mary Williams' , 'num_orders' : 25 , 'last_order_date' : '2020-03-15' } , { 'user_id' : 5 , 'user_name' : 'Robert Brown' , 'num_orders' : 30 , 'last_order_date' : '2020-02-28' } , { 'user_id' : 6 , 'user_name' : 'Michael Miller' , 'num_orders' : 35 , 'last_order_date' : '2020-02-15' } , { 'user_id' : 7 , 'user_name' : 'Linda Davis' , 'num_orders' : 40 , 'last_order_date' : '2020-01-31' } , { 'user_id' : 8 , 'user_name' : 'William Anderson' , 'num_orders' : 45 , 'last_order_date' : '2020-01-15' } , { 'user_id' : 9 , 'user_name' : 'David Taylor' , 'num_orders' : 48 , 'last_order_date' : '2019-12-31' } , { 'user_id' : 10 , 'user_name' : 'Joseph Thomas' , 'num_orders' : 50 , 'last_order_date' : '2019-12-15' } ] }","title":"Step 3: Wrap the LLM API call with Guard"},{"location":"examples/no_secrets_in_generated_text/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Generating strings that don't have any secrets Note To download this example as a Jupyter notebook, click here . In this example, we will use Guardrails to generate strings that don't have any secrets. This is also a good example to show how to use the script element of the RAIL specification. In this case, we will use the script element to create a custom Validator that checks if a string has any secrets. Objective We want to ask help with an API, but make sure that the generated text has no secrets. Step 1: Create the RAIL Spec Ordinarily, we would create an RAIL spec in a separate file. For the purposes of this example, we will create the spec in this notebook as a string following the RAIL syntax. For more information on RAIL, see the RAIL documentation . In this RAIL spec, we: Create a script element that creates a custom Validator that checks if a string has any secrets. This is a simple example, but you can use this to create more complex Validators. For more information on creating custom Validators, see the Validators documentation . Create a output schema that returns an object with a api_help key. rail_str = \"\"\" <rail version=\"0.1\"> <script language='python'> from dataclasses import dataclass from guardrails.validators import Validator, EventDetail, register_validator import re from typing import Dict, List OPENAI_KEY_PATTERN = re.compile(r\"sk-[a-zA-Z0-9] {24} \") @register_validator(name=\"no-code-secrets\", data_type=\"string\") class NoCodeSecrets(Validator): def validate(self, key, value, schema) -> Dict: global OPENAI_KEY_PATTERN if re.search(OPENAI_KEY_PATTERN, value) is not None: # Corrected value should replace the OpenAI API key with \"sk-xxx\" correct_value = re.sub(OPENAI_KEY_PATTERN, \"sk-xxx\", value) raise EventDetail( key, value, schema, f\"Value {value} is an OpenAI API key.\", correct_value, ) return schema </script> <output> <string name=\"api_help\" description=\"Show an example curl command for using openai Completion API\" format=\"no-code-secrets\" on-fail-no-code-secrets=\"fix\" /> </output> <prompt> How do I use OpenAI's Completion API? @complete_json_suffix </prompt> </rail> \"\"\" Step 2: Create a Guard object with the RAIL Spec We create a gd.Guard object that will check, validate and correct the output of the LLM. This object: Enforces the quality criteria specified in the RAIL spec. Takes corrective action when the quality criteria are not met. Compiles the schema and type info from the RAIL spec and adds it to the prompt. import guardrails as gd from rich import print guard = gd . Guard . from_rail_string ( rail_str ) We see the prompt that will be sent to the LLM. print ( guard . base_prompt ) How do I use OpenAI's Completion API? Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <string name = \"api_help\" description = \"Show an example curl command for using openai Completion API\" format = \"no-code-secrets\" / > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter ` None `. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object: Step 3: Wrap the LLM API call with Guard import openai raw_llm_response , validated_response = guard ( openai . Completion . create , engine = \"text-davinci-003\" , max_tokens = 2048 , temperature = 0 ) The guard wrapper returns the raw_llm_respose (which is a simple string), and the validated and corrected output (which is a dictionary). We can see that the output is a dictionary with the correct schema and types. print ( validated_response ) { 'api_help' : 'curl -X POST -H \\'Content-Type: application/json\\' -d \\'{\"prompt\": \"The quick brown fox\", \"max_tokens\": 10}\\' https://api.openai.com/v1/engines/completion/completions' }","title":"No secrets in generated text"},{"location":"examples/no_secrets_in_generated_text/#generating-strings-that-dont-have-any-secrets","text":"Note To download this example as a Jupyter notebook, click here . In this example, we will use Guardrails to generate strings that don't have any secrets. This is also a good example to show how to use the script element of the RAIL specification. In this case, we will use the script element to create a custom Validator that checks if a string has any secrets.","title":"Generating strings that don't have any secrets"},{"location":"examples/no_secrets_in_generated_text/#objective","text":"We want to ask help with an API, but make sure that the generated text has no secrets.","title":"Objective"},{"location":"examples/no_secrets_in_generated_text/#step-1-create-the-rail-spec","text":"Ordinarily, we would create an RAIL spec in a separate file. For the purposes of this example, we will create the spec in this notebook as a string following the RAIL syntax. For more information on RAIL, see the RAIL documentation . In this RAIL spec, we: Create a script element that creates a custom Validator that checks if a string has any secrets. This is a simple example, but you can use this to create more complex Validators. For more information on creating custom Validators, see the Validators documentation . Create a output schema that returns an object with a api_help key. rail_str = \"\"\" <rail version=\"0.1\"> <script language='python'> from dataclasses import dataclass from guardrails.validators import Validator, EventDetail, register_validator import re from typing import Dict, List OPENAI_KEY_PATTERN = re.compile(r\"sk-[a-zA-Z0-9] {24} \") @register_validator(name=\"no-code-secrets\", data_type=\"string\") class NoCodeSecrets(Validator): def validate(self, key, value, schema) -> Dict: global OPENAI_KEY_PATTERN if re.search(OPENAI_KEY_PATTERN, value) is not None: # Corrected value should replace the OpenAI API key with \"sk-xxx\" correct_value = re.sub(OPENAI_KEY_PATTERN, \"sk-xxx\", value) raise EventDetail( key, value, schema, f\"Value {value} is an OpenAI API key.\", correct_value, ) return schema </script> <output> <string name=\"api_help\" description=\"Show an example curl command for using openai Completion API\" format=\"no-code-secrets\" on-fail-no-code-secrets=\"fix\" /> </output> <prompt> How do I use OpenAI's Completion API? @complete_json_suffix </prompt> </rail> \"\"\"","title":"Step 1: Create the RAIL Spec"},{"location":"examples/no_secrets_in_generated_text/#step-2-create-a-guard-object-with-the-rail-spec","text":"We create a gd.Guard object that will check, validate and correct the output of the LLM. This object: Enforces the quality criteria specified in the RAIL spec. Takes corrective action when the quality criteria are not met. Compiles the schema and type info from the RAIL spec and adds it to the prompt. import guardrails as gd from rich import print guard = gd . Guard . from_rail_string ( rail_str ) We see the prompt that will be sent to the LLM. print ( guard . base_prompt ) How do I use OpenAI's Completion API? Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <string name = \"api_help\" description = \"Show an example curl command for using openai Completion API\" format = \"no-code-secrets\" / > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter ` None `. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object:","title":"Step 2: Create a Guard object with the RAIL Spec"},{"location":"examples/no_secrets_in_generated_text/#step-3-wrap-the-llm-api-call-with-guard","text":"import openai raw_llm_response , validated_response = guard ( openai . Completion . create , engine = \"text-davinci-003\" , max_tokens = 2048 , temperature = 0 ) The guard wrapper returns the raw_llm_respose (which is a simple string), and the validated and corrected output (which is a dictionary). We can see that the output is a dictionary with the correct schema and types. print ( validated_response ) { 'api_help' : 'curl -X POST -H \\'Content-Type: application/json\\' -d \\'{\"prompt\": \"The quick brown fox\", \"max_tokens\": 10}\\' https://api.openai.com/v1/engines/completion/completions' }","title":"Step 3: Wrap the LLM API call with Guard"},{"location":"examples/recipe_generation/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Generating Vegan Recipes Note To download this example as a Jupyter notebook, click here . In this example, we will use Guardrails to generate vegan mac and cheese recipe. Objective We want to generate a vegan Mac-n-Cheese recipe as a list of ingredients and instructions. We will use Guardrails to make sure the recipe is vegan. import guardrails as gd from rich import print Step 1: Create the RAIL Spec Ordinarily, we would create an RAIL spec in a separate file. For the purposes of this example, we will create the spec in this notebook as a string following the RAIL syntax. For more information on RAIL, see the RAIL documentation . Here, we request: rail_str = \"\"\" <rail version=\"0.1\"> <script language='python'> from dataclasses import dataclass from guardrails.validators import Validator, EventDetail, register_validator import re from typing import Dict, List NON_VEGAN_INGREDIENTS = [\"butter\", \"milk\", \"eggs\", \"cheese\", \"cream\", \"yogurt\"] SUBSTITUTIONS = { \"butter\": \"margarine\", \"milk\": \"soy milk\", \"eggs\": \"flax eggs\", \"cheese\": \"vegan cheese\", \"cream\": \"soy cream\", \"yogurt\": \"soy yogurt\", } @register_validator(name=\"is-vegan\", data_type=\"string\") class IsVegan(Validator): def validate(self, key, value, schema) -> Dict: global NON_VEGAN_INGREDIENTS, SUBSTITUTIONS # Make sure the ingredient is not in the list of non-vegan ingredients. if value.lower() in NON_VEGAN_INGREDIENTS: raise EventDetail( key, value, schema, f\"Value {value} is not vegan.\", # Programmatically fix the value by replacing it with a vegan # substitute. SUBSTITUTIONS[value.lower()], ) return schema </script> <output> <list name=\"ingredients\" description=\"What are the ingredients for the recipe?\"> <object> <integer name=\"index\" format=\"1-indexed\" /> <string name=\"name\" format=\"is-vegan\" on-fail-is-vegan=\"fix\" /> <string name=\"brand\" description=\"Suggested brand for the ingredient (if any)\" /> <bool name=\"optional\" description=\"Is the ingredient necessary?\" /> <float name=\"quantity\" format=\"units-imperial\" /> <string name=\"units\" format=\"units-imperial\" /> </object> </list> <list name=\"instructions\" description=\"What are the instructions for the recipe?\"> <object> <integer name=\"index\" format=\"1-indexed\" /> <string name=\"step\" /> </object> </list> </output> <prompt> Generate a recipe for vegan mac and cheese. @complete_json_suffix </prompt> </rail> \"\"\" Note Here, we create a custom IsVegan validator that checks if the ingredient is vegan. We also set on-fail-is-vegan to fix , which in this case means that programatically we will replace the ingredient with a vegan substitute. Step 2: Create a Guard object with the RAIL Spec We create a gd.Guard object that will check, validate and correct the output of the LLM. This object: Enforces the quality criteria specified in the RAIL spec. Takes corrective action when the quality criteria are not met. Compiles the schema and type info from the RAIL spec and adds it to the prompt. guard = gd . Guard . from_rail_string ( rail_str ) /Users/krandiash/Desktop/workspace/projects/guardrails/guardrails/datatypes.py:53: UserWarning: Formatter 1-indexed is not valid for element integer. warnings.warn( /Users/krandiash/Desktop/workspace/projects/guardrails/guardrails/datatypes.py:53: UserWarning: Formatter units-imperial is not valid for element float. warnings.warn( /Users/krandiash/Desktop/workspace/projects/guardrails/guardrails/datatypes.py:53: UserWarning: Formatter units-imperial is not valid for element string. warnings.warn( As we can see, a few formatters weren't supported. These formatters won't be enforced in the output, but this information can still be used to generate a prompt. We see the prompt that will be sent to the LLM. The {document} is substituted with the user provided value at runtime. print ( guard . base_prompt ) Generate a recipe for vegan mac and cheese. Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <list name = \"ingredients\" description = \"What are the ingredients for the recipe?\" > <object> <integer name = \"index\" format = \"1-indexed\" / > <string name = \"name\" format = \"is-vegan\" / > <string name = \"brand\" description = \"Suggested brand for the ingredient (if any)\" / > <bool name = \"optional\" description = \"Is the ingredient necessary?\" / > <float name = \"quantity\" format = \"units-imperial\" / > <string name = \"units\" format = \"units-imperial\" / > < / object > < / list > <list name = \"instructions\" description = \"What are the instructions for the recipe?\" > <object> <integer name = \"index\" format = \"1-indexed\" / > <string name = \"step\" / > < / object > < / list > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter ` None `. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object: Step 3: Wrap the LLM API call with Guard import openai raw_llm_response , validated_response = guard ( openai . Completion . create , engine = \"text-davinci-003\" , max_tokens = 2048 , temperature = 0 ) The guard wrapper returns the raw_llm_respose (which is a simple string), and the validated and corrected output (which is a dictionary). We can see that the output is a dictionary with the correct schema and types. print ( validated_response ) { 'ingredients' : [ { 'index' : 1 , 'name' : 'macaroni' , 'brand' : 'Barilla' , 'optional' : False , 'quantity' : 8.0 , 'units' : 'oz' } , { 'index' : 2 , 'name' : 'vegan butter' , 'brand' : 'Earth Balance' , 'optional' : False , 'quantity' : 2.0 , 'units' : 'tbsp' } , { 'index' : 3 , 'name' : 'all-purpose flour' , 'brand' : 'Gold Medal' , 'optional' : False , 'quantity' : 2.0 , 'units' : 'tbsp' } , { 'index' : 4 , 'name' : 'vegan milk' , 'brand' : 'Oatly' , 'optional' : False , 'quantity' : 2.0 , 'units' : 'cups' } , { 'index' : 5 , 'name' : 'vegan cheese' , 'brand' : 'Daiya' , 'optional' : False , 'quantity' : 8.0 , 'units' : 'oz' } , { 'index' : 6 , 'name' : 'nutritional yeast' , 'brand' : \"Bob's Red Mill\" , 'optional' : False , 'quantity' : 2.0 , 'units' : 'tbsp' } , { 'index' : 7 , 'name' : 'garlic powder' , 'brand' : 'McCormick' , 'optional' : False , 'quantity' : 1.0 , 'units' : 'tsp' } , { 'index' : 8 , 'name' : 'onion powder' , 'brand' : 'McCormick' , 'optional' : False , 'quantity' : 1.0 , 'units' : 'tsp' } , { 'index' : 9 , 'name' : 'salt' , 'brand' : 'Morton' , 'optional' : False , 'quantity' : 1.0 , 'units' : 'tsp' } , { 'index' : 10 , 'name' : 'black pepper' , 'brand' : 'McCormick' , 'optional' : False , 'quantity' : 1.0 , 'units' : 'tsp' } ] , 'instructions' : [ { 'index' : 1 , 'step' : 'Preheat oven to 350\u00b0F.' } , { 'index' : 2 , 'step' : 'Bring a large pot of salted water to a boil. Add macaroni and cook according to package instructions.' } , { 'index' : 3 , 'step' : 'Drain macaroni and set aside.' } , { 'index' : 4 , 'step' : 'In a medium saucepan, melt vegan butter over medium heat. Add flour and whisk until combined. Cook for 1 minute, stirring constantly.' } , { 'index' : 5 , 'step' : 'Slowly add vegan milk, whisking constantly. Cook for 3-4 minutes, stirring constantly, until sauce thickens.' } , { 'index' : 6 , 'step' : 'Remove from heat and stir in vegan cheese, nutritional yeast, garlic powder, onion powder, salt, and pepper. Stir until cheese is melted and sauce is smooth.' } , { 'index' : 7 , 'step' : 'Add macaroni to the sauce and stir until combined.' } , { 'index' : 8 , 'step' : 'Transfer macaroni and cheese to a 9x13 inch baking dish. Bake for 20 minutes, or until cheese is bubbly and golden brown.' } , { 'index' : 9 , 'step' : 'Serve warm and enjoy!' } ] }","title":"Vegan Mac & Cheese Recipe Generator"},{"location":"examples/recipe_generation/#generating-vegan-recipes","text":"Note To download this example as a Jupyter notebook, click here . In this example, we will use Guardrails to generate vegan mac and cheese recipe.","title":"Generating Vegan Recipes"},{"location":"examples/recipe_generation/#objective","text":"We want to generate a vegan Mac-n-Cheese recipe as a list of ingredients and instructions. We will use Guardrails to make sure the recipe is vegan. import guardrails as gd from rich import print","title":"Objective"},{"location":"examples/recipe_generation/#step-1-create-the-rail-spec","text":"Ordinarily, we would create an RAIL spec in a separate file. For the purposes of this example, we will create the spec in this notebook as a string following the RAIL syntax. For more information on RAIL, see the RAIL documentation . Here, we request: rail_str = \"\"\" <rail version=\"0.1\"> <script language='python'> from dataclasses import dataclass from guardrails.validators import Validator, EventDetail, register_validator import re from typing import Dict, List NON_VEGAN_INGREDIENTS = [\"butter\", \"milk\", \"eggs\", \"cheese\", \"cream\", \"yogurt\"] SUBSTITUTIONS = { \"butter\": \"margarine\", \"milk\": \"soy milk\", \"eggs\": \"flax eggs\", \"cheese\": \"vegan cheese\", \"cream\": \"soy cream\", \"yogurt\": \"soy yogurt\", } @register_validator(name=\"is-vegan\", data_type=\"string\") class IsVegan(Validator): def validate(self, key, value, schema) -> Dict: global NON_VEGAN_INGREDIENTS, SUBSTITUTIONS # Make sure the ingredient is not in the list of non-vegan ingredients. if value.lower() in NON_VEGAN_INGREDIENTS: raise EventDetail( key, value, schema, f\"Value {value} is not vegan.\", # Programmatically fix the value by replacing it with a vegan # substitute. SUBSTITUTIONS[value.lower()], ) return schema </script> <output> <list name=\"ingredients\" description=\"What are the ingredients for the recipe?\"> <object> <integer name=\"index\" format=\"1-indexed\" /> <string name=\"name\" format=\"is-vegan\" on-fail-is-vegan=\"fix\" /> <string name=\"brand\" description=\"Suggested brand for the ingredient (if any)\" /> <bool name=\"optional\" description=\"Is the ingredient necessary?\" /> <float name=\"quantity\" format=\"units-imperial\" /> <string name=\"units\" format=\"units-imperial\" /> </object> </list> <list name=\"instructions\" description=\"What are the instructions for the recipe?\"> <object> <integer name=\"index\" format=\"1-indexed\" /> <string name=\"step\" /> </object> </list> </output> <prompt> Generate a recipe for vegan mac and cheese. @complete_json_suffix </prompt> </rail> \"\"\" Note Here, we create a custom IsVegan validator that checks if the ingredient is vegan. We also set on-fail-is-vegan to fix , which in this case means that programatically we will replace the ingredient with a vegan substitute.","title":"Step 1: Create the RAIL Spec"},{"location":"examples/recipe_generation/#step-2-create-a-guard-object-with-the-rail-spec","text":"We create a gd.Guard object that will check, validate and correct the output of the LLM. This object: Enforces the quality criteria specified in the RAIL spec. Takes corrective action when the quality criteria are not met. Compiles the schema and type info from the RAIL spec and adds it to the prompt. guard = gd . Guard . from_rail_string ( rail_str ) /Users/krandiash/Desktop/workspace/projects/guardrails/guardrails/datatypes.py:53: UserWarning: Formatter 1-indexed is not valid for element integer. warnings.warn( /Users/krandiash/Desktop/workspace/projects/guardrails/guardrails/datatypes.py:53: UserWarning: Formatter units-imperial is not valid for element float. warnings.warn( /Users/krandiash/Desktop/workspace/projects/guardrails/guardrails/datatypes.py:53: UserWarning: Formatter units-imperial is not valid for element string. warnings.warn( As we can see, a few formatters weren't supported. These formatters won't be enforced in the output, but this information can still be used to generate a prompt. We see the prompt that will be sent to the LLM. The {document} is substituted with the user provided value at runtime. print ( guard . base_prompt ) Generate a recipe for vegan mac and cheese. Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <list name = \"ingredients\" description = \"What are the ingredients for the recipe?\" > <object> <integer name = \"index\" format = \"1-indexed\" / > <string name = \"name\" format = \"is-vegan\" / > <string name = \"brand\" description = \"Suggested brand for the ingredient (if any)\" / > <bool name = \"optional\" description = \"Is the ingredient necessary?\" / > <float name = \"quantity\" format = \"units-imperial\" / > <string name = \"units\" format = \"units-imperial\" / > < / object > < / list > <list name = \"instructions\" description = \"What are the instructions for the recipe?\" > <object> <integer name = \"index\" format = \"1-indexed\" / > <string name = \"step\" / > < / object > < / list > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter ` None `. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object:","title":"Step 2: Create a Guard object with the RAIL Spec"},{"location":"examples/recipe_generation/#step-3-wrap-the-llm-api-call-with-guard","text":"import openai raw_llm_response , validated_response = guard ( openai . Completion . create , engine = \"text-davinci-003\" , max_tokens = 2048 , temperature = 0 ) The guard wrapper returns the raw_llm_respose (which is a simple string), and the validated and corrected output (which is a dictionary). We can see that the output is a dictionary with the correct schema and types. print ( validated_response ) { 'ingredients' : [ { 'index' : 1 , 'name' : 'macaroni' , 'brand' : 'Barilla' , 'optional' : False , 'quantity' : 8.0 , 'units' : 'oz' } , { 'index' : 2 , 'name' : 'vegan butter' , 'brand' : 'Earth Balance' , 'optional' : False , 'quantity' : 2.0 , 'units' : 'tbsp' } , { 'index' : 3 , 'name' : 'all-purpose flour' , 'brand' : 'Gold Medal' , 'optional' : False , 'quantity' : 2.0 , 'units' : 'tbsp' } , { 'index' : 4 , 'name' : 'vegan milk' , 'brand' : 'Oatly' , 'optional' : False , 'quantity' : 2.0 , 'units' : 'cups' } , { 'index' : 5 , 'name' : 'vegan cheese' , 'brand' : 'Daiya' , 'optional' : False , 'quantity' : 8.0 , 'units' : 'oz' } , { 'index' : 6 , 'name' : 'nutritional yeast' , 'brand' : \"Bob's Red Mill\" , 'optional' : False , 'quantity' : 2.0 , 'units' : 'tbsp' } , { 'index' : 7 , 'name' : 'garlic powder' , 'brand' : 'McCormick' , 'optional' : False , 'quantity' : 1.0 , 'units' : 'tsp' } , { 'index' : 8 , 'name' : 'onion powder' , 'brand' : 'McCormick' , 'optional' : False , 'quantity' : 1.0 , 'units' : 'tsp' } , { 'index' : 9 , 'name' : 'salt' , 'brand' : 'Morton' , 'optional' : False , 'quantity' : 1.0 , 'units' : 'tsp' } , { 'index' : 10 , 'name' : 'black pepper' , 'brand' : 'McCormick' , 'optional' : False , 'quantity' : 1.0 , 'units' : 'tsp' } ] , 'instructions' : [ { 'index' : 1 , 'step' : 'Preheat oven to 350\u00b0F.' } , { 'index' : 2 , 'step' : 'Bring a large pot of salted water to a boil. Add macaroni and cook according to package instructions.' } , { 'index' : 3 , 'step' : 'Drain macaroni and set aside.' } , { 'index' : 4 , 'step' : 'In a medium saucepan, melt vegan butter over medium heat. Add flour and whisk until combined. Cook for 1 minute, stirring constantly.' } , { 'index' : 5 , 'step' : 'Slowly add vegan milk, whisking constantly. Cook for 3-4 minutes, stirring constantly, until sauce thickens.' } , { 'index' : 6 , 'step' : 'Remove from heat and stir in vegan cheese, nutritional yeast, garlic powder, onion powder, salt, and pepper. Stir until cheese is melted and sauce is smooth.' } , { 'index' : 7 , 'step' : 'Add macaroni to the sauce and stir until combined.' } , { 'index' : 8 , 'step' : 'Transfer macaroni and cheese to a 9x13 inch baking dish. Bake for 20 minutes, or until cheese is bubbly and golden brown.' } , { 'index' : 9 , 'step' : 'Serve warm and enjoy!' } ] }","title":"Step 3: Wrap the LLM API call with Guard"},{"location":"examples/syntax_error_free_sql/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Natural Language to Bug Free SQL Note To download this example as a Jupyter notebook, click here . In this example, we will use Guardrails to generate SQL queries from natural language. We will check that the SQL is free of any syntax errors. Objective We want to generate SQL queries from natural language, and check that the SQL is free of any syntax errors. Step 0: Setup In order to run this example, you will need to install the sqlvalidator package. You can do so by running the following command: ! pip install sqlvalidator Step 1: Create the RAIL Spec Ordinarily, we would create an RAIL spec in a separate file. For the purposes of this example, we will create the spec in this notebook as a string following the RAIL syntax. For more information on RAIL, see the RAIL documentation . In this RAIL spec, we: Create an output schema that returns a single key-value pair. The key should be 'generated_sql' and the value should be the SQL query generated from the natural language, which is syntactically correct. rail_str = \"\"\" <rail version=\"0.1\"> <output> <string name=\"generated_sql\" description=\"Generate SQL for the given natural language instruction.\" format=\"bug-free-sql\" on-fail-bug-free-sql=\"reask\" /> </output> <prompt> Generate a valid SQL query for the following natural language instruction: {{nl_instruction}} @complete_json_suffix </prompt> </rail> \"\"\" Note In order to ensure that the SQL is syntactically correct, we use bug-free-sql as the formatter. This is a light-weight formatter that uses the sqlvalidator package to check that the SQL is free of any syntax errors. For your use case, you can create a custom SQL validator that connects to your database and checks that the SQL is valid. Step 2: Create a Guard object with the RAIL Spec We create a gd.Guard object that will check, validate and correct the output of the LLM. This object: Enforces the quality criteria specified in the RAIL spec. Takes corrective action when the quality criteria are not met. Compiles the schema and type info from the RAIL spec and adds it to the prompt. import guardrails as gd from rich import print guard = gd . Guard . from_rail_string ( rail_str ) We see the prompt that will be sent to the LLM: print ( guard . base_prompt ) Generate a valid SQL query for the following natural language instruction: { nl_instruction } Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <string name = \"generated_sql\" description = \"Generate SQL for the given natural language instruction.\" format = \"bug-free-sql\" / > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter ` None `. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object: Here, nl_language is the natural language instruction and will be provided by the user at runtime. Step 3: Wrap the LLM API call with Guard import openai raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { \"nl_instruction\" : \"Select the name of the employee who has the highest salary.\" }, engine = \"text-davinci-003\" , max_tokens = 2048 , temperature = 0 , ) The guard wrapper returns the raw_llm_respose (which is a simple string), and the validated and corrected output (which is a dictionary). We can see that the output is a dictionary with the correct schema and types. print ( validated_response ) { 'generated_sql' : 'SELECT name FROM employee ORDER BY salary DESC LIMIT 1' }","title":"Natural language to bug-free SQL"},{"location":"examples/syntax_error_free_sql/#natural-language-to-bug-free-sql","text":"Note To download this example as a Jupyter notebook, click here . In this example, we will use Guardrails to generate SQL queries from natural language. We will check that the SQL is free of any syntax errors.","title":"Natural Language to Bug Free SQL"},{"location":"examples/syntax_error_free_sql/#objective","text":"We want to generate SQL queries from natural language, and check that the SQL is free of any syntax errors.","title":"Objective"},{"location":"examples/syntax_error_free_sql/#step-0-setup","text":"In order to run this example, you will need to install the sqlvalidator package. You can do so by running the following command: ! pip install sqlvalidator","title":"Step 0: Setup"},{"location":"examples/syntax_error_free_sql/#step-1-create-the-rail-spec","text":"Ordinarily, we would create an RAIL spec in a separate file. For the purposes of this example, we will create the spec in this notebook as a string following the RAIL syntax. For more information on RAIL, see the RAIL documentation . In this RAIL spec, we: Create an output schema that returns a single key-value pair. The key should be 'generated_sql' and the value should be the SQL query generated from the natural language, which is syntactically correct. rail_str = \"\"\" <rail version=\"0.1\"> <output> <string name=\"generated_sql\" description=\"Generate SQL for the given natural language instruction.\" format=\"bug-free-sql\" on-fail-bug-free-sql=\"reask\" /> </output> <prompt> Generate a valid SQL query for the following natural language instruction: {{nl_instruction}} @complete_json_suffix </prompt> </rail> \"\"\" Note In order to ensure that the SQL is syntactically correct, we use bug-free-sql as the formatter. This is a light-weight formatter that uses the sqlvalidator package to check that the SQL is free of any syntax errors. For your use case, you can create a custom SQL validator that connects to your database and checks that the SQL is valid.","title":"Step 1: Create the RAIL Spec"},{"location":"examples/syntax_error_free_sql/#step-2-create-a-guard-object-with-the-rail-spec","text":"We create a gd.Guard object that will check, validate and correct the output of the LLM. This object: Enforces the quality criteria specified in the RAIL spec. Takes corrective action when the quality criteria are not met. Compiles the schema and type info from the RAIL spec and adds it to the prompt. import guardrails as gd from rich import print guard = gd . Guard . from_rail_string ( rail_str ) We see the prompt that will be sent to the LLM: print ( guard . base_prompt ) Generate a valid SQL query for the following natural language instruction: { nl_instruction } Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <string name = \"generated_sql\" description = \"Generate SQL for the given natural language instruction.\" format = \"bug-free-sql\" / > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter ` None `. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object: Here, nl_language is the natural language instruction and will be provided by the user at runtime.","title":"Step 2: Create a Guard object with the RAIL Spec"},{"location":"examples/syntax_error_free_sql/#step-3-wrap-the-llm-api-call-with-guard","text":"import openai raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { \"nl_instruction\" : \"Select the name of the employee who has the highest salary.\" }, engine = \"text-davinci-003\" , max_tokens = 2048 , temperature = 0 , ) The guard wrapper returns the raw_llm_respose (which is a simple string), and the validated and corrected output (which is a dictionary). We can see that the output is a dictionary with the correct schema and types. print ( validated_response ) { 'generated_sql' : 'SELECT name FROM employee ORDER BY salary DESC LIMIT 1' }","title":"Step 3: Wrap the LLM API call with Guard"},{"location":"examples/text_summarization_quality/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Summarize text accurately Note To download this example as a Jupyter notebook, click here . In this example, we will use Guardrails in the summarization of a text document. We will check whether the summarized document has a high semantic similarity with the original document. Objective Summarize a text document and check whether the summarized document has a high semantic similarity with the original document. Step 0: Setup In order to run this example, you will need to install the numpy package. You can do so by running the following commands: ! pip install numpy Requirement already satisfied: numpy in /Users/krandiash/opt/anaconda3/envs/guardrails/lib/python3.9/site-packages (1.24.2) Step 1: Create the RAIL Spec Ordinarily, we would create an RAIL spec in a separate file. For the purposes of this example, we will create the spec in this notebook as a string following the RAIL syntax. For more information on RAIL, see the RAIL documentation . In this RAIL spec, we: Create an output schema that returns a single key-value pair. The key should be 'summary', and the value should be the summary of the given document. rail_str = \"\"\" <rail version=\"0.1\"> <script language='python'> document = open(\"data/article1.txt\", \"r\").read() </script> <output> <string name=\"summary\" description=\"Summarize the given document faithfully.\" format=\"similar-to-document: {document} , 0.60\" on-fail-similar-to-document=\"filter\" /> </output> <prompt> Summarize the following document: {{document}} @complete_json_suffix </prompt> </rail> \"\"\" Note In order to ensure the summary is similar to the document, we use similar-to-document as the validator. This validator embeds the document and the summary and checks whether the cosine similarity between the two embeddings is above a threshold. Step 2: Create a Guard object with the RAIL Spec We create a gd.Guard object that will check, validate and correct the output of the LLM. This object: Enforces the quality criteria specified in the RAIL spec. Takes corrective action when the quality criteria are not met. Compiles the schema and type info from the RAIL spec and adds it to the prompt. import guardrails as gd from rich import print guard = gd . Guard . from_rail_string ( rail_str ) We see the prompt that will be sent to the LLM: print ( guard . base_prompt ) Summarize the following document: { document } Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <string name = \"summary\" description = \"Summarize the given document faithfully.\" format = \"similar-to-document: {document}, 0.60\" / > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter ` None `. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object: Here, statement_to_be_translated is the the statement and will be provided by the user at runtime. Step 3: Wrap the LLM API call with Guard First, let's try translating a statement that doesn't have any profanity in it. import openai raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { 'document' : open ( \"data/article1.txt\" , \"r\" ) . read ()}, engine = 'text-davinci-003' , max_tokens = 2048 , temperature = 0 ) print ( f \"Validated Output: { validated_response } \" ) Validated Output: { 'summary' : 'All legislative Powers shall be vested in a Congress of the United States, which shall consist of a Senate and House of Representatives. The House of Representatives shall be composed of Members chosen every second Year by the People of the several States, and the Electors in each State shall have the Qualifications requisite for Electors of the most numerous Branch of the State Legislature. Representatives and direct Taxes shall be apportioned among the several States according to their respective Numbers, and the Number of Representatives shall not exceed one for every thirty Thousand. When vacancies happen in the Representation from any State, the Executive Authority thereof shall issue Writs of Election to fill such Vacancies. The House of Representatives shall chuse their Speaker and other Officers; and shall have the sole Power of Impeachment.' } The guard wrapper returns the raw_llm_respose (which is a simple string), and the validated and corrected output (which is a dictionary). We can see that the output is a dictionary with the correct schema and types. Next, let's try using a smaller model, which is not boing to be good at summarization. We can see that the output is filtered out. raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { 'document' : open ( \"data/article1.txt\" , \"r\" ) . read ()}, engine = 'text-ada-001' , max_tokens = 512 , temperature = 0 ) print ( f \"Validated Output: { validated_response } \" ) Validated Output: None","title":"Check key info present in generated summary"},{"location":"examples/text_summarization_quality/#summarize-text-accurately","text":"Note To download this example as a Jupyter notebook, click here . In this example, we will use Guardrails in the summarization of a text document. We will check whether the summarized document has a high semantic similarity with the original document.","title":"Summarize text accurately"},{"location":"examples/text_summarization_quality/#objective","text":"Summarize a text document and check whether the summarized document has a high semantic similarity with the original document.","title":"Objective"},{"location":"examples/text_summarization_quality/#step-0-setup","text":"In order to run this example, you will need to install the numpy package. You can do so by running the following commands: ! pip install numpy Requirement already satisfied: numpy in /Users/krandiash/opt/anaconda3/envs/guardrails/lib/python3.9/site-packages (1.24.2)","title":"Step 0: Setup"},{"location":"examples/text_summarization_quality/#step-1-create-the-rail-spec","text":"Ordinarily, we would create an RAIL spec in a separate file. For the purposes of this example, we will create the spec in this notebook as a string following the RAIL syntax. For more information on RAIL, see the RAIL documentation . In this RAIL spec, we: Create an output schema that returns a single key-value pair. The key should be 'summary', and the value should be the summary of the given document. rail_str = \"\"\" <rail version=\"0.1\"> <script language='python'> document = open(\"data/article1.txt\", \"r\").read() </script> <output> <string name=\"summary\" description=\"Summarize the given document faithfully.\" format=\"similar-to-document: {document} , 0.60\" on-fail-similar-to-document=\"filter\" /> </output> <prompt> Summarize the following document: {{document}} @complete_json_suffix </prompt> </rail> \"\"\" Note In order to ensure the summary is similar to the document, we use similar-to-document as the validator. This validator embeds the document and the summary and checks whether the cosine similarity between the two embeddings is above a threshold.","title":"Step 1: Create the RAIL Spec"},{"location":"examples/text_summarization_quality/#step-2-create-a-guard-object-with-the-rail-spec","text":"We create a gd.Guard object that will check, validate and correct the output of the LLM. This object: Enforces the quality criteria specified in the RAIL spec. Takes corrective action when the quality criteria are not met. Compiles the schema and type info from the RAIL spec and adds it to the prompt. import guardrails as gd from rich import print guard = gd . Guard . from_rail_string ( rail_str ) We see the prompt that will be sent to the LLM: print ( guard . base_prompt ) Summarize the following document: { document } Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <string name = \"summary\" description = \"Summarize the given document faithfully.\" format = \"similar-to-document: {document}, 0.60\" / > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter ` None `. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object: Here, statement_to_be_translated is the the statement and will be provided by the user at runtime.","title":"Step 2: Create a Guard object with the RAIL Spec"},{"location":"examples/text_summarization_quality/#step-3-wrap-the-llm-api-call-with-guard","text":"First, let's try translating a statement that doesn't have any profanity in it. import openai raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { 'document' : open ( \"data/article1.txt\" , \"r\" ) . read ()}, engine = 'text-davinci-003' , max_tokens = 2048 , temperature = 0 ) print ( f \"Validated Output: { validated_response } \" ) Validated Output: { 'summary' : 'All legislative Powers shall be vested in a Congress of the United States, which shall consist of a Senate and House of Representatives. The House of Representatives shall be composed of Members chosen every second Year by the People of the several States, and the Electors in each State shall have the Qualifications requisite for Electors of the most numerous Branch of the State Legislature. Representatives and direct Taxes shall be apportioned among the several States according to their respective Numbers, and the Number of Representatives shall not exceed one for every thirty Thousand. When vacancies happen in the Representation from any State, the Executive Authority thereof shall issue Writs of Election to fill such Vacancies. The House of Representatives shall chuse their Speaker and other Officers; and shall have the sole Power of Impeachment.' } The guard wrapper returns the raw_llm_respose (which is a simple string), and the validated and corrected output (which is a dictionary). We can see that the output is a dictionary with the correct schema and types. Next, let's try using a smaller model, which is not boing to be good at summarization. We can see that the output is filtered out. raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { 'document' : open ( \"data/article1.txt\" , \"r\" ) . read ()}, engine = 'text-ada-001' , max_tokens = 512 , temperature = 0 ) print ( f \"Validated Output: { validated_response } \" ) Validated Output: None","title":"Step 3: Wrap the LLM API call with Guard"},{"location":"examples/translation_to_specific_language/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Translate text without profanities Note To download this example as a Jupyter notebook, click here . In this example, we will use Guardrails during the translation of a statement from another language to english. We will check whether the translated statement passes the profanity check or not. Objective We want to translate a statement from another languages to English and ensure the translated statement is profanity free. Step 0: Setup In order to run this example, you will need to install alt-profanity-check package. You can do so by running the following commands: ! pip install alt - profanity - check Step 1: Create the RAIL Spec Ordinarily, we would create an RAIL spec in a separate file. For the purposes of this example, we will create the spec in this notebook as a string following the RAIL syntax. For more information on RAIL, see the RAIL documentation . In this RAIL spec, we: Create an output schema that returns a single key-value pair. The key should be 'translated_statement', and the value should be the English translation of the given statement. The translated statement should not have any profanity. from profanity_check import predict rail_str = \"\"\" <rail version=\"0.1\"> <script language='python'> from profanity_check import predict from guardrails.validators import Validator, EventDetail, register_validator from typing import Dict, List @register_validator(name=\"is-profanity-free\", data_type=\"string\") class IsProfanityFree(Validator): global predict global EventDetail def validate(self, key, value, schema) -> Dict: text = value prediction = predict([value]) if prediction[0] == 1: raise EventDetail( key, value, schema, f\"Value {value} contains profanity language\", \"\", ) return schema </script> <output> <string name=\"translated_statement\" description=\"Translate the given statement into english language\" format=\"is-profanity-free\" on-fail-is-profanity-free=\"fix\" /> </output> <prompt> Translate the given statement into english language: {{statement_to_be_translated}} @complete_json_suffix </prompt> </rail> \"\"\" Note In order to ensure the translated statement is profanity free, we use is-profanity-free as the validator. This validator uses profanity_check package. Step 2: Create a Guard object with the RAIL Spec We create a gd.Guard object that will check, validate and correct the output of the LLM. This object: Enforces the quality criteria specified in the RAIL spec. Takes corrective action when the quality criteria are not met. Compiles the schema and type info from the RAIL spec and adds it to the prompt. import guardrails as gd from rich import print guard = gd . Guard . from_rail_string ( rail_str ) We see the prompt that will be sent to the LLM: print ( guard . base_prompt ) Translate the given statement into english language: { statement_to_be_translated } Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <string name = \"translated_statement\" description = \"Translate the given statement into english language\" format = \"is-profanity-free\" / > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter ` None `. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object: Here, statement_to_be_translated is the the statement and will be provided by the user at runtime. Step 3: Wrap the LLM API call with Guard First, let's try translating a statement that doesn't have any profanity in it. import openai raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { \"statement_to_be_translated\" : \"quesadilla de pollo\" }, engine = \"text-davinci-003\" , max_tokens = 2048 , temperature = 0 , ) print ( f \"Validated Output: { validated_response } \" ) Validated Output: { 'translated_statement' : 'Chicken Quesadilla' } The guard wrapper returns the raw_llm_respose (which is a simple string), and the validated and corrected output (which is a dictionary). We can see that the output is a dictionary with the correct schema and types. Next, let's try translating a statement that has profanity in it. We see that the translated statement has been corrected to return an empty string instead of the translated statement. raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { \"statement_to_be_translated\" : \"\u0443\u0431\u0435\u0439 \u0441\u0435\u0431\u044f\" }, engine = \"text-davinci-003\" , max_tokens = 2048 , temperature = 0 , ) print ( f \"Validated Output: { validated_response } \" ) Validated Output: { 'translated_statement' : '' }","title":"Translate text with profanity filtering"},{"location":"examples/translation_to_specific_language/#translate-text-without-profanities","text":"Note To download this example as a Jupyter notebook, click here . In this example, we will use Guardrails during the translation of a statement from another language to english. We will check whether the translated statement passes the profanity check or not.","title":"Translate text without profanities"},{"location":"examples/translation_to_specific_language/#objective","text":"We want to translate a statement from another languages to English and ensure the translated statement is profanity free.","title":"Objective"},{"location":"examples/translation_to_specific_language/#step-0-setup","text":"In order to run this example, you will need to install alt-profanity-check package. You can do so by running the following commands: ! pip install alt - profanity - check","title":"Step 0: Setup"},{"location":"examples/translation_to_specific_language/#step-1-create-the-rail-spec","text":"Ordinarily, we would create an RAIL spec in a separate file. For the purposes of this example, we will create the spec in this notebook as a string following the RAIL syntax. For more information on RAIL, see the RAIL documentation . In this RAIL spec, we: Create an output schema that returns a single key-value pair. The key should be 'translated_statement', and the value should be the English translation of the given statement. The translated statement should not have any profanity. from profanity_check import predict rail_str = \"\"\" <rail version=\"0.1\"> <script language='python'> from profanity_check import predict from guardrails.validators import Validator, EventDetail, register_validator from typing import Dict, List @register_validator(name=\"is-profanity-free\", data_type=\"string\") class IsProfanityFree(Validator): global predict global EventDetail def validate(self, key, value, schema) -> Dict: text = value prediction = predict([value]) if prediction[0] == 1: raise EventDetail( key, value, schema, f\"Value {value} contains profanity language\", \"\", ) return schema </script> <output> <string name=\"translated_statement\" description=\"Translate the given statement into english language\" format=\"is-profanity-free\" on-fail-is-profanity-free=\"fix\" /> </output> <prompt> Translate the given statement into english language: {{statement_to_be_translated}} @complete_json_suffix </prompt> </rail> \"\"\" Note In order to ensure the translated statement is profanity free, we use is-profanity-free as the validator. This validator uses profanity_check package.","title":"Step 1: Create the RAIL Spec"},{"location":"examples/translation_to_specific_language/#step-2-create-a-guard-object-with-the-rail-spec","text":"We create a gd.Guard object that will check, validate and correct the output of the LLM. This object: Enforces the quality criteria specified in the RAIL spec. Takes corrective action when the quality criteria are not met. Compiles the schema and type info from the RAIL spec and adds it to the prompt. import guardrails as gd from rich import print guard = gd . Guard . from_rail_string ( rail_str ) We see the prompt that will be sent to the LLM: print ( guard . base_prompt ) Translate the given statement into english language: { statement_to_be_translated } Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <string name = \"translated_statement\" description = \"Translate the given statement into english language\" format = \"is-profanity-free\" / > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter ` None `. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object: Here, statement_to_be_translated is the the statement and will be provided by the user at runtime.","title":"Step 2: Create a Guard object with the RAIL Spec"},{"location":"examples/translation_to_specific_language/#step-3-wrap-the-llm-api-call-with-guard","text":"First, let's try translating a statement that doesn't have any profanity in it. import openai raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { \"statement_to_be_translated\" : \"quesadilla de pollo\" }, engine = \"text-davinci-003\" , max_tokens = 2048 , temperature = 0 , ) print ( f \"Validated Output: { validated_response } \" ) Validated Output: { 'translated_statement' : 'Chicken Quesadilla' } The guard wrapper returns the raw_llm_respose (which is a simple string), and the validated and corrected output (which is a dictionary). We can see that the output is a dictionary with the correct schema and types. Next, let's try translating a statement that has profanity in it. We see that the translated statement has been corrected to return an empty string instead of the translated statement. raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { \"statement_to_be_translated\" : \"\u0443\u0431\u0435\u0439 \u0441\u0435\u0431\u044f\" }, engine = \"text-davinci-003\" , max_tokens = 2048 , temperature = 0 , ) print ( f \"Validated Output: { validated_response } \" ) Validated Output: { 'translated_statement' : '' }","title":"Step 3: Wrap the LLM API call with Guard"},{"location":"examples/translation_with_quality_check/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Translate text with quality checks Note To download this example as a Jupyter notebook, click here . In this example, we will use Guardrails during the translation of a statement from another language to English. We will check whether the translated statement is likely high quality or not. Objective We want to translate a statement from another languages to English and ensure that the translated statement accurately reflects the original content. Step 0: Setup To do the quality check, we can use the Critique library, which allows for simple calculation of various metrics over generated text, including translation quality estimation . First you can get an API key from the Inspired Cognition Dashboard add the following line to the \".env\" file in your top directory (like you do for your OpenAI API key). INSPIREDCO_API_KEY = <your_api_key> Then you can install the library ! pip install inspiredco Step 1: Create the RAIL Spec Ordinarily, we would create an RAIL spec in a separate file. For the purposes of this example, we will create the spec in this notebook as a string following the RAIL syntax. For more information on RAIL, see the RAIL documentation . In this RAIL spec, we: Create an output schema that returns a single key-value pair. The key should be 'translated_statement', and the value should be the English translation of the given statement. The translated statement should not have any profanity. from inspiredco import critique rail_str = \"\"\" <rail version=\"0.1\"> <script language='python'> import inspiredco.critique import os from guardrails.validators import Validator, EventDetail, register_validator critique = inspiredco.critique.Critique(api_key=os.environ['INSPIREDCO_API_KEY']) from typing import Dict, List @register_validator(name=\"is-high-quality-translation\", data_type=\"string\") class IsHighQualityTranslation(Validator): global critique global EventDetail def validate(self, key, value, schema) -> Dict: prediction = critique.evaluate( metric = \"comet\", config = {\"model\": \"unbabel_comet/wmt21-comet-qe-da\"}, dataset = [{\"source\": key, \"target\": value}], ) quality = prediction[\"examples\"][0][\"value\"] if quality &lt; -0.1: raise EventDetail( key, value, schema, f\"Value {value} has relatively low quality {quality} \", \"\", ) return schema </script> <output> <string name=\"translated_statement\" description=\"Translate the given statement into the English language\" format=\"is-high-quality-translation\" on-fail-is-high-quality-translation=\"fix\" /> </output> <prompt> Translate the given statement into the English language: {{statement_to_be_translated}} @complete_json_suffix </prompt> </rail> \"\"\" Note In order to ensure the translated statement is high quality, we use is-high-quality-translation as the validator. This validator uses inspiredco package. Step 2: Create a Guard object with the RAIL Spec We create a gd.Guard object that will check, validate and correct the output of the LLM. This object: Enforces the quality criteria specified in the RAIL spec. Takes corrective action when the quality criteria are not met. Compiles the schema and type info from the RAIL spec and adds it to the prompt. import guardrails as gd from rich import print guard = gd . Guard . from_rail_string ( rail_str ) We see the prompt that will be sent to the LLM: print ( guard . base_prompt ) Translate the given statement into the English language: { statement_to_be_translated } Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <string name = \"translated_statement\" description = \"Translate the given statement into the English language\" format = \"is-high-quality-translation\" / > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter ` None `. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object: Here, statement_to_be_translated is the the statement and will be provided by the user at runtime. Step 3: Wrap the LLM API call with Guard First, let's try translating a statement that is relatively easy to translate. import openai raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { 'statement_to_be_translated' : '\u3053\u308c\u306f\u7c21\u5358\u306b\u7ffb\u8a33\u3067\u304d\u308b\u304b\u3082\u3057\u308c\u306a\u3044\u3002' }, engine = 'text-davinci-003' , max_tokens = 2048 , temperature = 0 ) print ( f \"Validated Output: { validated_response } \" ) Validated Output: { 'translated_statement' : 'This may be easy to translate.' } The guard wrapper returns the raw_llm_respose (which is a simple string), and the validated and corrected output (which is a dictionary). We can see that the output is a dictionary with the correct schema and types. Next, let's try translating a statement that is harder to translate (because it contains some difficult-to-translate slang words). We see that the translated statement has been corrected to return an empty string instead of the translated statement. raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { 'statement_to_be_translated' : '\u30c9\u30f3\u5f15\u304d\u3059\u308b\u307b\u3069\u7ffb\u8a33\u304c\u60aa\u3044\u3002' }, engine = 'text-davinci-003' , max_tokens = 2048 , temperature = 0 ) print ( f \"Validated Output: { validated_response } \" ) Validated Output: { 'translated_statement' : '' }","title":"Ensure translated text is high quality"},{"location":"examples/translation_with_quality_check/#translate-text-with-quality-checks","text":"Note To download this example as a Jupyter notebook, click here . In this example, we will use Guardrails during the translation of a statement from another language to English. We will check whether the translated statement is likely high quality or not.","title":"Translate text with quality checks"},{"location":"examples/translation_with_quality_check/#objective","text":"We want to translate a statement from another languages to English and ensure that the translated statement accurately reflects the original content.","title":"Objective"},{"location":"examples/translation_with_quality_check/#step-0-setup","text":"To do the quality check, we can use the Critique library, which allows for simple calculation of various metrics over generated text, including translation quality estimation . First you can get an API key from the Inspired Cognition Dashboard add the following line to the \".env\" file in your top directory (like you do for your OpenAI API key). INSPIREDCO_API_KEY = <your_api_key> Then you can install the library ! pip install inspiredco","title":"Step 0: Setup"},{"location":"examples/translation_with_quality_check/#step-1-create-the-rail-spec","text":"Ordinarily, we would create an RAIL spec in a separate file. For the purposes of this example, we will create the spec in this notebook as a string following the RAIL syntax. For more information on RAIL, see the RAIL documentation . In this RAIL spec, we: Create an output schema that returns a single key-value pair. The key should be 'translated_statement', and the value should be the English translation of the given statement. The translated statement should not have any profanity. from inspiredco import critique rail_str = \"\"\" <rail version=\"0.1\"> <script language='python'> import inspiredco.critique import os from guardrails.validators import Validator, EventDetail, register_validator critique = inspiredco.critique.Critique(api_key=os.environ['INSPIREDCO_API_KEY']) from typing import Dict, List @register_validator(name=\"is-high-quality-translation\", data_type=\"string\") class IsHighQualityTranslation(Validator): global critique global EventDetail def validate(self, key, value, schema) -> Dict: prediction = critique.evaluate( metric = \"comet\", config = {\"model\": \"unbabel_comet/wmt21-comet-qe-da\"}, dataset = [{\"source\": key, \"target\": value}], ) quality = prediction[\"examples\"][0][\"value\"] if quality &lt; -0.1: raise EventDetail( key, value, schema, f\"Value {value} has relatively low quality {quality} \", \"\", ) return schema </script> <output> <string name=\"translated_statement\" description=\"Translate the given statement into the English language\" format=\"is-high-quality-translation\" on-fail-is-high-quality-translation=\"fix\" /> </output> <prompt> Translate the given statement into the English language: {{statement_to_be_translated}} @complete_json_suffix </prompt> </rail> \"\"\" Note In order to ensure the translated statement is high quality, we use is-high-quality-translation as the validator. This validator uses inspiredco package.","title":"Step 1: Create the RAIL Spec"},{"location":"examples/translation_with_quality_check/#step-2-create-a-guard-object-with-the-rail-spec","text":"We create a gd.Guard object that will check, validate and correct the output of the LLM. This object: Enforces the quality criteria specified in the RAIL spec. Takes corrective action when the quality criteria are not met. Compiles the schema and type info from the RAIL spec and adds it to the prompt. import guardrails as gd from rich import print guard = gd . Guard . from_rail_string ( rail_str ) We see the prompt that will be sent to the LLM: print ( guard . base_prompt ) Translate the given statement into the English language: { statement_to_be_translated } Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <string name = \"translated_statement\" description = \"Translate the given statement into the English language\" format = \"is-high-quality-translation\" / > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter ` None `. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object: Here, statement_to_be_translated is the the statement and will be provided by the user at runtime.","title":"Step 2: Create a Guard object with the RAIL Spec"},{"location":"examples/translation_with_quality_check/#step-3-wrap-the-llm-api-call-with-guard","text":"First, let's try translating a statement that is relatively easy to translate. import openai raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { 'statement_to_be_translated' : '\u3053\u308c\u306f\u7c21\u5358\u306b\u7ffb\u8a33\u3067\u304d\u308b\u304b\u3082\u3057\u308c\u306a\u3044\u3002' }, engine = 'text-davinci-003' , max_tokens = 2048 , temperature = 0 ) print ( f \"Validated Output: { validated_response } \" ) Validated Output: { 'translated_statement' : 'This may be easy to translate.' } The guard wrapper returns the raw_llm_respose (which is a simple string), and the validated and corrected output (which is a dictionary). We can see that the output is a dictionary with the correct schema and types. Next, let's try translating a statement that is harder to translate (because it contains some difficult-to-translate slang words). We see that the translated statement has been corrected to return an empty string instead of the translated statement. raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { 'statement_to_be_translated' : '\u30c9\u30f3\u5f15\u304d\u3059\u308b\u307b\u3069\u7ffb\u8a33\u304c\u60aa\u3044\u3002' }, engine = 'text-davinci-003' , max_tokens = 2048 , temperature = 0 ) print ( f \"Validated Output: { validated_response } \" ) Validated Output: { 'translated_statement' : '' }","title":"Step 3: Wrap the LLM API call with Guard"},{"location":"examples/valid_chess_moves/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Playing Valid Chess Moves Note To download this example as a Jupyter notebook, click here . Warning This example is currently under development (it cannot be used to play a full chess game yet). In this example, we will use Guardrails to play chess with an LLM and ensure that it makes valid moves. Objective We want to generate a valid chess moves for a given board state. import guardrails as gd from rich import print ! pip install chess Step 1: Create the RAIL Spec Ordinarily, we would create an RAIL spec in a separate file. For the purposes of this example, we will create the spec in this notebook as a string following the RAIL syntax. For more information on RAIL, see the RAIL documentation . Here, we request: rail_str = \"\"\" <rail version=\"0.1\"> <script language='python'> from dataclasses import dataclass from guardrails.validators import Validator, EventDetail, register_validator import re from typing import Dict, List import chess BOARD = chess.Board() @register_validator(name=\"is-valid-chess-move\", data_type=\"string\") class IsValidChessMove(Validator): board = BOARD def validate(self, key, value, schema) -> Dict: global BOARD try: # Push the move onto the board. BOARD.push_san(value) except Exception as e: # If the move is invalid, raise an error. raise EventDetail( key, value, schema, f\"Value {value} is not a valid chess move. {e} \", None, ) return schema </script> <output> <string description=\"A move in standard algebraic notation.\" name=\"move\" required=\"true\" format=\"is-valid-chess-move\" on-fail-is-valid-chess-move=\"reask\" /> </output> <prompt> Generate a move for the chess board. The board is currently in the following state: {{board_state}} @complete_json_suffix </prompt> </rail> \"\"\" Step 2: Create a Guard object with the RAIL Spec We create a gd.Guard object that will check, validate and correct the output of the LLM. This object: Enforces the quality criteria specified in the RAIL spec. Takes corrective action when the quality criteria are not met. Compiles the schema and type info from the RAIL spec and adds it to the prompt. guard = gd . Guard . from_rail_string ( rail_str ) We see the prompt that will be sent to the LLM. The {board_state} is substituted with the current state of the board. print ( guard . base_prompt ) Generate a move for the chess board. The board is currently in the following state: { board_state } Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <string description = \"A move in standard algebraic notation.\" name = \"move\" required = \"true\" format = \"is-valid-chess-move\" / > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter ` None `. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object: Let's get the reference to the board. board = guard . output_schema . move . validators [ 0 ] . board board r n b q k b n r p p p p p p p p . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . P P P P P P P P R N B Q K B N R Step 3: Wrap the LLM API call with Guard import openai raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { \"board_state\" : str ( board . move_stack ) if board . move_stack else \"Starting position.\" }, engine = \"text-davinci-003\" , max_tokens = 2048 , temperature = 0.3 , ) The guard wrapper returns the raw_llm_respose (which is a simple string), and the validated and corrected output (which is a dictionary). We can see that the output is a dictionary with the correct schema and types. print ( validated_response ) { 'move' : 'e4' } board r n b q k b n r p p p p p p p p . . . . . . . . . . . . . . . . . . . . P . . . . . . . . . . . P P P P . P P P R N B Q K B N R Let's make a move. board . push_san ( \"e5\" ) board r n b q k b n r p p p p . p p p . . . . . . . . . . . . p . . . . . . . P . . . . . . . . . . . P P P P . P P P R N B Q K B N R Ask for another move from the model. raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { \"board_state\" : str ( board . move_stack ) if board . move_stack else \"Starting position.\" }, engine = \"text-davinci-003\" , max_tokens = 2048 , temperature = 0.3 , ) board r n b q k b n r p p p p . p p p . . . . . . . . . . . . p . . . . . . . P . . . . . . . . N . . P P P P . P P P R N B Q K B . R board . push_san ( \"Nc6\" ) board r . b q k b n r p p p p . p p p . . n . . . . . . . . . p . . . . . . . P . . . . . . . . N . . P P P P . P P P R N B Q K B . R","title":"Using GPT to play valid chess moves"},{"location":"examples/valid_chess_moves/#playing-valid-chess-moves","text":"Note To download this example as a Jupyter notebook, click here . Warning This example is currently under development (it cannot be used to play a full chess game yet). In this example, we will use Guardrails to play chess with an LLM and ensure that it makes valid moves.","title":"Playing Valid Chess Moves"},{"location":"examples/valid_chess_moves/#objective","text":"We want to generate a valid chess moves for a given board state. import guardrails as gd from rich import print ! pip install chess","title":"Objective"},{"location":"examples/valid_chess_moves/#step-1-create-the-rail-spec","text":"Ordinarily, we would create an RAIL spec in a separate file. For the purposes of this example, we will create the spec in this notebook as a string following the RAIL syntax. For more information on RAIL, see the RAIL documentation . Here, we request: rail_str = \"\"\" <rail version=\"0.1\"> <script language='python'> from dataclasses import dataclass from guardrails.validators import Validator, EventDetail, register_validator import re from typing import Dict, List import chess BOARD = chess.Board() @register_validator(name=\"is-valid-chess-move\", data_type=\"string\") class IsValidChessMove(Validator): board = BOARD def validate(self, key, value, schema) -> Dict: global BOARD try: # Push the move onto the board. BOARD.push_san(value) except Exception as e: # If the move is invalid, raise an error. raise EventDetail( key, value, schema, f\"Value {value} is not a valid chess move. {e} \", None, ) return schema </script> <output> <string description=\"A move in standard algebraic notation.\" name=\"move\" required=\"true\" format=\"is-valid-chess-move\" on-fail-is-valid-chess-move=\"reask\" /> </output> <prompt> Generate a move for the chess board. The board is currently in the following state: {{board_state}} @complete_json_suffix </prompt> </rail> \"\"\"","title":"Step 1: Create the RAIL Spec"},{"location":"examples/valid_chess_moves/#step-2-create-a-guard-object-with-the-rail-spec","text":"We create a gd.Guard object that will check, validate and correct the output of the LLM. This object: Enforces the quality criteria specified in the RAIL spec. Takes corrective action when the quality criteria are not met. Compiles the schema and type info from the RAIL spec and adds it to the prompt. guard = gd . Guard . from_rail_string ( rail_str ) We see the prompt that will be sent to the LLM. The {board_state} is substituted with the current state of the board. print ( guard . base_prompt ) Generate a move for the chess board. The board is currently in the following state: { board_state } Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <string description = \"A move in standard algebraic notation.\" name = \"move\" required = \"true\" format = \"is-valid-chess-move\" / > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter ` None `. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object: Let's get the reference to the board. board = guard . output_schema . move . validators [ 0 ] . board board r n b q k b n r p p p p p p p p . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . P P P P P P P P R N B Q K B N R","title":"Step 2: Create a Guard object with the RAIL Spec"},{"location":"examples/valid_chess_moves/#step-3-wrap-the-llm-api-call-with-guard","text":"import openai raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { \"board_state\" : str ( board . move_stack ) if board . move_stack else \"Starting position.\" }, engine = \"text-davinci-003\" , max_tokens = 2048 , temperature = 0.3 , ) The guard wrapper returns the raw_llm_respose (which is a simple string), and the validated and corrected output (which is a dictionary). We can see that the output is a dictionary with the correct schema and types. print ( validated_response ) { 'move' : 'e4' } board r n b q k b n r p p p p p p p p . . . . . . . . . . . . . . . . . . . . P . . . . . . . . . . . P P P P . P P P R N B Q K B N R Let's make a move. board . push_san ( \"e5\" ) board r n b q k b n r p p p p . p p p . . . . . . . . . . . . p . . . . . . . P . . . . . . . . . . . P P P P . P P P R N B Q K B N R Ask for another move from the model. raw_llm_response , validated_response = guard ( openai . Completion . create , prompt_params = { \"board_state\" : str ( board . move_stack ) if board . move_stack else \"Starting position.\" }, engine = \"text-davinci-003\" , max_tokens = 2048 , temperature = 0.3 , ) board r n b q k b n r p p p p . p p p . . . . . . . . . . . . p . . . . . . . P . . . . . . . . N . . P P P P . P P P R N B Q K B . R board . push_san ( \"Nc6\" ) board r . b q k b n r p p p p . p p p . . n . . . . . . . . . p . . . . . . . P . . . . . . . . N . . P P P P . P P P R N B Q K B . R","title":"Step 3: Wrap the LLM API call with Guard"},{"location":"integrations/langchain/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Use Guardrails from LangChain You can use Guardrails to add a layer of security around LangChain components. Here's how to use Guardrails with LangChain. Installing dependencies Make sure you have both langchain and guardrails installed. If you don't, run the following commands: ! pip install guardrails - ai ! pip install langchain Create a RAIL spec rail_spec = \"\"\" <rail version=\"0.1\"> <output> <object name=\"patient_info\"> <string name=\"gender\" description=\"Patient's gender\" /> <integer name=\"age\" format=\"valid-range: 0 100\" /> <string name=\"symptoms\" description=\"Symptoms that the patient is currently experiencing\" /> </object> </output> <prompt> Given the following doctor's notes about a patient, please extract a dictionary that contains the patient's information. {{doctors_notes}} @complete_json_suffix_v2 </prompt> </rail> \"\"\" Create a GuardrailsOutputParser from rich import print from langchain.output_parsers import GuardrailsOutputParser from langchain.prompts import PromptTemplate from langchain.llms import OpenAI output_parser = GuardrailsOutputParser . from_rail_string ( rail_spec ) The GuardrailsOutputParser contains a Guard object, which can be used to access the prompt and output schema. E.g., here is the compiled prompt that is stored in GuardrailsOutputParser : print ( output_parser . guard . base_prompt ) Given the following doctor's notes about a patient, please extract a dictionary that contains the patient's information. { doctors_notes } Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <object name = \"patient_info\" > <string name = \"gender\" description = \"Patient's gender\" / > <integer name = \"age\" format = \"valid-range: 0 100\" / > <string name = \"symptoms\" description = \"Symptoms that the patient is currently experiencing\" / > < / object > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object: We can now create a LangChain PromptTemplate from this output parser. Create Prompt Template prompt = PromptTemplate ( template = output_parser . guard . base_prompt , input_variables = output_parser . guard . prompt . variable_names , ) Query the LLM and get formatted, validated and corrected output model = OpenAI ( temperature = 0 ) doctors_notes = \"\"\" 49 y/o Male with chronic macular rash to face & hair, worse in beard, eyebrows & nares. Itchy, flaky, slightly scaly. Moderate response to OTC steroid cream \"\"\" output = model ( prompt . format_prompt ( doctors_notes = doctors_notes ) . to_string ()) print ( output_parser . parse ( output )) /Users/shreyarajpal/anaconda3/envs/tiff-env/lib/python3.9/site-packages/eliot/json.py:22: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar. (This may have returned Python scalars in past versions. if isinstance(o, (numpy.bool, numpy.bool_)): { 'gender' : 'Male' , 'age' : 49 , 'symptoms' : 'Chronic macular rash to face & hair, worse in beard, eyebrows & nares. Itchy, flaky, slightly scaly. Moderate response to OTC steroid cream' }","title":"LangChain"},{"location":"integrations/langchain/#use-guardrails-from-langchain","text":"You can use Guardrails to add a layer of security around LangChain components. Here's how to use Guardrails with LangChain.","title":"Use Guardrails from LangChain"},{"location":"integrations/langchain/#installing-dependencies","text":"Make sure you have both langchain and guardrails installed. If you don't, run the following commands: ! pip install guardrails - ai ! pip install langchain","title":"Installing dependencies"},{"location":"integrations/langchain/#create-a-rail-spec","text":"rail_spec = \"\"\" <rail version=\"0.1\"> <output> <object name=\"patient_info\"> <string name=\"gender\" description=\"Patient's gender\" /> <integer name=\"age\" format=\"valid-range: 0 100\" /> <string name=\"symptoms\" description=\"Symptoms that the patient is currently experiencing\" /> </object> </output> <prompt> Given the following doctor's notes about a patient, please extract a dictionary that contains the patient's information. {{doctors_notes}} @complete_json_suffix_v2 </prompt> </rail> \"\"\"","title":"Create a RAIL spec"},{"location":"integrations/langchain/#create-a-guardrailsoutputparser","text":"from rich import print from langchain.output_parsers import GuardrailsOutputParser from langchain.prompts import PromptTemplate from langchain.llms import OpenAI output_parser = GuardrailsOutputParser . from_rail_string ( rail_spec ) The GuardrailsOutputParser contains a Guard object, which can be used to access the prompt and output schema. E.g., here is the compiled prompt that is stored in GuardrailsOutputParser : print ( output_parser . guard . base_prompt ) Given the following doctor's notes about a patient, please extract a dictionary that contains the patient's information. { doctors_notes } Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <object name = \"patient_info\" > <string name = \"gender\" description = \"Patient's gender\" / > <integer name = \"age\" format = \"valid-range: 0 100\" / > <string name = \"symptoms\" description = \"Symptoms that the patient is currently experiencing\" / > < / object > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object: We can now create a LangChain PromptTemplate from this output parser.","title":"Create a GuardrailsOutputParser"},{"location":"integrations/langchain/#create-prompt-template","text":"prompt = PromptTemplate ( template = output_parser . guard . base_prompt , input_variables = output_parser . guard . prompt . variable_names , )","title":"Create Prompt Template"},{"location":"integrations/langchain/#query-the-llm-and-get-formatted-validated-and-corrected-output","text":"model = OpenAI ( temperature = 0 ) doctors_notes = \"\"\" 49 y/o Male with chronic macular rash to face & hair, worse in beard, eyebrows & nares. Itchy, flaky, slightly scaly. Moderate response to OTC steroid cream \"\"\" output = model ( prompt . format_prompt ( doctors_notes = doctors_notes ) . to_string ()) print ( output_parser . parse ( output )) /Users/shreyarajpal/anaconda3/envs/tiff-env/lib/python3.9/site-packages/eliot/json.py:22: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar. (This may have returned Python scalars in past versions. if isinstance(o, (numpy.bool, numpy.bool_)): { 'gender' : 'Male' , 'age' : 49 , 'symptoms' : 'Chronic macular rash to face & hair, worse in beard, eyebrows & nares. Itchy, flaky, slightly scaly. Moderate response to OTC steroid cream' }","title":"Query the LLM and get formatted, validated and corrected output"},{"location":"integrations/pydantic_validation/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Validating LLM Outputs with Pydantic Note To download this example as a Jupyter notebook, click here . In this example, we will use Guardrails with Pydantic. Objective We want to generate synthetic data that is consistent with a Person Pydantic BaseModel. import guardrails as gd from rich import print Step 1: Create the RAIL Spec Ordinarily, we would create an RAIL spec in a separate file. For the purposes of this example, we will create the spec in this notebook as a string following the RAIL syntax. For more information on RAIL, see the RAIL documentation . Here, we define a Pydantic model for a Person with the following fields: name : a string age : an integer zip_code : a string zip code and write very simple validators for the fields as an example. As a way to show how LLM reasking can be used to generate data that is consistent with the Pydantic model, we can define a validator that asks for a zip code in California (including being perversely opposed to the \"90210\" zip code). If this validator fails, the LLM will be sent the error message and will reask the question. This Pydantic model could also be any model that you already have in your codebase, and just needs to be decorated with @register_pydantic . To use this model in the <output> specification, we used the special pydantic tag. This tag takes the name of the Pydantic model, as well as the on-fail-pydantic attribute, which specifies what to do when the output does not validate against the Pydantic model. rail_str = \"\"\" <rail version=\"0.1\"> <script language=\"python\"> from guardrails.utils.pydantic_utils import register_pydantic from pydantic import BaseModel, validator @register_pydantic class Person(BaseModel): ''' Information about a person. Args: name (str): The name of the person. age (int): The age of the person. zip_code (str): The zip code of the person. ''' name: str age: int zip_code: str @validator(\"zip_code\") def zip_code_must_be_numeric(cls, v): if not v.isnumeric(): raise ValueError(\"Zip code must be numeric.\") return v @validator(\"age\") def age_must_be_between_0_and_150(cls, v): if not 0 &lt;= v &lt;= 150: raise ValueError(\"Age must be between 0 and 150.\") return v @validator(\"zip_code\") def zip_code_in_california(cls, v): if not v.startswith(\"9\"): raise ValueError(\"Zip code must be in California, and start with 9.\") if v == \"90210\": raise ValueError(\"Zip code must not be Beverly Hills.\") return v </script> <output> <list name=\"people\" description=\"A list of 3 people.\"> <pydantic description=\"Information about a person.\" model=\"Person\" on-fail-pydantic=\"reask\" /> </list> </output> <prompt> Generate data for possible users in accordance with the specification below. @xml_prefix_prompt {output_schema} @complete_json_suffix_v2</prompt> </rail> \"\"\" Step 2: Create a Guard object with the RAIL Spec We create a gd.Guard object that will check, validate and correct the output of the LLM. This object: Enforces the quality criteria specified in the RAIL spec. Takes corrective action when the quality criteria are not met. Compiles the schema and type info from the RAIL spec and adds it to the prompt. guard = gd . Guard . from_rail_string ( rail_str ) We see the prompt that will be sent to the LLM. print ( guard . base_prompt ) Generate data for possible users in accordance with the specification below. Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <list name = \"people\" description = \"A list of 3 people.\" > <object description = \"Information about a person.\" pydantic = \"Person\" ><string name = \"name\" description = \"The name of the person.\" / ><integer name = \"age\" description = \"The age of the person.\" format = \"age-must-be-between-0-and-150\" / ><string name = \"zip_code\" description = \"The zip code of the person.\" format = \"zip-code-must-be-numeric; zip-code-in-california\" / >< / object >< / list > < / output > Given below is XML that describes the information to extract from this document and the tags to extract it into. <output> <list name = \"people\" description = \"A list of 3 people.\" > <object description = \"Information about a person.\" pydantic = \"Person\" ><string name = \"name\" description = \"The name of the person.\" / ><integer name = \"age\" description = \"The age of the person.\" format = \"age-must-be-between-0-and-150\" / ><string name = \"zip_code\" description = \"The zip code of the person.\" format = \"zip-code-must-be-numeric; zip-code-in-california\" / >< / object >< / list > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object: Note Notice that the prompt replaces the pydantic tag with the schema, validator and type information from the Pydantic model. This e.g. tells the LLM that we want that zip-code-must-be-numeric and zip-code-in-california . Guardrails will even automatically read the docstrings from the Pydantic model and add them to the prompt! Step 3: Wrap the LLM API call with Guard import openai raw_llm_response , validated_response = guard ( openai . Completion . create , engine = \"text-davinci-003\" , max_tokens = 512 , temperature = 0.5 , num_reasks = 2 , ) /Users/krandiash/opt/anaconda3/envs/guardrails/lib/python3.9/site-packages/eliot/json.py:22: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar. if isinstance(o, (numpy.bool, numpy.bool_)): print ( validated_response ) { 'people' : [ Person ( name = 'John Doe' , age = 25 , zip_code = '90000' ) , Person ( name = 'Jane Doe' , age = 30 , zip_code = '94105' ) , Person ( name = 'John Smith' , age = 40 , zip_code = '90001' ) ] } The guard wrapper returns the raw_llm_respose (which is a simple string), and the validated and corrected output (which is a dictionary). We can see that the output is a dictionary with the correct schema and contains a few Person objects! We can even print out the logs of the most recent call. Notice that the first time the LLM actually returns a Beverly Hills zip code, the LLM is sent the error message and is reasked. The second time, the LLM returns a valid zip code and the output is returned. print ( guard . state . most_recent_call ) GuardHistory ( history = [ GuardLogs ( prompt = '\\nGenerate data for possible users in accordance with the specification below.\\n\\n\\nGiven below is XML that describes the information to extract from this document and the tags to extract it into.\\n\\n\\n<output>\\n <list name=\"people\" description=\"A list of 3 people.\">\\n <object description=\"Information about a person.\" pydantic=\"Person\"><string name=\"name\" description=\"The name of the person.\"/><integer name=\"age\" description=\"The age of the person.\" format=\"age-must-be-between-0-and-150\"/><string name=\"zip_code\" description=\"The zip code of the person.\" format=\"zip-code-must-be-numeric; zip-code-in-california\"/></object></list>\\n</output>\\n\\n\\nGiven below is XML that describes the information to extract from this document and the tags to extract it into.\\n\\n<output>\\n <list name=\"people\" description=\"A list of 3 people.\">\\n <object description=\"Information about a person.\" pydantic=\"Person\"><string name=\"name\" description=\"The name of the person.\"/><integer name=\"age\" description=\"The age of the person.\" format=\"age-must-be-between-0-and-150\"/><string name=\"zip_code\" description=\"The zip code of the person.\" format=\"zip-code-must-be-numeric; zip-code-in-california\"/></object></list>\\n</output>\\n\\nONLY return a valid JSON object (no other text is necessary), where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML\\'s tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise.\\n\\nHere are examples of simple (XML, JSON) pairs that show the expected behavior:\\n- `<string name=\\'foo\\' format=\\'two-words lower-case\\' />` => `{\\'foo\\': \\'example one\\'}`\\n- `<list name=\\'bar\\'><string format=\\'upper-case\\' /></list>` => `{\"bar\": [\\'STRING ONE\\', \\'STRING TWO\\', etc.]}`\\n- `<object name=\\'baz\\'><string name=\"foo\" format=\"capitalize two-words\" /><integer name=\"index\" format=\"1-indexed\" /></object>` => `{\\'baz\\': {\\'foo\\': \\'Some String\\', \\'index\\': 1}}`\\n\\nJSON Object:' , output = ' \\n{\\n \"people\": [\\n {\\n \"name\": \"John Doe\",\\n \"age\": 25,\\n \"zip_code\": \"90210\"\\n },\\n {\\n \"name\": \"Jane Doe\",\\n \"age\": 30,\\n \"zip_code\": \"94105\"\\n },\\n {\\n \"name\": \"John Smith\",\\n \"age\": 40,\\n \"zip_code\": \"90001\"\\n }\\n ]\\n}' , output_as_dict = { 'people' : [ { 'name' : 'John Doe' , 'age' : 25 , 'zip_code' : '90210' } , { 'name' : 'Jane Doe' , 'age' : 30 , 'zip_code' : '94105' } , { 'name' : 'John Smith' , 'age' : 40 , 'zip_code' : '90001' } ] } , validated_output = { 'people' : [ { 'name' : 'John Doe' , 'age' : 25 , 'zip_code' : ReAsk ( incorrect_value = '90210' , error_message = 'Zip code must not be Beverly Hills.' , fix_value = None , path = [ 'people' , 0 ] ) } , Person ( name = 'Jane Doe' , age = 30 , zip_code = '94105' ) , Person ( name = 'John Smith' , age = 40 , zip_code = '90001' ) ] } , reasks = [ ReAsk ( incorrect_value = '90210' , error_message = 'Zip code must not be Beverly Hills.' , fix_value = None , path = [ 'people' , 0 ] ) ] ) , GuardLogs ( prompt = '\\nI was given the following JSON response, which had problems due to incorrect values.\\n\\n{\\n \"people\": [\\n {\\n \"name\": \"John Doe\",\\n \"age\": 25,\\n \"zip_code\": {\\n \"incorrect_value\": \"90210\",\\n \"error_message\": \"Zip code must not be Beverly Hills.\"\\n }\\n }\\n ]\\n}\\n\\nHelp me correct the incorrect values based on the given error messages.\\n\\nGiven below is XML that describes the information to extract from this document and the tags to extract it into.\\n\\n<output>\\n <list name=\"people\" description=\"A list of 3 people.\">\\n <object description=\"Information about a person.\" pydantic=\"Person\"><string name=\"name\" description=\"The name of the person.\"/><integer name=\"age\" description=\"The age of the person.\" format=\"age-must-be-between-0-and-150\"/><string name=\"zip_code\" description=\"The zip code of the person.\" format=\"zip-code-must-be-numeric; zip-code-in-california\"/></object></list>\\n</output>\\n\\nONLY return a valid JSON object (no other text is necessary), where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML\\'s tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter `None`.\\n\\nHere are examples of simple (XML, JSON) pairs that show the expected behavior:\\n- `<string name=\\'foo\\' format=\\'two-words lower-case\\' />` => `{{\\'foo\\': \\'example one\\'}}`\\n- `<list name=\\'bar\\'><string format=\\'upper-case\\' /></list>` => `{{\"bar\": [\\'STRING ONE\\', \\'STRING TWO\\', etc.]}}`\\n- `<object name=\\'baz\\'><string name=\"foo\" format=\"capitalize two-words\" /><integer name=\"index\" format=\"1-indexed\" /></object>` => `{{\\'baz\\': {{\\'foo\\': \\'Some String\\', \\'index\\': 1}}}}`\\n\\nJSON Object:' , output = '\\n{\\n \"people\": [\\n {\\n \"name\": \"John Doe\",\\n \"age\": 25,\\n \"zip_code\": \"90000\"\\n }\\n ]\\n}' , output_as_dict = { 'people' : [{ 'name' : 'John Doe' , 'age' : 25 , 'zip_code' : '90000' }]} , validated_output = { 'people' : [ Person ( name = 'John Doe' , age = 25 , zip_code = '90000' ) , Person ( name = 'Jane Doe' , age = 30 , zip_code = '94105' ) , Person ( name = 'John Smith' , age = 40 , zip_code = '90001' ) ] } , reasks = [] ) ] )","title":"Pydantic"},{"location":"integrations/pydantic_validation/#validating-llm-outputs-with-pydantic","text":"Note To download this example as a Jupyter notebook, click here . In this example, we will use Guardrails with Pydantic.","title":"Validating LLM Outputs with Pydantic"},{"location":"integrations/pydantic_validation/#objective","text":"We want to generate synthetic data that is consistent with a Person Pydantic BaseModel. import guardrails as gd from rich import print","title":"Objective"},{"location":"integrations/pydantic_validation/#step-1-create-the-rail-spec","text":"Ordinarily, we would create an RAIL spec in a separate file. For the purposes of this example, we will create the spec in this notebook as a string following the RAIL syntax. For more information on RAIL, see the RAIL documentation . Here, we define a Pydantic model for a Person with the following fields: name : a string age : an integer zip_code : a string zip code and write very simple validators for the fields as an example. As a way to show how LLM reasking can be used to generate data that is consistent with the Pydantic model, we can define a validator that asks for a zip code in California (including being perversely opposed to the \"90210\" zip code). If this validator fails, the LLM will be sent the error message and will reask the question. This Pydantic model could also be any model that you already have in your codebase, and just needs to be decorated with @register_pydantic . To use this model in the <output> specification, we used the special pydantic tag. This tag takes the name of the Pydantic model, as well as the on-fail-pydantic attribute, which specifies what to do when the output does not validate against the Pydantic model. rail_str = \"\"\" <rail version=\"0.1\"> <script language=\"python\"> from guardrails.utils.pydantic_utils import register_pydantic from pydantic import BaseModel, validator @register_pydantic class Person(BaseModel): ''' Information about a person. Args: name (str): The name of the person. age (int): The age of the person. zip_code (str): The zip code of the person. ''' name: str age: int zip_code: str @validator(\"zip_code\") def zip_code_must_be_numeric(cls, v): if not v.isnumeric(): raise ValueError(\"Zip code must be numeric.\") return v @validator(\"age\") def age_must_be_between_0_and_150(cls, v): if not 0 &lt;= v &lt;= 150: raise ValueError(\"Age must be between 0 and 150.\") return v @validator(\"zip_code\") def zip_code_in_california(cls, v): if not v.startswith(\"9\"): raise ValueError(\"Zip code must be in California, and start with 9.\") if v == \"90210\": raise ValueError(\"Zip code must not be Beverly Hills.\") return v </script> <output> <list name=\"people\" description=\"A list of 3 people.\"> <pydantic description=\"Information about a person.\" model=\"Person\" on-fail-pydantic=\"reask\" /> </list> </output> <prompt> Generate data for possible users in accordance with the specification below. @xml_prefix_prompt {output_schema} @complete_json_suffix_v2</prompt> </rail> \"\"\"","title":"Step 1: Create the RAIL Spec"},{"location":"integrations/pydantic_validation/#step-2-create-a-guard-object-with-the-rail-spec","text":"We create a gd.Guard object that will check, validate and correct the output of the LLM. This object: Enforces the quality criteria specified in the RAIL spec. Takes corrective action when the quality criteria are not met. Compiles the schema and type info from the RAIL spec and adds it to the prompt. guard = gd . Guard . from_rail_string ( rail_str ) We see the prompt that will be sent to the LLM. print ( guard . base_prompt ) Generate data for possible users in accordance with the specification below. Given below is XML that describes the information to extract from this document and the tags to extract it into. < output > <list name = \"people\" description = \"A list of 3 people.\" > <object description = \"Information about a person.\" pydantic = \"Person\" ><string name = \"name\" description = \"The name of the person.\" / ><integer name = \"age\" description = \"The age of the person.\" format = \"age-must-be-between-0-and-150\" / ><string name = \"zip_code\" description = \"The zip code of the person.\" format = \"zip-code-must-be-numeric; zip-code-in-california\" / >< / object >< / list > < / output > Given below is XML that describes the information to extract from this document and the tags to extract it into. <output> <list name = \"people\" description = \"A list of 3 people.\" > <object description = \"Information about a person.\" pydantic = \"Person\" ><string name = \"name\" description = \"The name of the person.\" / ><integer name = \"age\" description = \"The age of the person.\" format = \"age-must-be-between-0-and-150\" / ><string name = \"zip_code\" description = \"The zip code of the person.\" format = \"zip-code-must-be-numeric; zip-code-in-california\" / >< / object >< / list > < / output > ONLY return a valid JSON object ( no other text is necessary ) , where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML's tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. Here are examples of simple ( XML, JSON ) pairs that show the expected behavior: - `<string name = 'foo' format = 'two-words lower-case' / >` => ` {{ 'foo' : 'example one' }} ` - `<list name = 'bar' ><string format = 'upper-case' / >< / list >` => ` {{ \"bar\" : [ 'STRING ONE' , 'STRING TWO' , etc. ]}} ` - `<object name = 'baz' ><string name = \"foo\" format = \"capitalize two-words\" / ><integer name = \"index\" format = \"1-indexed\" / >< / object >` = > ` {{ 'baz' : {{ 'foo' : 'Some String' , 'index' : 1 }}}} ` JSON Object: Note Notice that the prompt replaces the pydantic tag with the schema, validator and type information from the Pydantic model. This e.g. tells the LLM that we want that zip-code-must-be-numeric and zip-code-in-california . Guardrails will even automatically read the docstrings from the Pydantic model and add them to the prompt!","title":"Step 2: Create a Guard object with the RAIL Spec"},{"location":"integrations/pydantic_validation/#step-3-wrap-the-llm-api-call-with-guard","text":"import openai raw_llm_response , validated_response = guard ( openai . Completion . create , engine = \"text-davinci-003\" , max_tokens = 512 , temperature = 0.5 , num_reasks = 2 , ) /Users/krandiash/opt/anaconda3/envs/guardrails/lib/python3.9/site-packages/eliot/json.py:22: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar. if isinstance(o, (numpy.bool, numpy.bool_)): print ( validated_response ) { 'people' : [ Person ( name = 'John Doe' , age = 25 , zip_code = '90000' ) , Person ( name = 'Jane Doe' , age = 30 , zip_code = '94105' ) , Person ( name = 'John Smith' , age = 40 , zip_code = '90001' ) ] } The guard wrapper returns the raw_llm_respose (which is a simple string), and the validated and corrected output (which is a dictionary). We can see that the output is a dictionary with the correct schema and contains a few Person objects! We can even print out the logs of the most recent call. Notice that the first time the LLM actually returns a Beverly Hills zip code, the LLM is sent the error message and is reasked. The second time, the LLM returns a valid zip code and the output is returned. print ( guard . state . most_recent_call ) GuardHistory ( history = [ GuardLogs ( prompt = '\\nGenerate data for possible users in accordance with the specification below.\\n\\n\\nGiven below is XML that describes the information to extract from this document and the tags to extract it into.\\n\\n\\n<output>\\n <list name=\"people\" description=\"A list of 3 people.\">\\n <object description=\"Information about a person.\" pydantic=\"Person\"><string name=\"name\" description=\"The name of the person.\"/><integer name=\"age\" description=\"The age of the person.\" format=\"age-must-be-between-0-and-150\"/><string name=\"zip_code\" description=\"The zip code of the person.\" format=\"zip-code-must-be-numeric; zip-code-in-california\"/></object></list>\\n</output>\\n\\n\\nGiven below is XML that describes the information to extract from this document and the tags to extract it into.\\n\\n<output>\\n <list name=\"people\" description=\"A list of 3 people.\">\\n <object description=\"Information about a person.\" pydantic=\"Person\"><string name=\"name\" description=\"The name of the person.\"/><integer name=\"age\" description=\"The age of the person.\" format=\"age-must-be-between-0-and-150\"/><string name=\"zip_code\" description=\"The zip code of the person.\" format=\"zip-code-must-be-numeric; zip-code-in-california\"/></object></list>\\n</output>\\n\\nONLY return a valid JSON object (no other text is necessary), where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML\\'s tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise.\\n\\nHere are examples of simple (XML, JSON) pairs that show the expected behavior:\\n- `<string name=\\'foo\\' format=\\'two-words lower-case\\' />` => `{\\'foo\\': \\'example one\\'}`\\n- `<list name=\\'bar\\'><string format=\\'upper-case\\' /></list>` => `{\"bar\": [\\'STRING ONE\\', \\'STRING TWO\\', etc.]}`\\n- `<object name=\\'baz\\'><string name=\"foo\" format=\"capitalize two-words\" /><integer name=\"index\" format=\"1-indexed\" /></object>` => `{\\'baz\\': {\\'foo\\': \\'Some String\\', \\'index\\': 1}}`\\n\\nJSON Object:' , output = ' \\n{\\n \"people\": [\\n {\\n \"name\": \"John Doe\",\\n \"age\": 25,\\n \"zip_code\": \"90210\"\\n },\\n {\\n \"name\": \"Jane Doe\",\\n \"age\": 30,\\n \"zip_code\": \"94105\"\\n },\\n {\\n \"name\": \"John Smith\",\\n \"age\": 40,\\n \"zip_code\": \"90001\"\\n }\\n ]\\n}' , output_as_dict = { 'people' : [ { 'name' : 'John Doe' , 'age' : 25 , 'zip_code' : '90210' } , { 'name' : 'Jane Doe' , 'age' : 30 , 'zip_code' : '94105' } , { 'name' : 'John Smith' , 'age' : 40 , 'zip_code' : '90001' } ] } , validated_output = { 'people' : [ { 'name' : 'John Doe' , 'age' : 25 , 'zip_code' : ReAsk ( incorrect_value = '90210' , error_message = 'Zip code must not be Beverly Hills.' , fix_value = None , path = [ 'people' , 0 ] ) } , Person ( name = 'Jane Doe' , age = 30 , zip_code = '94105' ) , Person ( name = 'John Smith' , age = 40 , zip_code = '90001' ) ] } , reasks = [ ReAsk ( incorrect_value = '90210' , error_message = 'Zip code must not be Beverly Hills.' , fix_value = None , path = [ 'people' , 0 ] ) ] ) , GuardLogs ( prompt = '\\nI was given the following JSON response, which had problems due to incorrect values.\\n\\n{\\n \"people\": [\\n {\\n \"name\": \"John Doe\",\\n \"age\": 25,\\n \"zip_code\": {\\n \"incorrect_value\": \"90210\",\\n \"error_message\": \"Zip code must not be Beverly Hills.\"\\n }\\n }\\n ]\\n}\\n\\nHelp me correct the incorrect values based on the given error messages.\\n\\nGiven below is XML that describes the information to extract from this document and the tags to extract it into.\\n\\n<output>\\n <list name=\"people\" description=\"A list of 3 people.\">\\n <object description=\"Information about a person.\" pydantic=\"Person\"><string name=\"name\" description=\"The name of the person.\"/><integer name=\"age\" description=\"The age of the person.\" format=\"age-must-be-between-0-and-150\"/><string name=\"zip_code\" description=\"The zip code of the person.\" format=\"zip-code-must-be-numeric; zip-code-in-california\"/></object></list>\\n</output>\\n\\nONLY return a valid JSON object (no other text is necessary), where the key of the field in JSON is the `name` attribute of the corresponding XML, and the value is of the type specified by the corresponding XML\\'s tag. The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter `None`.\\n\\nHere are examples of simple (XML, JSON) pairs that show the expected behavior:\\n- `<string name=\\'foo\\' format=\\'two-words lower-case\\' />` => `{{\\'foo\\': \\'example one\\'}}`\\n- `<list name=\\'bar\\'><string format=\\'upper-case\\' /></list>` => `{{\"bar\": [\\'STRING ONE\\', \\'STRING TWO\\', etc.]}}`\\n- `<object name=\\'baz\\'><string name=\"foo\" format=\"capitalize two-words\" /><integer name=\"index\" format=\"1-indexed\" /></object>` => `{{\\'baz\\': {{\\'foo\\': \\'Some String\\', \\'index\\': 1}}}}`\\n\\nJSON Object:' , output = '\\n{\\n \"people\": [\\n {\\n \"name\": \"John Doe\",\\n \"age\": 25,\\n \"zip_code\": \"90000\"\\n }\\n ]\\n}' , output_as_dict = { 'people' : [{ 'name' : 'John Doe' , 'age' : 25 , 'zip_code' : '90000' }]} , validated_output = { 'people' : [ Person ( name = 'John Doe' , age = 25 , zip_code = '90000' ) , Person ( name = 'Jane Doe' , age = 30 , zip_code = '94105' ) , Person ( name = 'John Smith' , age = 40 , zip_code = '90001' ) ] } , reasks = [] ) ] )","title":"Step 3: Wrap the LLM API call with Guard"},{"location":"rail/","text":"Overview \ud83e\udd16 What is RAIL ? .RAIL is a dialect of XML. It stands for \" R eliable AI markup L anguage\", and it can be used to define: The structure of the expected outcome of the LLM. (E.g. JSON) The type of each field in the expected outcome. (E.g. string, integer, list, object) The quality criteria for the expected outcome to be considered valid. (E.g. generated text should be bias-free, generated code should be bug-free) The corrective action to take in case the quality criteria is not met. (E.g. reask the question, filter the LLM, progrmatically fix, etc.) Expand to see an example of a RAIL specification. <rail version= \"0.1\" > <output> <list name= \"fees\" description= \"What fees and charges are associated with my account?\" > <object> <integer name= \"index\" format= \"1-indexed\" /> <string name= \"name\" format= \"lower-case; two-words\" on-fail-lower-case= \"noop\" on-fail-two-words= \"reask\" /> <string name= \"explanation\" format= \"one-line\" on-fail-one-line= \"noop\" /> <float name= \"value\" format= \"percentage\" /> </object> </list> <string name= 'interest_rates' description= 'What are the interest rates offered by the bank on savings and checking accounts, loans, and credit products?' format= \"one-line\" on-fail-one-line= \"noop\" /> </output> <prompt> Given the following document, answer the following questions. If the answer doesn't exist in the document, enter 'None'. {document} @xml_prefix_prompt {{output_schema}} @json_suffix_prompt </prompt> <script language= 'python' > from guardrails.validators import Validator, EventDetail, register_validator import random @register_validator(name=\"custom\", data_type=\"any\") class CustomValidator(Validator): def __init__(self, *args, **kwargs): super(CustomValidator, self).__init__(*args, **kwargs) def validate(self, key: str, value: Any, schema: Union[Dict, List]): \"\"\"Validate that a value is within a range.\"\"\" logger.debug(f\"Validating {value} is in choices {self._choices}...\") if random.random() > 0.5: raise EventDetail( key, value, schema, f\"Value {value} is not in choices {self._choices}.\", None, ) return schema </script> </rail> \ud83e\udd14 Why RAIL ? Language agnostic: RAIL Specifications can be enforced in any language. Simple and familiar: RAIL should be familiar to anyone familiar with HTML, and should be easy to learn. Validation and correction : RAIL can be used to define quality criteria for the expected output, and corrective actions to take in case the quality criteria is not met. Can define complex structures: RAIL can be used to define arbitrarily complex structures, such as nested lists, nested objects, etc. Supports writing custom code: If needed, RAIL supports writing code for using validators, custom corrective actions, etc. To see examples of this, check out the RAIL Script page. Code assistance : In the future, we plan to support code completion and IntelliSense for RAIL specifications, which will make it very easy to write RAIL specifications. Design inspiration HTML, CSS and Javascript: RAIL spec is a dialect of XML, and so is similar to HTML. Specifying quality criteria is done via the format attribute, which is similar to CSS style tags. Corrective actions are specified via the on-fail-* attributes, which is similar to Javascript event handlers. OpenAPI as an open standard for creating machine-readable RESTful APIs. \ud83d\udcda Components of an RAIL Specification The RAIL specification contains 3 main components: Output : Contains information about the expected output of the LLM. It contains the spec for the overall structure of the LLM output, type info for each field, and the quality criteria for each field and the corrective action to be taken in case quality criteria is not met. This is the main component of the RAIL specification, which enforces the guarantees that the LLM should provide. Check out the RAIL Output page for more details, including the full specifcation of how to create complex output schemas. Prompt : Prompt template, and contains the high level instructions that are sent to the LLM. Check out the RAIL Prompt page for more details. (Experimental) (Optional) Script : Contains any custom code for implementing the schema. This is useful for implementing custom validators, custom corrective actions, etc. Check out the RAIL Script page for more details. Let's see an example of an RAIL specification in action: <rail version= \"0.1\" > <output> <!-- (1)! --> ... </output> <prompt> <!-- (2)! --> ... </prompt> <script language= python > <!-- (3)! --> ... </script> </rail> The output element contains the structure of the expected output of the LLM. It contains the spec for the overall structure of the LLM output, type info for each field, and the quality criteria for each field and the corrective action to be taken in case quality criteria is not met. The prompt element contains the high level instructions that are sent to the LLM. Check out the RAIL Prompt page for more details. The script element is optional, and contains any custom code for implementing the schema. \ud83d\udcd6 How to use RAIL in Guardrails? After creating a RAIL specification, you can use it to get corrected output from LLMs by wrapping your LLM API call with a Guard module. Here's an example of doing that: import guardrails as gd # Create a Guard object guard = gd . Guard . from_rail ( 'path/to/rail/spec.xml' ) # (1)! validated_output = guard ( openai . Completion . create , # (2)! ** prompt_args , * args , ** kwargs ) A Guard object is created from a RAIL specification. This object manages the validation and correction of the output of the LLM, as well as the prompt that is sent to the LLM. Wrap the LLM API call ( openai.Completion.create ) with the Guard object, and add any additional arguments that you want to pass to the LLM API call. Instead of returning the raw text object, the Guard object will return a JSON object that is validated and corrected according to the RAIL specification.","title":"Overview"},{"location":"rail/#overview","text":"","title":"Overview"},{"location":"rail/#what-is-rail","text":".RAIL is a dialect of XML. It stands for \" R eliable AI markup L anguage\", and it can be used to define: The structure of the expected outcome of the LLM. (E.g. JSON) The type of each field in the expected outcome. (E.g. string, integer, list, object) The quality criteria for the expected outcome to be considered valid. (E.g. generated text should be bias-free, generated code should be bug-free) The corrective action to take in case the quality criteria is not met. (E.g. reask the question, filter the LLM, progrmatically fix, etc.) Expand to see an example of a RAIL specification. <rail version= \"0.1\" > <output> <list name= \"fees\" description= \"What fees and charges are associated with my account?\" > <object> <integer name= \"index\" format= \"1-indexed\" /> <string name= \"name\" format= \"lower-case; two-words\" on-fail-lower-case= \"noop\" on-fail-two-words= \"reask\" /> <string name= \"explanation\" format= \"one-line\" on-fail-one-line= \"noop\" /> <float name= \"value\" format= \"percentage\" /> </object> </list> <string name= 'interest_rates' description= 'What are the interest rates offered by the bank on savings and checking accounts, loans, and credit products?' format= \"one-line\" on-fail-one-line= \"noop\" /> </output> <prompt> Given the following document, answer the following questions. If the answer doesn't exist in the document, enter 'None'. {document} @xml_prefix_prompt {{output_schema}} @json_suffix_prompt </prompt> <script language= 'python' > from guardrails.validators import Validator, EventDetail, register_validator import random @register_validator(name=\"custom\", data_type=\"any\") class CustomValidator(Validator): def __init__(self, *args, **kwargs): super(CustomValidator, self).__init__(*args, **kwargs) def validate(self, key: str, value: Any, schema: Union[Dict, List]): \"\"\"Validate that a value is within a range.\"\"\" logger.debug(f\"Validating {value} is in choices {self._choices}...\") if random.random() > 0.5: raise EventDetail( key, value, schema, f\"Value {value} is not in choices {self._choices}.\", None, ) return schema </script> </rail>","title":"\ud83e\udd16 What is RAIL?"},{"location":"rail/#why-rail","text":"Language agnostic: RAIL Specifications can be enforced in any language. Simple and familiar: RAIL should be familiar to anyone familiar with HTML, and should be easy to learn. Validation and correction : RAIL can be used to define quality criteria for the expected output, and corrective actions to take in case the quality criteria is not met. Can define complex structures: RAIL can be used to define arbitrarily complex structures, such as nested lists, nested objects, etc. Supports writing custom code: If needed, RAIL supports writing code for using validators, custom corrective actions, etc. To see examples of this, check out the RAIL Script page. Code assistance : In the future, we plan to support code completion and IntelliSense for RAIL specifications, which will make it very easy to write RAIL specifications. Design inspiration HTML, CSS and Javascript: RAIL spec is a dialect of XML, and so is similar to HTML. Specifying quality criteria is done via the format attribute, which is similar to CSS style tags. Corrective actions are specified via the on-fail-* attributes, which is similar to Javascript event handlers. OpenAPI as an open standard for creating machine-readable RESTful APIs.","title":"\ud83e\udd14 Why RAIL?"},{"location":"rail/#components-of-an-rail-specification","text":"The RAIL specification contains 3 main components: Output : Contains information about the expected output of the LLM. It contains the spec for the overall structure of the LLM output, type info for each field, and the quality criteria for each field and the corrective action to be taken in case quality criteria is not met. This is the main component of the RAIL specification, which enforces the guarantees that the LLM should provide. Check out the RAIL Output page for more details, including the full specifcation of how to create complex output schemas. Prompt : Prompt template, and contains the high level instructions that are sent to the LLM. Check out the RAIL Prompt page for more details. (Experimental) (Optional) Script : Contains any custom code for implementing the schema. This is useful for implementing custom validators, custom corrective actions, etc. Check out the RAIL Script page for more details. Let's see an example of an RAIL specification in action: <rail version= \"0.1\" > <output> <!-- (1)! --> ... </output> <prompt> <!-- (2)! --> ... </prompt> <script language= python > <!-- (3)! --> ... </script> </rail> The output element contains the structure of the expected output of the LLM. It contains the spec for the overall structure of the LLM output, type info for each field, and the quality criteria for each field and the corrective action to be taken in case quality criteria is not met. The prompt element contains the high level instructions that are sent to the LLM. Check out the RAIL Prompt page for more details. The script element is optional, and contains any custom code for implementing the schema.","title":"\ud83d\udcda Components of an RAIL Specification"},{"location":"rail/#how-to-use-rail-in-guardrails","text":"After creating a RAIL specification, you can use it to get corrected output from LLMs by wrapping your LLM API call with a Guard module. Here's an example of doing that: import guardrails as gd # Create a Guard object guard = gd . Guard . from_rail ( 'path/to/rail/spec.xml' ) # (1)! validated_output = guard ( openai . Completion . create , # (2)! ** prompt_args , * args , ** kwargs ) A Guard object is created from a RAIL specification. This object manages the validation and correction of the output of the LLM, as well as the prompt that is sent to the LLM. Wrap the LLM API call ( openai.Completion.create ) with the Guard object, and add any additional arguments that you want to pass to the LLM API call. Instead of returning the raw text object, the Guard object will return a JSON object that is validated and corrected according to the RAIL specification.","title":"\ud83d\udcd6 How to use RAIL in Guardrails?"},{"location":"rail/output/","text":"Output Element The <output>...</output> element of a RAIL spec is used to give precise specification of the expected output of the LLM. It specifies the structure of the expected output (e.g. JSON), the type of each field, the quality criteria for each field to be considered valid (e.g. generated text should be bias-free, generated code should be bug-free), and the corrective action to take in case the quality criteria is not met (e.g. reask the question to the LLM, filter offending values, progrmatically fix, etc.) Example: RAIL Spec Output JSON <rail version= \"0.1\" > <output> <string name= \"text\" description= \"The generated text\" format= \"two-words\" on-fail-two-words= \"reask\" /> <float name= \"score\" description= \"The score of the generated text\" format= \"min-val: 0\" on-fail-min-val= \"fix\" /> <object name= \"metadata\" description= \"The metadata associated with the generated text\" > <string name= \"key_1\" description= \"description of key_1\" /> ... </object> </output> </rail> { \"text\" : \"string output\" , \"score\" : 0.0 , \"metadata\" : { \"key_1\" : \"string\" , ... } } \ud83c\udff7\ufe0f RAIL Elements At the heart of the RAIL specification is the use of elements. Each element's tag represents a type of data. For example, in the element <string ... /> , the tag represents a string, the <integer ... /> elements represents an integer, the <object ...></object> element represents an object, etc. Note The tag of RAIL element is the same as the \"type\" of the data it represents. E.g. <string .../> element will generate a string, <integer .../> element will generate an integer, etc. Supported types Guardrails supports many data types, including:, string , integer , float , boolean , list , object , url , email and many more. Check out the RAIL Data Types page for a list of supported data types. Scalar vs Non-scalar types Guardrails supports two types of data types: scalar and non-scalar. Scalar Non Scalar Scalar types are void elements, and can't have any child elements. Non-scalar types can be non-void, and can have closing tags and child elements. Syntax: <string ... /> Syntax: Examples: string , integer , float , boolean , url , email , etc. Examples: list and object are the only non-scalar types supported by Guardrails. Supported attributes Each element can have attributes that specify additional information about the data, such as: name attribute that specifies the name of the field. This will be the key in the output JSON. E.g. RAIL Spec Output JSON <rail version= \"0.1\" > <output> <string name= \"some_key\" /> </output> </rail> { \"some_key\" : \"...\" } description attribute that specifies the description of the field. This is similar to a prompt that will be provided to the LLM. It can contain more context to help the LLM generate the correct output. (Coming soon!) required attribute that specifies whether the field is required or not. If the field is required, the LLM will be asked to generate the field until it is generated correctly. If the field is not required, the LLM will not be asked to generate the field if it is not generated correctly. format attribute that specifies the quality criteria that the field should respect. The format attribute can contain multiple quality criteria separated by a colon ( ; ). For example, two-words; upper-case . on-fail-{quality-criteria} attribute that specifies the corrective action to take in case the quality criteria is not met. For example, on-fail-two-words=\"reask\" specifies that if the field does not have two words, the LLM should be asked to re-generate the field. E.g., RAIL Spec Output JSON <rail version= \"0.1\" > <output> <string name= \"some_key\" description= \"Detailed description of what the value of the key should be\" required= \"true\" format= \"two-words; upper-case\" on-fail-two-words= \"reask\" on-fail-upper-case= \"noop\" /> </output> </rail> { \"some_key\" : \"SOME STRING\" } \u26a1 Specifying output structure You can combine RAIL elements to create an arbitrarily complex output structure. Flat JSON output RAIL Spec Output JSON <rail version= \"0.1\" > <output> <string name= \"some_key\" .... /> <integer name= \"some_other_key\" .... /> </output> </rail> { \"some_key\" : \"string\" , \"some_other_key\" : 0 } JSON output with objects object elements can be used to specify a JSON object, which is a collection of key-value pairs. A child of an object element represents a key in the JSON object. The child element can be any RAIL element, including another list or object elements. The value of the key is generated by the LLM based on the info provided by the child element. An object element can have multiple children, each of which can be any RAIL element, including another list or object elements. Formatters can be applied to the child elements of an object element. For example, if the child element is a string element, the format attribute can be used to specify the quality criteria for the strings in the list. RAIL Spec Output JSON <rail version= \"0.1\" > <output> <object name= \"some_object\" > <string name= \"some_str_key\" description= \"What should the value for this key represent?\" format= \"two-words; upper-case\" /> <integer name= \"some_other_key\" description= \"What should this integer represent?\" format= \"min-val: 0\" /> </object> </output> </rail> { \"some_object\" : { \"some_str_key\" : \"SOME STRING\" , \"some_other_key\" : 0 } } In the above example, \"SOME STRING\" is the value for the some_str_key key, and is generated based on the name, description and quality criteria provided by the <string name=\"some_str_key\" ... /> element. Note The object element doesn't need to have children. If child elements are not provided, the LLM will automatically generate keys and values for the object based on the name , description and format attributes of the object element. Providing child elements is useful when you want to specify the keys and values that the LLM should generate. JSON output with lists list elements can be used to specify a list of values. Currently, a list element can only contain a single child element. This means that a list can only contain a single type of data. For example, a list can only contain strings, or a list can only contain integers, but a list cannot contain both strings and integers. This child element can be any RAIL element, including another list or object elements. The child of a list element doesn't need to have a name attribute, since items in a list don't have names. Formatters can be applied to the child element of a list element. For example, if the child element is a string element, the format attribute can be used to specify the quality criteria for the strings in the list. RAIL Spec Output JSON <rail version= \"0.1\" > <output> <list name= \"some_list\" format= \"min-len: 2\" > <string format= \"two-words; upper-case\" /> </list> </output> </rail> { \"some_list\" : [ \"STRING 1\" , \"STRING 2\" ] } Note The list element doesn't need to have a child element. If a child element is not provided, the LLM will automatically generate values for the list based on the name , description and format attributes of the list element. Providing a child element is useful when you want to have more control over the values that the LLM should generate. \ud83c\udf40 Specifying quality criteria The format attribute allows specifying the quality criteria for each field in the expected output. The format attribute can contain multiple quality criteria separated by a colon ( ; ). For example, <rail version= \"0.1\" > <output> <string name= \"text\" description= \"The generated text\" format= \"two-words; upper-case\" on-fail-two-words= \"reask\" /> </output> </rail> The above example specifies that the text field should be a string with two words and the text should be returned in upper case. Quality criteria under the hood Under the hood, the format attribute is parsed into a list of quality criteria. Each quality criteria is backed by a Validator class that checks if the generated output meets the quality criteria. For example, the two-words quality criteria is backed by the TwoWords class, which checks if the generated output has two words. Each quality criteria is then checked against the generated output. If the quality criteria is not met, the corrective action specified by the on-fail-{quality-criteria} attribute is taken. Supported criteria Each quality critera is relevant to a specific data type. For example, the two-words quality criteria is only relevant to strings, and the positive quality criteria is only relevant to integers and floats. To see the full list of supported quality criteria, check out the Validation page. \ud83d\udee0\ufe0f Specifying corrective actions The on-fail-{quality-criteria} attribute allows specifying the corrective action that should be taken if the quality criteria is not met. The corrective action can be one of the following: Action Behavior reask Reask the LLM to generate an output that meets the quality criteria. The prompt used for reasking contains information about which quality criteria failed, which is auto-generated by the validator. fix Programmatically fix the generated output to meet the quality criteria. E.g. for the formatter two-words , the programatic fix simply takes the first 2 words of the generated string. filter Filter the incorrect value. This only filters the field that fails, and will return the rest of the generated output. refrain Refrain from returning an output. If a formatter has the corrective action refrain, then on failure there will be a None output returned instead of the JSON. noop Do nothing. The failure will still be recorded in the logs, but no corrective action will be taken. \ud83d\ude92 Adding compiled output element to prompt In order to generate the correct LLM output, the output schema needs to be compiled and added to the prompt. This is handled automatically by the Guardrails library. The output element can be compiled into different formats to be used in the prompt. Currently, only a passthrough compilation into XML is supported, but in the future we will support additional compilation formats like TypeScript . Passthrough ( XML ) compilation By default, the output element will be compiled into XML and added to the prompt. Compilation into XML involves removing any on-fail-{quality-criteria} attributes, and adding the output element to the prompt. An example of the compiled output element: RAIL Spec Compiled XML added to prompt <rail version= \"0.1\" > <output> <string name= \"text\" description= \"The generated text\" format= \"two-words; upper-case\" /> </output> </rail> <output> <string name= \"text\" description= \"The generated text\" /> </output> TypeScript Compilation Coming soon! \u2753 Unsupported tags and attributes By default, Guardrails will not throw an error if you add an unsupported type, attribute or quality criteria. Instead, it will treat the unsupported type as a string, and will not perform any quality checks on the field. Often, LLMs will generate a string for an unsupported type, so this behavior is useful. Unsupported tags and attributes will still be included in the output schema definition that is appended to the prompt. This behavior can be changed by setting the strict attribute of the <output> element to true . If strict is set to true , Guardrails will throw an error if you add an unsupported type, attribute or quality criteria. <rail version= \"0.1\" > <output strict= \"true\" > <unsupported-type ... /> </output> </rail> This will throw an error: \u274c Error: Unsupported type: unsupported-type","title":"Output Element"},{"location":"rail/output/#output-element","text":"The <output>...</output> element of a RAIL spec is used to give precise specification of the expected output of the LLM. It specifies the structure of the expected output (e.g. JSON), the type of each field, the quality criteria for each field to be considered valid (e.g. generated text should be bias-free, generated code should be bug-free), and the corrective action to take in case the quality criteria is not met (e.g. reask the question to the LLM, filter offending values, progrmatically fix, etc.) Example: RAIL Spec Output JSON <rail version= \"0.1\" > <output> <string name= \"text\" description= \"The generated text\" format= \"two-words\" on-fail-two-words= \"reask\" /> <float name= \"score\" description= \"The score of the generated text\" format= \"min-val: 0\" on-fail-min-val= \"fix\" /> <object name= \"metadata\" description= \"The metadata associated with the generated text\" > <string name= \"key_1\" description= \"description of key_1\" /> ... </object> </output> </rail> { \"text\" : \"string output\" , \"score\" : 0.0 , \"metadata\" : { \"key_1\" : \"string\" , ... } }","title":"Output Element"},{"location":"rail/output/#rail-elements","text":"At the heart of the RAIL specification is the use of elements. Each element's tag represents a type of data. For example, in the element <string ... /> , the tag represents a string, the <integer ... /> elements represents an integer, the <object ...></object> element represents an object, etc. Note The tag of RAIL element is the same as the \"type\" of the data it represents. E.g. <string .../> element will generate a string, <integer .../> element will generate an integer, etc.","title":"\ud83c\udff7\ufe0f RAIL Elements"},{"location":"rail/output/#supported-types","text":"Guardrails supports many data types, including:, string , integer , float , boolean , list , object , url , email and many more. Check out the RAIL Data Types page for a list of supported data types.","title":"Supported types"},{"location":"rail/output/#scalar-vs-non-scalar-types","text":"Guardrails supports two types of data types: scalar and non-scalar. Scalar Non Scalar Scalar types are void elements, and can't have any child elements. Non-scalar types can be non-void, and can have closing tags and child elements. Syntax: <string ... /> Syntax: Examples: string , integer , float , boolean , url , email , etc. Examples: list and object are the only non-scalar types supported by Guardrails.","title":"Scalar vs Non-scalar types"},{"location":"rail/output/#supported-attributes","text":"Each element can have attributes that specify additional information about the data, such as: name attribute that specifies the name of the field. This will be the key in the output JSON. E.g. RAIL Spec Output JSON <rail version= \"0.1\" > <output> <string name= \"some_key\" /> </output> </rail> { \"some_key\" : \"...\" } description attribute that specifies the description of the field. This is similar to a prompt that will be provided to the LLM. It can contain more context to help the LLM generate the correct output. (Coming soon!) required attribute that specifies whether the field is required or not. If the field is required, the LLM will be asked to generate the field until it is generated correctly. If the field is not required, the LLM will not be asked to generate the field if it is not generated correctly. format attribute that specifies the quality criteria that the field should respect. The format attribute can contain multiple quality criteria separated by a colon ( ; ). For example, two-words; upper-case . on-fail-{quality-criteria} attribute that specifies the corrective action to take in case the quality criteria is not met. For example, on-fail-two-words=\"reask\" specifies that if the field does not have two words, the LLM should be asked to re-generate the field. E.g., RAIL Spec Output JSON <rail version= \"0.1\" > <output> <string name= \"some_key\" description= \"Detailed description of what the value of the key should be\" required= \"true\" format= \"two-words; upper-case\" on-fail-two-words= \"reask\" on-fail-upper-case= \"noop\" /> </output> </rail> { \"some_key\" : \"SOME STRING\" }","title":"Supported attributes"},{"location":"rail/output/#specifying-output-structure","text":"You can combine RAIL elements to create an arbitrarily complex output structure.","title":"\u26a1 Specifying output structure"},{"location":"rail/output/#flat-json-output","text":"RAIL Spec Output JSON <rail version= \"0.1\" > <output> <string name= \"some_key\" .... /> <integer name= \"some_other_key\" .... /> </output> </rail> { \"some_key\" : \"string\" , \"some_other_key\" : 0 }","title":"Flat JSON output"},{"location":"rail/output/#json-output-with-objects","text":"object elements can be used to specify a JSON object, which is a collection of key-value pairs. A child of an object element represents a key in the JSON object. The child element can be any RAIL element, including another list or object elements. The value of the key is generated by the LLM based on the info provided by the child element. An object element can have multiple children, each of which can be any RAIL element, including another list or object elements. Formatters can be applied to the child elements of an object element. For example, if the child element is a string element, the format attribute can be used to specify the quality criteria for the strings in the list. RAIL Spec Output JSON <rail version= \"0.1\" > <output> <object name= \"some_object\" > <string name= \"some_str_key\" description= \"What should the value for this key represent?\" format= \"two-words; upper-case\" /> <integer name= \"some_other_key\" description= \"What should this integer represent?\" format= \"min-val: 0\" /> </object> </output> </rail> { \"some_object\" : { \"some_str_key\" : \"SOME STRING\" , \"some_other_key\" : 0 } } In the above example, \"SOME STRING\" is the value for the some_str_key key, and is generated based on the name, description and quality criteria provided by the <string name=\"some_str_key\" ... /> element. Note The object element doesn't need to have children. If child elements are not provided, the LLM will automatically generate keys and values for the object based on the name , description and format attributes of the object element. Providing child elements is useful when you want to specify the keys and values that the LLM should generate.","title":"JSON output with objects"},{"location":"rail/output/#json-output-with-lists","text":"list elements can be used to specify a list of values. Currently, a list element can only contain a single child element. This means that a list can only contain a single type of data. For example, a list can only contain strings, or a list can only contain integers, but a list cannot contain both strings and integers. This child element can be any RAIL element, including another list or object elements. The child of a list element doesn't need to have a name attribute, since items in a list don't have names. Formatters can be applied to the child element of a list element. For example, if the child element is a string element, the format attribute can be used to specify the quality criteria for the strings in the list. RAIL Spec Output JSON <rail version= \"0.1\" > <output> <list name= \"some_list\" format= \"min-len: 2\" > <string format= \"two-words; upper-case\" /> </list> </output> </rail> { \"some_list\" : [ \"STRING 1\" , \"STRING 2\" ] } Note The list element doesn't need to have a child element. If a child element is not provided, the LLM will automatically generate values for the list based on the name , description and format attributes of the list element. Providing a child element is useful when you want to have more control over the values that the LLM should generate.","title":"JSON output with lists"},{"location":"rail/output/#specifying-quality-criteria","text":"The format attribute allows specifying the quality criteria for each field in the expected output. The format attribute can contain multiple quality criteria separated by a colon ( ; ). For example, <rail version= \"0.1\" > <output> <string name= \"text\" description= \"The generated text\" format= \"two-words; upper-case\" on-fail-two-words= \"reask\" /> </output> </rail> The above example specifies that the text field should be a string with two words and the text should be returned in upper case.","title":"\ud83c\udf40 Specifying quality criteria"},{"location":"rail/output/#quality-criteria-under-the-hood","text":"Under the hood, the format attribute is parsed into a list of quality criteria. Each quality criteria is backed by a Validator class that checks if the generated output meets the quality criteria. For example, the two-words quality criteria is backed by the TwoWords class, which checks if the generated output has two words. Each quality criteria is then checked against the generated output. If the quality criteria is not met, the corrective action specified by the on-fail-{quality-criteria} attribute is taken.","title":"Quality criteria under the hood"},{"location":"rail/output/#supported-criteria","text":"Each quality critera is relevant to a specific data type. For example, the two-words quality criteria is only relevant to strings, and the positive quality criteria is only relevant to integers and floats. To see the full list of supported quality criteria, check out the Validation page.","title":"Supported criteria"},{"location":"rail/output/#specifying-corrective-actions","text":"The on-fail-{quality-criteria} attribute allows specifying the corrective action that should be taken if the quality criteria is not met. The corrective action can be one of the following: Action Behavior reask Reask the LLM to generate an output that meets the quality criteria. The prompt used for reasking contains information about which quality criteria failed, which is auto-generated by the validator. fix Programmatically fix the generated output to meet the quality criteria. E.g. for the formatter two-words , the programatic fix simply takes the first 2 words of the generated string. filter Filter the incorrect value. This only filters the field that fails, and will return the rest of the generated output. refrain Refrain from returning an output. If a formatter has the corrective action refrain, then on failure there will be a None output returned instead of the JSON. noop Do nothing. The failure will still be recorded in the logs, but no corrective action will be taken.","title":"\ud83d\udee0\ufe0f Specifying corrective actions"},{"location":"rail/output/#adding-compiled-output-element-to-prompt","text":"In order to generate the correct LLM output, the output schema needs to be compiled and added to the prompt. This is handled automatically by the Guardrails library. The output element can be compiled into different formats to be used in the prompt. Currently, only a passthrough compilation into XML is supported, but in the future we will support additional compilation formats like TypeScript .","title":"\ud83d\ude92 Adding compiled output element to prompt"},{"location":"rail/output/#passthrough-xml-compilation","text":"By default, the output element will be compiled into XML and added to the prompt. Compilation into XML involves removing any on-fail-{quality-criteria} attributes, and adding the output element to the prompt. An example of the compiled output element: RAIL Spec Compiled XML added to prompt <rail version= \"0.1\" > <output> <string name= \"text\" description= \"The generated text\" format= \"two-words; upper-case\" /> </output> </rail> <output> <string name= \"text\" description= \"The generated text\" /> </output>","title":"Passthrough (XML) compilation"},{"location":"rail/output/#typescript-compilation","text":"Coming soon!","title":"TypeScript Compilation"},{"location":"rail/output/#unsupported-tags-and-attributes","text":"By default, Guardrails will not throw an error if you add an unsupported type, attribute or quality criteria. Instead, it will treat the unsupported type as a string, and will not perform any quality checks on the field. Often, LLMs will generate a string for an unsupported type, so this behavior is useful. Unsupported tags and attributes will still be included in the output schema definition that is appended to the prompt. This behavior can be changed by setting the strict attribute of the <output> element to true . If strict is set to true , Guardrails will throw an error if you add an unsupported type, attribute or quality criteria. <rail version= \"0.1\" > <output strict= \"true\" > <unsupported-type ... /> </output> </rail> This will throw an error: \u274c Error: Unsupported type: unsupported-type","title":"\u2753 Unsupported tags and attributes"},{"location":"rail/prompt/","text":"Prompt Element The <prompt></prompt> element contains the high level instructions sent to the LLM, that describe the high level task. \ud83d\udcda Components of a Prompt In addition to the high level task description, the prompt also contains the following: Component Syntax Description Variables {{variable_name}} These are provided by the user at runtime, and substituted in the prompt. Output Schema {output_schema} This is the schema of the expected output, and is compiled based on the output element. For more information on how the output schema is compiled for the prompt, check out output element compilation . Prompt Primitives @prompt_primitive_name These are pre-constructed prompts that are useful for common tasks. E.g., some primitives may contain information that helps the LLM understand the output schema better. To see the full list of prompt primitives, check out guardrails/constants.xml . <rail version= \"0.1\" > <prompt> <!-- (1)! --> Given the following document, answer the following questions. If the answer doesn't exist in the document, enter 'None'. {document} <!-- (2)! --> @xml_prefix_prompt <!-- (3)! --> {{output_schema}} <!-- (4)! --> @json_suffix_prompt <!-- (5)! --> </prompt> </rail> The prompt contains high level task information. The variable {{document}} is provided by the user at runtime. @xml_prefix_prompt is a prompt primitive provided by guardrails. It is equivalent to typing the following lines in the prompt: Given below is XML that describes the information to extract from this document and the tags to extract it into. {output_schema} is the output schema and contains information about , which is compiled based on the output element. @json_suffix_prompt is a prompt primitive provided by guardrails. It is equivalent to typing the following lines in the prompt: ONLY return a valid JSON object (no other text is necessary). The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter `None`. JSON Output:","title":"Prompt Element"},{"location":"rail/prompt/#prompt-element","text":"The <prompt></prompt> element contains the high level instructions sent to the LLM, that describe the high level task.","title":"Prompt Element"},{"location":"rail/prompt/#components-of-a-prompt","text":"In addition to the high level task description, the prompt also contains the following: Component Syntax Description Variables {{variable_name}} These are provided by the user at runtime, and substituted in the prompt. Output Schema {output_schema} This is the schema of the expected output, and is compiled based on the output element. For more information on how the output schema is compiled for the prompt, check out output element compilation . Prompt Primitives @prompt_primitive_name These are pre-constructed prompts that are useful for common tasks. E.g., some primitives may contain information that helps the LLM understand the output schema better. To see the full list of prompt primitives, check out guardrails/constants.xml . <rail version= \"0.1\" > <prompt> <!-- (1)! --> Given the following document, answer the following questions. If the answer doesn't exist in the document, enter 'None'. {document} <!-- (2)! --> @xml_prefix_prompt <!-- (3)! --> {{output_schema}} <!-- (4)! --> @json_suffix_prompt <!-- (5)! --> </prompt> </rail> The prompt contains high level task information. The variable {{document}} is provided by the user at runtime. @xml_prefix_prompt is a prompt primitive provided by guardrails. It is equivalent to typing the following lines in the prompt: Given below is XML that describes the information to extract from this document and the tags to extract it into. {output_schema} is the output schema and contains information about , which is compiled based on the output element. @json_suffix_prompt is a prompt primitive provided by guardrails. It is equivalent to typing the following lines in the prompt: ONLY return a valid JSON object (no other text is necessary). The JSON MUST conform to the XML format, including any types and format requests e.g. requests for lists, objects and specific types. Be correct and concise. If you are unsure anywhere, enter `None`. JSON Output:","title":"\ud83d\udcda Components of a Prompt"},{"location":"rail/script/","text":"Script Element Note This is a beta feature, and serves more advanced use cases. If you're just getting started with Guardrails, you can skip this section for now. The <script></script> element contains any custom code that a developer wants to use. Common use cases include: Custom Validators : Here's a few examples of adding custom validators via the <script> tag: adding a validator to filter secret keys , adding a validator to check if an ingredient is vegan , adding a validator to check if a chess move is valid . Custom DataTypes : Examples coming soon! Here's the syntax for the <script> element: <rail version= \"0.1\" > <script language= \"python\" > # your code here </script> </rail> \ud83d\udd10 Adding a custom Validator Here's an example of adding a custom validator to check if a generated text contains any secret keys. The validator is added via the <script> element. <rail version= \"0.1\" > <script> from guardrails.validators import Validator, EventDetail, register_validator <!-- (1)! --> @register_validator(name=\"custom-validator\", data_type=\"string\") <!-- (2)! --> class CustomValidatorName(Validator): <!-- (3)! --> def validate(self, key, value, schema) -> Dict: <!-- (4)! --> # Check if value meets the criteria. valid_condition = ... descriptive_error_message = ... if not valid_condition: # Create a programatically corrected value. correct_value = ... raise EventDetail( <!-- (5)! --> key=key, value=value, schema=schema, error_message=descriptive_error_message, fix_value=correct_value, ) return schema <!-- (6)! --> </script> </rail> In order to add a custom validator, you need to import the Validator class, EventDetail class, and register_validator decorator. Add the register_validator decorator to your custom validator class. The name argument is the name of the validator (this will be used in RAIL as the formatter name), and the data_type argument is the data type that the validator is applicable to. In this case, the validator is applicable to strings. Subclass the Validator class. You only need to implement the validate method. The validate method takes in the key , value , and schema as arguments. The key is the key of the value in the JSON object, the value is the value itself, and the schema is the schema of the value. The validate method raises an EventDetail object if the value is invalid. This object is then used to take corrective action specified in the RAIL spec. The validate method should return the schema if the value is valid. The custom validator defined in above can be used in the RAIL spec as follows: <rail version= \"0.1\" > <output> <string .... format= \"custom-validator\" on-fail-custom-validator= \"fix\" > </output> </rail> \ud83e\udded Adding a custom DataType Coming soon!","title":"(Experimental) Script Element"},{"location":"rail/script/#script-element","text":"Note This is a beta feature, and serves more advanced use cases. If you're just getting started with Guardrails, you can skip this section for now. The <script></script> element contains any custom code that a developer wants to use. Common use cases include: Custom Validators : Here's a few examples of adding custom validators via the <script> tag: adding a validator to filter secret keys , adding a validator to check if an ingredient is vegan , adding a validator to check if a chess move is valid . Custom DataTypes : Examples coming soon! Here's the syntax for the <script> element: <rail version= \"0.1\" > <script language= \"python\" > # your code here </script> </rail>","title":"Script Element"},{"location":"rail/script/#adding-a-custom-validator","text":"Here's an example of adding a custom validator to check if a generated text contains any secret keys. The validator is added via the <script> element. <rail version= \"0.1\" > <script> from guardrails.validators import Validator, EventDetail, register_validator <!-- (1)! --> @register_validator(name=\"custom-validator\", data_type=\"string\") <!-- (2)! --> class CustomValidatorName(Validator): <!-- (3)! --> def validate(self, key, value, schema) -> Dict: <!-- (4)! --> # Check if value meets the criteria. valid_condition = ... descriptive_error_message = ... if not valid_condition: # Create a programatically corrected value. correct_value = ... raise EventDetail( <!-- (5)! --> key=key, value=value, schema=schema, error_message=descriptive_error_message, fix_value=correct_value, ) return schema <!-- (6)! --> </script> </rail> In order to add a custom validator, you need to import the Validator class, EventDetail class, and register_validator decorator. Add the register_validator decorator to your custom validator class. The name argument is the name of the validator (this will be used in RAIL as the formatter name), and the data_type argument is the data type that the validator is applicable to. In this case, the validator is applicable to strings. Subclass the Validator class. You only need to implement the validate method. The validate method takes in the key , value , and schema as arguments. The key is the key of the value in the JSON object, the value is the value itself, and the schema is the schema of the value. The validate method raises an EventDetail object if the value is invalid. This object is then used to take corrective action specified in the RAIL spec. The validate method should return the schema if the value is valid. The custom validator defined in above can be used in the RAIL spec as follows: <rail version= \"0.1\" > <output> <string .... format= \"custom-validator\" on-fail-custom-validator= \"fix\" > </output> </rail>","title":"\ud83d\udd10 Adding a custom Validator"},{"location":"rail/script/#adding-a-custom-datatype","text":"Coming soon!","title":"\ud83e\udded Adding a custom DataType"}]}